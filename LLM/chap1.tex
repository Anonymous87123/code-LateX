\chapter{基础知识}
\section{大模型基础概念}

\textbf{大模型}：一般指1亿以上参数模型，但标准一直升级，目前已有万亿参数以上的模型。

\textbf{大语言模型(Large Language Model, LLM)}：针对语言的大模型。

参数规模：\textbf{175B、60B、540B等}，这些一般指参数的个数，B是Billion/十亿的意思，175B是1750亿参数，这是ChatGPT大约的参数规模。

\section{单双向注意力}
\subsection{核心概念：“阅读”和“写作”}
理解单双向注意力是掌握大模型架构差异的关键。我们可以用两个生动的比喻来理解：

\textbf{双向注意力：像阅读侦探小说}:想象你在阅读一本悬疑小说。为了理解复杂的情节，你会\textbf{随意地前后翻看}。当看到最后一章揭示凶手时，你可能会翻回前面的章节，查看某个角色的不在场证明是否有漏洞。这就是"双向"的精髓——任何一个部分的信息都可以参考全文的任何其他部分，获得全局的、最充分的理解。

\textbf{单向注意力：像写作小说续集}:现在你要为这本小说写续集。你只能\textbf{从左到右一个一个词地写}。在写下"侦探"这个词时，你只能基于前面已经写好的"突然，门开了，走进来一位…"来构思，你\textbf{不能提前知道或使用}后面将要写出的"掏出了手枪"这个词。这就是"单向"或"因果"的本质——每个新词只能基于它之前的所有词来生成。

双向注意力机制:
\begin{itemize}
\item \textbf{目标}：深度\textbf{理解}和\textbf{编码}输入信息
\item \textbf{工作原理}：模型同时处理整个句子的所有词。当理解某个词（如代词"它"）时，可以\textbf{同时关注}该词左右两侧的所有上下文，从而准确判断指代关系
\item \textbf{优势}：文本理解能力极强，能把握复杂语义关系和指代消解
\item \textbf{局限}：不适合直接用于生成任务，否则会"作弊"（提前看到答案）
\item \textbf{典型代表}：BERT模型，主要用于文本分类、情感分析等理解型任务
\end{itemize}

单向注意力机制:
\begin{itemize}
\item \textbf{目标}：序列\textbf{生成}
\item \textbf{工作原理}：模型以自回归方式工作，每次只能基于当前和之前的词预测下一个词，严格遵循因果律
\item \textbf{优势}：天然适合文本生成任务，训练目标与实际应用完全一致，Zero-shot能力强，容易涌现新能力
\item \textbf{局限}：在纯理解任务上可能不如双向模型深入
\item \textbf{典型代表}：GPT系列、LLaMA系列
\end{itemize}

\begin{table}[h]
\centering
\caption{单双向注意力机制对比}
\begin{tabular}{p{0.28\textwidth}p{0.28\textwidth}p{0.28\textwidth}}
\toprule
\textbf{特性} & \textbf{双向注意力} & \textbf{单向注意力（因果注意力）} \\
\midrule
\textbf{核心目标} & 理解与分析 & 生成与创作 \\
\textbf{信息流动} & 全局、无方向限制 & 从左到右、严格因果 \\
\textbf{形象比喻} & 阅读分析文章 & 写作口述文章 \\
\textbf{主要优势} & 深层语义理解、分类任务强 & 文本生成、零样本能力、涌现能力 \\
\textbf{主要局限} & 不直接适用于生成 & 理解任务可能缺少全局上下文 \\
\textbf{典型架构} & Encoder（编码器） & Decoder（解码器） \\
\textbf{代表模型} & BERT & GPT、LLaMA系列 \\
\bottomrule
\end{tabular}
\end{table}

\section{各系模型详细介绍}

\subsection{Causal Decoder（因果解码器）系}

核心原理:Causal Decoder采用传统的GPT风格设计，在生成每一个新词（Token）时，只能看到它之前的所有词（左侧上下文），无法看到后面的词。这种结构简单、高效，特别适合\textbf{自回归文本生成}任务。

代表模型：LLaMA系列（如LLaMA-7B）
\begin{itemize}
\item \textbf{开发机构}：Meta（Facebook）公司
\item \textbf{技术特点}：
    \begin{itemize}
    \item 专注于"原始"的文本生成能力，模型结构经典、干净
    \item 采用纯Decoder架构，参数量从7B到70B不等
    \item 训练数据涵盖20种语言的公开语料，总计1.4万亿Token
    \end{itemize}
\item \textbf{开源影响}：
    \begin{itemize}
    \item 2023年2月发布，成为AI开源社区最重要的基石之一
    \item 绝大多数开源衍生模型（如中文的、医学的、法律的）都基于LLaMA的架构进行\textbf{微调}或\textbf{继续训练}
    \item 其开源策略彻底改变了行业生态，使中小研究机构和企业能够基于强大底座进行AI研发
    \end{itemize}
\end{itemize}

\subsection{Encoder-Decoder（编码器-解码器）系}

核心原理:这是自然语言处理领域的经典框架，包含两个核心组件
\begin{itemize}
\item \textbf{编码器}：像"阅读理解器"，使用双向注意力机制完整阅读并理解整个输入文本
\item \textbf{解码器}：像"写作器"，根据编码器的理解，从左到右地生成输出文本
\item 两者通过"上下文向量"（Context Vector）或交叉注意力机制连接
\end{itemize}

代表模型：T5、Flan-T5
\begin{itemize}
\item \textbf{开发机构}：Google Research
\item \textbf{T5模型核心思想}：
    \begin{itemize}
    \item 提出\textbf{"将所有文本任务都统一为文本到文本的格式"}
    \item 示例：翻译任务输入：\texttt{"translate English to German: That is good."}，输出：\texttt{"Das ist gut."}
    \item 将分类、摘要、问答、翻译等任务统一为相同的形式
    \end{itemize} 
\item \textbf{Flan-T5模型特点}：
    \begin{itemize}
    \item 是T5的升级版，经过大规模\textbf{"指令微调"}
    \item 使用数千个不同任务的指令数据进行训练（如"请总结以下文章"、"改写这句话"）
    \item 在零样本和少样本学习上表现突出，具备极强的\textbf{理解和遵循人类指令}能力
    \item 参数量从80M到11B多个版本，适应不同计算资源需求
    \end{itemize}
\end{itemize}

\subsection{Prefix Decoder（前缀解码器）系}

核心原理:这是\textbf{Causal Decoder的"增强版"}，其工作流程为：
\begin{enumerate}
\item 将输入（前缀）和输出拼成一个长序列
\item 对输入部分（前缀）允许模型使用\textbf{双向注意力}进行充分理解
\item 当开始生成输出部分时，切换回\textbf{单向注意力}模式
\item 这样在生成时，模型对输入有更完整的认知
\end{enumerate}

代表模型：ChatGLM / ChatGLM2
\begin{itemize}
\item \textbf{开发机构}：中国清华大学·智谱AI公司
\item \textbf{技术特点}：
    \begin{itemize}
    \item \textbf{双语优势}：对中文和英文进行同等优化的训练，在中英文理解和生成上平衡且强大
    \item \textbf{架构优势}：Prefix Decoder架构使其在理解长上下文和复杂提示方面表现优异
    \item \textbf{开源贡献}：ChatGLM2-6B是早期最具影响力的中英双语开源对话模型之一
    \item \textbf{高效推理}：采用INT4量化等技术，降低部署和推理成本
    \end{itemize}
\item \textbf{版本演进}：
    \begin{itemize}
    \item ChatGLM（第一代）：130B参数，支持中英双语对话
    \item ChatGLM2-6B：62B参数，推理速度提升42\%，支持32K上下文长度
    \item ChatGLM3：进一步优化指令遵循和代码生成能力
    \end{itemize}
\end{itemize}

\section{三种Decoder架构区别}
核心区别主要区别在于attention mask不同：

\noindent Encoder-Decoder架构:
\begin{itemize}
\item 在输入上采用双向注意力，对问题的编码理解更充分
\item 适用任务：在偏理解的NLP任务上效果好
\item 缺点：在长文本生成任务上效果差，训练效率低
\end{itemize}

\noindent Causal Decoder架构:
\begin{itemize}
\item 自回归语言模型，预训练和下游应用是完全一致的，严格遵守只有后面的token才能看到前面的token的规则
\item 适用任务：文本生成任务效果好
\item 优点：训练效率高，zero-shot能力更强，具有涌现能力
\end{itemize}

\noindent Prefix Decoder架构:
\begin{itemize}
\item 特点：prefix部分的token互相能看到，是Causal Decoder和Encoder-Decoder的折中
\item 缺点：训练效率低
\end{itemize}

\section{大模型训练目标}
\subsection{语言模型}
根据已有词预测下一个词，训练目标为最大似然函数：
\[
\mathcal{L}_{LM}(x)=\sum_{i=1}^{n}\log P(x_{i}|x_{<i})
\]
训练效率：Prefix Decoder $<$ Causal Decoder\\
Causal Decoder结构会在所有token上计算损失，而Prefix Decoder只会在输出上计算损失。

\subsection{去噪自编码器}
随机替换掉一些文本段，训练语言模型去恢复被打乱的文本段。目标函数为：
\[
\mathcal{L}_{DAE}(x)=\log P(\tilde{x}|x_{/\tilde{x}})
\]
去噪自编码器的实现难度更高。采用去噪自编码器作为训练目标的任务有GLM-130B、T5。

\section{涌现能力分析}
根据前人分析和论文总结，大致是2个猜想：
\begin{itemize}
\item 任务的评价指标不够平滑
\item 复杂任务vs子任务：假设某个任务T有5个子任务Sub-T构成，每个sub-T随着模型增长，指标从40\%提升到60\%，但是最终任务的指标只从1.1\%提升到了7\%，也就是说宏观上看到了涌现现象，但是子任务效果其实是平滑增长的
\end{itemize}

\section{Decoder Only架构优势}
\begin{itemize}
\item decoder-only结构模型在没有任何微调数据的情况下，zero-shot的表现能力最好
\item 而encoder-decoder则需要在一定量的标注数据上做multitask-finetuning才能够激发最佳性能
\item 目前的Large LM的训练范式还是在大规模语料上做自监督学习，zero-shot性能更好的decoder-only架构才能更好的利用这些无标注的数据
\item 大模型使用decoder-only架构除了训练效率和工程实现上的优势外，在理论上因为Encoder的双向注意力会存在低秩的问题，这可能会削弱模型的表达能力
\item 就生成任务而言，引入双向注意力并无实质的好处
\item Encoder-decoder模型架构之所以能够在某些场景下表现更好，大概是因为它多了一倍参数
\item 在同等参数量、同等推理成本下，Decoder-only架构就是最优的选择
\end{itemize}

\section{大模型优缺点分析}
\subsection{优点}
\begin{itemize}
\item 可以利用大量的无标注数据来训练一个通用的模型，然后再用少量的有标注数据来微调模型，以适应特定的任务。这种预训练和微调的方法可以减少数据标注的成本和时间，提高模型的泛化能力
\item 可以利用生成式人工智能技术来产生新颖和有价值的内容，例如图像、文本、音乐等。这种生成能力可以帮助用户在创意、娱乐、教育等领域获得更好的体验和效果
\item 可以利用涌现能力(Emergent Capabilities)来完成一些之前无法完成或者很难完成的任务，例如数学应用题、常识推理、符号操作等。这种涌现能力可以反映模型的智能水平和推理能力
\end{itemize}

\subsection{缺点}
\begin{itemize}
\item 需要消耗大量的计算资源和存储资源来训练和运行，这会增加经济和环境的负担。据估计，训练一个GPT-3模型需要消耗约30万美元，并产生约284吨二氧化碳排放
\item 需要面对数据质量和安全性的问题，例如数据偏见、数据泄露、数据滥用等。这些问题可能会导致模型产生不准确或不道德的输出，并影响用户或社会的利益
\item 需要考虑可解释性、可靠性、可持续性等方面的挑战，例如如何理解和控制模型的行为、如何保证模型的正确性和稳定性、如何平衡模型的效益和风险等。这些挑战需要多方面的研究和合作，以确保大模型能够健康地发展
\end{itemize}