\contentsline {chapter}{\numberline {第一章\hspace {.3em}}基础知识}{31}{chapter.1}%
\contentsline {section}{\numberline {1.1}大模型基础概念}{31}{section.1.1}%
\contentsline {section}{\numberline {1.2}单双向注意力}{31}{section.1.2}%
\contentsline {subsection}{\numberline {1.2.1}核心概念：“阅读”和“写作”}{31}{subsection.1.2.1}%
\contentsline {subsection}{\numberline {1.2.2}技术深度解析}{31}{subsection.1.2.2}%
\contentsline {subsection}{\numberline {1.2.3}单双向注意力对比总结}{32}{subsection.1.2.3}%
\contentsline {section}{\numberline {1.3}主流开源模型体系}{32}{section.1.3}%
\contentsline {subsection}{\numberline {1.3.1}三种主流体系}{32}{subsection.1.3.1}%
\contentsline {section}{\numberline {1.4}三种Decoder架构区别}{33}{section.1.4}%
\contentsline {subsection}{\numberline {1.4.1}核心区别}{33}{subsection.1.4.1}%
\contentsline {subsection}{\numberline {1.4.2}Encoder-Decoder架构}{33}{subsection.1.4.2}%
\contentsline {subsection}{\numberline {1.4.3}Causal Decoder架构}{33}{subsection.1.4.3}%
\contentsline {subsection}{\numberline {1.4.4}Prefix Decoder架构}{33}{subsection.1.4.4}%
\contentsline {section}{\numberline {1.5}大模型训练目标}{33}{section.1.5}%
\contentsline {subsection}{\numberline {1.5.1}语言模型}{33}{subsection.1.5.1}%
\contentsline {subsection}{\numberline {1.5.2}去噪自编码器}{33}{subsection.1.5.2}%
\contentsline {section}{\numberline {1.6}涌现能力分析}{34}{section.1.6}%
\contentsline {section}{\numberline {1.7}Decoder Only架构优势}{34}{section.1.7}%
\contentsline {section}{\numberline {1.8}大模型优缺点分析}{34}{section.1.8}%
\contentsline {subsection}{\numberline {1.8.1}优点}{34}{subsection.1.8.1}%
\contentsline {subsection}{\numberline {1.8.2}缺点}{35}{subsection.1.8.2}%
\contentsline {chapter}{\numberline {第二章\hspace {.3em}}Layer Normalization 篇}{36}{chapter.2}%
\contentsline {section}{\numberline {2.1}Layer Norm 基础}{36}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}Layer Norm 计算公式}{36}{subsection.2.1.1}%
\contentsline {section}{\numberline {2.2}RMS Norm（均方根 Norm）}{36}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}RMS Norm 计算公式}{36}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}RMS Norm 的特点}{36}{subsection.2.2.2}%
\contentsline {section}{\numberline {2.3}Deep Norm}{37}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}Deep Norm 思路}{37}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2}Deep Norm 代码实现}{37}{subsection.2.3.2}%
\contentsline {subsection}{\numberline {2.3.3}Deep Norm 的优点}{37}{subsection.2.3.3}%
\contentsline {section}{\numberline {2.4}Layer Normalization 的位置设计}{37}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}LN 在 LLMs 中的不同位置}{37}{subsection.2.4.1}%
\contentsline {subsubsection}{Post LN}{37}{subsubsection*.3}%
\contentsline {subsubsection}{Pre-LN}{37}{subsubsection*.4}%
\contentsline {subsubsection}{Sandwich-LN}{38}{subsubsection*.5}%
\contentsline {section}{\numberline {2.5}Layer Normalization 对比分析}{38}{section.2.5}%
\contentsline {subsection}{\numberline {2.5.1}各模型使用的 Normalization 方法}{38}{subsection.2.5.1}%
\contentsline {subsection}{\numberline {2.5.2}特殊说明}{38}{subsection.2.5.2}%
\contentsline {chapter}{\numberline {第三章\hspace {.3em}}LLMs 激活函数篇}{39}{chapter.3}%
\contentsline {section}{\numberline {3.1}FFN 块基础}{39}{section.3.1}%
\contentsline {subsection}{\numberline {3.1.1}FFN 块计算公式}{39}{subsection.3.1.1}%
\contentsline {section}{\numberline {3.2}常见激活函数}{39}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}GeLU 激活函数}{39}{subsection.3.2.1}%
\contentsline {subsection}{\numberline {3.2.2}Swish 激活函数}{39}{subsection.3.2.2}%
\contentsline {section}{\numberline {3.3}GLU 线性门控单元}{39}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}基础 GLU 计算公式}{39}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}GeGLU 计算公式}{40}{subsection.3.3.2}%
\contentsline {subsection}{\numberline {3.3.3}SwiGLU 计算公式}{40}{subsection.3.3.3}%
\contentsline {subsection}{\numberline {3.3.4}参数规模说明}{40}{subsection.3.3.4}%
\contentsline {section}{\numberline {3.4}各 LLMs 激活函数使用情况}{40}{section.3.4}%
\contentsline {section}{\numberline {3.5}模型参数结构示例}{41}{section.3.5}%
\contentsline {subsection}{\numberline {3.5.1}LLaMA 模型参数结构}{41}{subsection.3.5.1}%
\contentsline {subsection}{\numberline {3.5.2}Bloom 模型参数结构}{41}{subsection.3.5.2}%
\contentsline {subsection}{\numberline {3.5.3}特殊说明}{41}{subsection.3.5.3}%
\contentsline {chapter}{\numberline {第四章\hspace {.3em}}Attention 升级面}{43}{chapter.4}%
\contentsline {section}{\numberline {4.1}传统 Attention 的问题}{43}{section.4.1}%
\contentsline {section}{\numberline {4.2}Attention 优化方向}{43}{section.4.2}%
\contentsline {section}{\numberline {4.3}Attention 变体概述}{43}{section.4.3}%
\contentsline {section}{\numberline {4.4}Multi-Query Attention}{43}{section.4.4}%
\contentsline {subsection}{\numberline {4.4.1}Multi-head Attention 存在的问题}{43}{subsection.4.4.1}%
\contentsline {subsection}{\numberline {4.4.2}Multi-Query Attention 介绍}{43}{subsection.4.4.2}%
\contentsline {subsection}{\numberline {4.4.3}Multi-head Attention 与 Multi-Query Attention 对比}{44}{subsection.4.4.3}%
\contentsline {subsection}{\numberline {4.4.4}各模型参数配置对比}{44}{subsection.4.4.4}%
\contentsline {subsection}{\numberline {4.4.5}Multi-Query Attention 的模型实现差异}{44}{subsection.4.4.5}%
\contentsline {subsection}{\numberline {4.4.6}Multi-Query Attention 的优势}{44}{subsection.4.4.6}%
\contentsline {subsection}{\numberline {4.4.7}使用 Multi-Query Attention 的模型}{44}{subsection.4.4.7}%
\contentsline {section}{\numberline {4.5}Grouped-query Attention}{44}{section.4.5}%
\contentsline {subsection}{\numberline {4.5.1}Grouped-query Attention 定义}{44}{subsection.4.5.1}%
\contentsline {subsection}{\numberline {4.5.2}使用 Grouped-query Attention 的模型}{45}{subsection.4.5.2}%
\contentsline {section}{\numberline {4.6}FlashAttention}{45}{section.4.6}%
\contentsline {subsection}{\numberline {4.6.1}FlashAttention 核心技术}{45}{subsection.4.6.1}%
\contentsline {subsection}{\numberline {4.6.2}FlashAttention 优点}{45}{subsection.4.6.2}%
\contentsline {subsection}{\numberline {4.6.3}使用 FlashAttention 的模型}{45}{subsection.4.6.3}%
\contentsline {section}{\numberline {4.7}并行 Transformer Block}{45}{section.4.7}%
\contentsline {subsection}{\numberline {4.7.1}并行 Transformer Block 原理}{45}{subsection.4.7.1}%
\contentsline {subsection}{\numberline {4.7.2}并行 Transformer Block 效果}{45}{subsection.4.7.2}%
\contentsline {subsection}{\numberline {4.7.3}使用并行 Transformer Block 的模型}{45}{subsection.4.7.3}%
\contentsline {chapter}{\numberline {第五章\hspace {.3em}}Transformers 操作篇}{46}{chapter.5}%
\contentsline {section}{\numberline {5.1}Transformers 库基础操作}{46}{section.5.1}%
\contentsline {subsection}{\numberline {5.1.1}如何利用 transformers 加载 Bert 模型？}{46}{subsection.5.1.1}%
\contentsline {subsection}{\numberline {5.1.2}如何利用 transformers 输出 Bert 指定 hidden\_state？}{47}{subsection.5.1.2}%
\contentsline {section}{\numberline {5.2}BERT 输出向量获取}{47}{section.5.2}%
\contentsline {subsection}{\numberline {5.2.1}BERT 模型输出结构}{47}{subsection.5.2.1}%
\contentsline {subsection}{\numberline {5.2.2}获取每一层网络的向量输出}{48}{subsection.5.2.2}%
\contentsline {chapter}{\numberline {第六章\hspace {.3em}}LLMs 损失函数篇}{49}{chapter.6}%
\contentsline {section}{\numberline {6.1}KL 散度}{49}{section.6.1}%
\contentsline {section}{\numberline {6.2}交叉熵损失函数}{49}{section.6.2}%
\contentsline {section}{\numberline {6.3}KL 散度与交叉熵的区别}{49}{section.6.3}%
\contentsline {section}{\numberline {6.4}多任务学习各loss差异过大处理}{50}{section.6.4}%
\contentsline {section}{\numberline {6.5}分类问题为什么用交叉熵损失函数不用均方误差(MSE)?}{50}{section.6.5}%
\contentsline {section}{\numberline {6.6}信息增益}{50}{section.6.6}%
\contentsline {section}{\numberline {6.7}多分类的分类损失函数(Softmax)}{50}{section.6.7}%
\contentsline {section}{\numberline {6.8}Softmax和交叉熵损失计算}{51}{section.6.8}%
\contentsline {section}{\numberline {6.9}Softmax数值稳定性问题}{51}{section.6.9}%
\contentsline {chapter}{\numberline {第七章\hspace {.3em}}相似度函数篇}{52}{chapter.7}%
\contentsline {section}{\numberline {7.1}相似度计算方法}{52}{section.7.1}%
\contentsline {subsection}{\numberline {7.1.1}除了余弦相似度还有哪些方法}{52}{subsection.7.1.1}%
\contentsline {section}{\numberline {7.2}对比学习}{52}{section.7.2}%
\contentsline {subsection}{\numberline {7.2.1}对比学习概述}{52}{subsection.7.2.1}%
\contentsline {section}{\numberline {7.3}对比学习中的负样本问题}{52}{section.7.3}%
\contentsline {subsection}{\numberline {7.3.1}负样本的重要性}{52}{subsection.7.3.1}%
\contentsline {subsection}{\numberline {7.3.2}负样本构造成本过高的解决方案}{52}{subsection.7.3.2}%
\contentsline {chapter}{\numberline {第八章\hspace {.3em}}大模型(LLMs)进阶面}{54}{chapter.8}%
\contentsline {section}{\numberline {8.1}生成式大模型概述}{54}{section.8.1}%
\contentsline {subsection}{\numberline {8.1.1}什么是生成式大模型？}{54}{subsection.8.1.1}%
\contentsline {section}{\numberline {8.2}文本生成多样性机制}{54}{section.8.2}%
\contentsline {subsection}{\numberline {8.2.1}大模型如何让生成的文本丰富而不单调？}{54}{subsection.8.2.1}%
\contentsline {subsubsection}{从训练角度来看}{54}{subsubsection*.11}%
\contentsline {subsubsection}{从推理角度来看}{54}{subsubsection*.12}%
\contentsline {section}{\numberline {8.3}LLMs复读机问题}{54}{section.8.3}%
\contentsline {subsection}{\numberline {8.3.1}什么是LLMs复读机问题？}{54}{subsection.8.3.1}%
\contentsline {subsection}{\numberline {8.3.2}为什么会出现LLMs复读机问题？}{55}{subsection.8.3.2}%
\contentsline {subsection}{\numberline {8.3.3}如何缓解LLMs复读机问题？}{55}{subsection.8.3.3}%
\contentsline {subsubsection}{Unlikelihood Training}{55}{subsubsection*.13}%
\contentsline {subsubsection}{引入噪声}{55}{subsubsection*.14}%
\contentsline {subsubsection}{Repetition Penalty}{55}{subsubsection*.15}%
\contentsline {subsubsection}{Contrastive Search}{55}{subsubsection*.16}%
\contentsline {subsubsection}{Beam Search}{56}{subsubsection*.17}%
\contentsline {subsubsection}{TopK sampling}{56}{subsubsection*.18}%
\contentsline {subsubsection}{Nucleus sampler}{56}{subsubsection*.19}%
\contentsline {subsubsection}{Temperature}{56}{subsubsection*.20}%
\contentsline {subsubsection}{No repeat ngram size}{56}{subsubsection*.21}%
\contentsline {subsubsection}{重复率指标检测}{56}{subsubsection*.22}%
\contentsline {subsubsection}{后处理和过滤}{56}{subsubsection*.23}%
\contentsline {subsubsection}{人工干预和控制}{56}{subsubsection*.24}%
\contentsline {section}{\numberline {8.4}LLaMA系列问题}{57}{section.8.4}%
\contentsline {subsection}{\numberline {8.4.1}LLaMA输入句子长度理论上可以无限长吗？}{57}{subsection.8.4.1}%
\contentsline {section}{\numberline {8.5}模型选择指南}{57}{section.8.5}%
\contentsline {subsection}{\numberline {8.5.1}什么情况用Bert模型，什么情况用LLaMA、ChatGLM类大模型？}{57}{subsection.8.5.1}%
\contentsline {section}{\numberline {8.6}专业领域大模型需求}{57}{section.8.6}%
\contentsline {subsection}{\numberline {8.6.1}各个专业领域是否需要各自的大模型来服务？}{57}{subsection.8.6.1}%
\contentsline {section}{\numberline {8.7}长文本处理技术}{57}{section.8.7}%
\contentsline {subsection}{\numberline {8.7.1}如何让大模型处理更长的文本？}{57}{subsection.8.7.1}%
\contentsline {subsubsection}{LongChat方法}{57}{subsubsection*.25}%
\contentsline {subsubsection}{其他技术方向}{57}{subsubsection*.26}%
\contentsline {chapter}{\numberline {第九章\hspace {.3em}}大模型(LLMs)微调面}{59}{chapter.9}%
\contentsline {section}{\numberline {9.1}微调基础问题}{59}{section.9.1}%
\contentsline {subsection}{\numberline {9.1.1}全参数微调显存需求}{59}{subsection.9.1.1}%
\contentsline {subsection}{\numberline {9.1.2}SFT后模型性能下降原因}{59}{subsection.9.1.2}%
\contentsline {section}{\numberline {9.2}数据构建与处理}{59}{section.9.2}%
\contentsline {subsection}{\numberline {9.2.1}SFT指令微调数据构建原则}{59}{subsection.9.2.1}%
\contentsline {subsection}{\numberline {9.2.2}领域模型Continue PreTrain数据选取}{60}{subsection.9.2.2}%
\contentsline {subsection}{\numberline {9.2.3}缓解模型遗忘通用能力}{60}{subsection.9.2.3}%
\contentsline {subsection}{\numberline {9.2.4}Multi-Task Instruction PreTraining}{60}{subsection.9.2.4}%
\contentsline {section}{\numberline {9.3}模型选择与配置}{60}{section.9.3}%
\contentsline {subsection}{\numberline {9.3.1}基座模型选择策略}{60}{subsection.9.3.1}%
\contentsline {subsection}{\numberline {9.3.2}数据输入格式要求}{60}{subsection.9.3.2}%
\contentsline {subsection}{\numberline {9.3.3}领域评测集构建}{60}{subsection.9.3.3}%
\contentsline {subsection}{\numberline {9.3.4}词表扩增必要性}{61}{subsection.9.3.4}%
\contentsline {section}{\numberline {9.4}训练实践与经验}{61}{section.9.4}%
\contentsline {subsection}{\numberline {9.4.1}训练自己的大模型步骤}{61}{subsection.9.4.1}%
\contentsline {subsection}{\numberline {9.4.2}多轮对话微调方法}{61}{subsection.9.4.2}%
\contentsline {section}{\numberline {9.5}关键技术问题}{62}{section.9.5}%
\contentsline {subsection}{\numberline {9.5.1}灾难性遗忘问题}{62}{subsection.9.5.1}%
\contentsline {subsection}{\numberline {9.5.2}微调模型显存需求}{62}{subsection.9.5.2}%
\contentsline {subsection}{\numberline {9.5.3}SFT学习内容}{62}{subsection.9.5.3}%
\contentsline {section}{\numberline {9.6}训练优化技术}{63}{section.9.6}%
\contentsline {subsection}{\numberline {9.6.1}Batch Size设置问题}{63}{subsection.9.6.1}%
\contentsline {subsection}{\numberline {9.6.2}优化器选择}{63}{subsection.9.6.2}%
\contentsline {section}{\numberline {9.7}数据构建建议}{63}{section.9.7}%
\contentsline {subsection}{\numberline {9.7.1}预训练数据集选择}{63}{subsection.9.7.1}%
\contentsline {subsection}{\numberline {9.7.2}微调数据集构建原则}{63}{subsection.9.7.2}%
\contentsline {section}{\numberline {9.8}Loss突刺问题分析}{63}{section.9.8}%
\contentsline {subsection}{\numberline {9.8.1}Loss突刺现象}{63}{subsection.9.8.1}%
\contentsline {subsection}{\numberline {9.8.2}Adam优化器与Loss突刺}{64}{subsection.9.8.2}%
\contentsline {subsection}{\numberline {9.8.3}Loss突刺解决方案}{64}{subsection.9.8.3}%
\contentsline {chapter}{\numberline {第十章\hspace {.3em}}LLMs 训练经验帖}{65}{chapter.10}%
\contentsline {section}{\numberline {10.1}分布式训练框架选择}{65}{section.10.1}%
\contentsline {section}{\numberline {10.2}LLMs 训练实用建议}{65}{section.10.2}%
\contentsline {subsection}{\numberline {10.2.1}弹性容错和自动重启机制}{65}{subsection.10.2.1}%
\contentsline {subsection}{\numberline {10.2.2}定期保存模型}{65}{subsection.10.2.2}%
\contentsline {subsection}{\numberline {10.2.3}规划训练目标}{65}{subsection.10.2.3}%
\contentsline {subsection}{\numberline {10.2.4}关注GPU使用效率}{65}{subsection.10.2.4}%
\contentsline {subsection}{\numberline {10.2.5}训练框架选择影响}{66}{subsection.10.2.5}%
\contentsline {subsection}{\numberline {10.2.6}环境配置注意事项}{66}{subsection.10.2.6}%
\contentsline {subsection}{\numberline {10.2.7}系统底层库升级谨慎性}{66}{subsection.10.2.7}%
\contentsline {section}{\numberline {10.3}模型规模选择策略}{66}{section.10.3}%
\contentsline {section}{\numberline {10.4}加速卡选择建议}{66}{section.10.4}%
\contentsline {chapter}{\numberline {第十一章\hspace {.3em}}大模型(LLMs) LangChain面}{67}{chapter.11}%
\contentsline {section}{\numberline {11.1}LangChain 基础概念}{67}{section.11.1}%
\contentsline {subsection}{\numberline {11.1.1}什么是LangChain？}{67}{subsection.11.1.1}%
\contentsline {subsection}{\numberline {11.1.2}LangChain Agent}{67}{subsection.11.1.2}%
\contentsline {section}{\numberline {11.2}LangChain 核心概念}{67}{section.11.2}%
\contentsline {subsection}{\numberline {11.2.1}Components and Chains}{67}{subsection.11.2.1}%
\contentsline {subsection}{\numberline {11.2.2}Prompt Templates and Values}{67}{subsection.11.2.2}%
\contentsline {subsection}{\numberline {11.2.3}Example Selectors}{68}{subsection.11.2.3}%
\contentsline {subsection}{\numberline {11.2.4}Output Parsers}{68}{subsection.11.2.4}%
\contentsline {subsection}{\numberline {11.2.5}Indexes and Retrievers}{68}{subsection.11.2.5}%
\contentsline {subsection}{\numberline {11.2.6}Chat Message History}{68}{subsection.11.2.6}%
\contentsline {subsection}{\numberline {11.2.7}Agents and Toolkits}{68}{subsection.11.2.7}%
\contentsline {section}{\numberline {11.3}LangChain 功能特性}{68}{section.11.3}%
\contentsline {subsection}{\numberline {11.3.1}主要功能}{68}{subsection.11.3.1}%
\contentsline {subsection}{\numberline {11.3.2}LangChain 模型类型}{69}{subsection.11.3.2}%
\contentsline {subsection}{\numberline {11.3.3}LangChain 特点}{69}{subsection.11.3.3}%
\contentsline {section}{\numberline {11.4}LangChain 使用示例}{69}{section.11.4}%
\contentsline {subsection}{\numberline {11.4.1}调用LLMs生成回复}{69}{subsection.11.4.1}%
\contentsline {subsection}{\numberline {11.4.2}修改提示模板}{70}{subsection.11.4.2}%
\contentsline {subsection}{\numberline {11.4.3}链接多个组件处理任务}{70}{subsection.11.4.3}%
\contentsline {subsection}{\numberline {11.4.4}Embedding \& Vector Store}{71}{subsection.11.4.4}%
\contentsline {section}{\numberline {11.5}LangChain 问题与解决方案}{71}{section.11.5}%
\contentsline {subsection}{\numberline {11.5.1}低效的令牌使用问题}{71}{subsection.11.5.1}%
\contentsline {subsection}{\numberline {11.5.2}文档问题}{72}{subsection.11.5.2}%
\contentsline {subsection}{\numberline {11.5.3}概念混淆问题}{72}{subsection.11.5.3}%
\contentsline {subsection}{\numberline {11.5.4}行为不一致问题}{72}{subsection.11.5.4}%
\contentsline {subsection}{\numberline {11.5.5}缺乏标准数据类型问题}{72}{subsection.11.5.5}%
\contentsline {section}{\numberline {11.6}LangChain 替代方案}{72}{section.11.6}%
\contentsline {subsection}{\numberline {11.6.1}LlamaIndex}{72}{subsection.11.6.1}%
\contentsline {subsection}{\numberline {11.6.2}Deepset Haystack}{72}{subsection.11.6.2}%
\contentsline {chapter}{\numberline {第十二章\hspace {.3em}}多轮对话中让AI保持长期记忆的8种优化方式篇}{73}{chapter.12}%
\contentsline {section}{\numberline {12.1}前言}{73}{section.12.1}%
\contentsline {section}{\numberline {12.2}Agent获取上下文对话信息的8种方式}{73}{section.12.2}%
\contentsline {subsection}{\numberline {12.2.1}获取全量历史对话}{73}{subsection.12.2.1}%
\contentsline {subsection}{\numberline {12.2.2}滑动窗口获取最近部分对话内容}{73}{subsection.12.2.2}%
\contentsline {subsection}{\numberline {12.2.3}获取历史对话中实体信息}{74}{subsection.12.2.3}%
\contentsline {subsection}{\numberline {12.2.4}利用知识图谱获取历史对话中的实体及其联系}{74}{subsection.12.2.4}%
\contentsline {subsection}{\numberline {12.2.5}对历史对话进行阶段性总结摘要}{75}{subsection.12.2.5}%
\contentsline {subsection}{\numberline {12.2.6}需要获取最新对话，又要兼顾较早历史对话}{75}{subsection.12.2.6}%
\contentsline {subsection}{\numberline {12.2.7}回溯最近和最关键的对话信息}{75}{subsection.12.2.7}%
\contentsline {subsection}{\numberline {12.2.8}基于向量检索对话信息}{75}{subsection.12.2.8}%
\contentsline {section}{\numberline {12.3}总结}{76}{section.12.3}%
\contentsline {chapter}{\numberline {第十三章\hspace {.3em}}基于LangChain RAG问答应用实战}{78}{chapter.13}%
\contentsline {section}{\numberline {13.1}前言}{78}{section.13.1}%
\contentsline {subsection}{\numberline {13.1.1}项目介绍}{78}{subsection.13.1.1}%
\contentsline {subsection}{\numberline {13.1.2}软件资源}{78}{subsection.13.1.2}%
\contentsline {section}{\numberline {13.2}环境搭建}{78}{section.13.2}%
\contentsline {subsection}{\numberline {13.2.1}环境配置}{78}{subsection.13.2.1}%
\contentsline {subsection}{\numberline {13.2.2}安装依赖}{78}{subsection.13.2.2}%
\contentsline {section}{\numberline {13.3}RAG问答应用实战}{79}{section.13.3}%
\contentsline {subsection}{\numberline {13.3.1}数据构建}{79}{subsection.13.3.1}%
\contentsline {subsection}{\numberline {13.3.2}本地数据加载}{79}{subsection.13.3.2}%
\contentsline {subsection}{\numberline {13.3.3}文档分割}{79}{subsection.13.3.3}%
\contentsline {subsection}{\numberline {13.3.4}向量化与数据入库}{80}{subsection.13.3.4}%
\contentsline {subsection}{\numberline {13.3.5}Prompt设计}{80}{subsection.13.3.5}%
\contentsline {subsection}{\numberline {13.3.6}RetrievalQAChain构建}{81}{subsection.13.3.6}%
\contentsline {subsection}{\numberline {13.3.7}高级用法}{81}{subsection.13.3.7}%
\contentsline {section}{\numberline {13.4}技术要点总结}{83}{section.13.4}%
\contentsline {subsection}{\numberline {13.4.1}核心组件}{83}{subsection.13.4.1}%
\contentsline {subsection}{\numberline {13.4.2}优化建议}{83}{subsection.13.4.2}%
\contentsline {subsection}{\numberline {13.4.3}扩展应用}{83}{subsection.13.4.3}%
\contentsline {chapter}{\numberline {第十四章\hspace {.3em}}基于LLM+向量库的文档对话经验面}{84}{chapter.14}%
\contentsline {section}{\numberline {14.1}基础理论}{84}{section.14.1}%
\contentsline {subsection}{\numberline {14.1.1}为什么大模型需要外挂(向量)知识库？}{84}{subsection.14.1.1}%
\contentsline {subsection}{\numberline {14.1.2}基于LLM+向量库的文档对话思路}{84}{subsection.14.1.2}%
\contentsline {subsection}{\numberline {14.1.3}核心技术：Embedding}{84}{subsection.14.1.3}%
\contentsline {subsection}{\numberline {14.1.4}Prompt模板构建}{85}{subsection.14.1.4}%
\contentsline {section}{\numberline {14.2}优化问题与解决方案}{85}{section.14.2}%
\contentsline {subsection}{\numberline {14.2.1}痛点1：文档切分粒度不好把控}{85}{subsection.14.2.1}%
\contentsline {subsubsection}{如何构建关键信息？}{85}{subsubsection*.28}%
\contentsline {subsection}{\numberline {14.2.2}痛点2：在垂直领域表现不佳}{86}{subsection.14.2.2}%
\contentsline {subsection}{\numberline {14.2.3}痛点3：LangChain内置问答分句效果不佳}{86}{subsection.14.2.3}%
\contentsline {subsection}{\numberline {14.2.4}痛点4：如何尽可能召回与query相关的Document}{86}{subsection.14.2.4}%
\contentsline {subsection}{\numberline {14.2.5}痛点5：如何让LLM基于query和context得到高质量的response}{87}{subsection.14.2.5}%
\contentsline {subsection}{\numberline {14.2.6}痛点6：Embedding模型在表示text chunks时偏差太大}{87}{subsection.14.2.6}%
\contentsline {subsection}{\numberline {14.2.7}痛点7：不同的prompt产生完全不同的效果}{87}{subsection.14.2.7}%
\contentsline {subsection}{\numberline {14.2.8}痛点8：LLM生成效果问题}{87}{subsection.14.2.8}%
\contentsline {subsection}{\numberline {14.2.9}痛点9：如何更高质量地召回context喂给LLM}{87}{subsection.14.2.9}%
\contentsline {section}{\numberline {14.3}工程实践与避坑指南}{87}{section.14.3}%
\contentsline {subsection}{\numberline {14.3.1}本地知识库问答系统（Langchain-chatGLM）}{87}{subsection.14.3.1}%
\contentsline {subsubsection}{环境配置问题解决}{87}{subsubsection*.29}%
\contentsline {subsubsection}{PDF加载问题解决}{88}{subsubsection*.30}%
\contentsline {subsubsection}{NLTK数据包问题解决}{88}{subsubsection*.31}%
\contentsline {subsubsection}{PaddleOCR错误解决}{88}{subsubsection*.32}%
\contentsline {subsubsection}{MOSS模型加载错误解决}{88}{subsubsection*.33}%
\contentsline {subsubsection}{MOSS提问错误解决}{88}{subsubsection*.34}%
\contentsline {section}{\numberline {14.4}技术要点总结}{89}{section.14.4}%
\contentsline {subsection}{\numberline {14.4.1}核心架构设计}{89}{subsection.14.4.1}%
\contentsline {subsection}{\numberline {14.4.2}关键优化建议}{89}{subsection.14.4.2}%
\contentsline {subsection}{\numberline {14.4.3}工程实践建议}{89}{subsection.14.4.3}%
\contentsline {chapter}{\numberline {第十五章\hspace {.3em}}大模型 RAG 经验面}{90}{chapter.15}%
\contentsline {section}{\numberline {15.1}LLMs 的不足与挑战}{90}{section.15.1}%
\contentsline {subsection}{\numberline {15.1.1}LLMs 存在的不足点}{90}{subsection.15.1.1}%
\contentsline {section}{\numberline {15.2}RAG 技术概述}{90}{section.15.2}%
\contentsline {subsection}{\numberline {15.2.1}什么是 RAG？}{90}{subsection.15.2.1}%
\contentsline {subsection}{\numberline {15.2.2}RAG 核心组件}{90}{subsection.15.2.2}%
\contentsline {subsubsection}{检索器模块（R）}{90}{subsubsection*.35}%
\contentsline {subsubsection}{生成器模块（G）}{91}{subsubsection*.36}%
\contentsline {section}{\numberline {15.3}RAG 的优势}{91}{section.15.3}%
\contentsline {section}{\numberline {15.4}RAG 与 SFT 对比}{92}{section.15.4}%
\contentsline {section}{\numberline {15.5}RAG 典型实现方法}{93}{section.15.5}%
\contentsline {subsection}{\numberline {15.5.1}数据索引构建}{93}{subsection.15.5.1}%
\contentsline {subsection}{\numberline {15.5.2}数据检索策略}{93}{subsection.15.5.2}%
\contentsline {subsection}{\numberline {15.5.3}文本生成与回复}{94}{subsection.15.5.3}%
\contentsline {section}{\numberline {15.6}RAG 典型案例}{94}{section.15.6}%
\contentsline {subsection}{\numberline {15.6.1}ChatPDF 及其复刻版}{94}{subsection.15.6.1}%
\contentsline {subsection}{\numberline {15.6.2}Baichuan 搜索增强系统}{94}{subsection.15.6.2}%
\contentsline {subsection}{\numberline {15.6.3}多模态检索增强模型}{95}{subsection.15.6.3}%
\contentsline {section}{\numberline {15.7}RAG 存在的问题与挑战}{95}{section.15.7}%
\contentsline {chapter}{\numberline {第十六章\hspace {.3em}}LLM文档对话PDF解析关键问题}{96}{chapter.16}%
\contentsline {section}{\numberline {16.1}PDF解析的必要性}{96}{section.16.1}%
\contentsline {subsection}{\numberline {16.1.1}为什么需要进行PDF解析？}{96}{subsection.16.1.1}%
\contentsline {subsection}{\numberline {16.1.2}PDF解析的重要性}{96}{subsection.16.1.2}%
\contentsline {section}{\numberline {16.2}PDF解析方法与区别}{96}{section.16.2}%
\contentsline {subsection}{\numberline {16.2.1}PDF解析的两条技术路线}{96}{subsection.16.2.1}%
\contentsline {section}{\numberline {16.3}PDF解析存在的问题}{97}{section.16.3}%
\contentsline {section}{\numberline {16.4}长文档关键信息提取方法}{97}{section.16.4}%
\contentsline {section}{\numberline {16.5}标题提取的重要性与方法}{97}{section.16.5}%
\contentsline {subsection}{\numberline {16.5.1}为什么要提取标题甚至是多级标题？}{97}{subsection.16.5.1}%
\contentsline {subsection}{\numberline {16.5.2}如何提取文章标题？}{98}{subsection.16.5.2}%
\contentsline {section}{\numberline {16.6}单双栏PDF的处理}{98}{section.16.6}%
\contentsline {subsection}{\numberline {16.6.1}区分单双栏PDF与重新排序}{98}{subsection.16.6.1}%
\contentsline {section}{\numberline {16.7}表格和图片数据提取}{99}{section.16.7}%
\contentsline {subsection}{\numberline {16.7.1}表格和图片数据提取思路}{99}{subsection.16.7.1}%
\contentsline {section}{\numberline {16.8}基于AI的文档解析优缺点}{99}{section.16.8}%
\contentsline {subsection}{\numberline {16.8.1}基于AI的文档解析优缺点分析}{99}{subsection.16.8.1}%
\contentsline {section}{\numberline {16.9}总结与建议}{99}{section.16.9}%
\contentsline {subsection}{\numberline {16.9.1}技术建议}{99}{subsection.16.9.1}%
\contentsline {subsection}{\numberline {16.9.2}实践要点总结}{99}{subsection.16.9.2}%
\contentsline {subsection}{\numberline {16.9.3}未来发展方向}{100}{subsection.16.9.3}%
\contentsline {chapter}{\numberline {第十七章\hspace {.3em}}大模型(LLMs)RAG版面分析表格识别方法篇}{101}{chapter.17}%
\contentsline {section}{\numberline {17.1}表格识别的必要性}{101}{section.17.1}%
\contentsline {subsection}{\numberline {17.1.1}为什么需要识别表格？}{101}{subsection.17.1.1}%
\contentsline {section}{\numberline {17.2}表格识别任务概述}{101}{section.17.2}%
\contentsline {subsection}{\numberline {17.2.1}表格识别任务定义}{101}{subsection.17.2.1}%
\contentsline {section}{\numberline {17.3}表格识别方法分类}{102}{section.17.3}%
\contentsline {subsection}{\numberline {17.3.1}传统方法}{102}{subsection.17.3.1}%
\contentsline {subsection}{\numberline {17.3.2}pdfplumber表格抽取}{102}{subsection.17.3.2}%
\contentsline {subsubsection}{pdfplumber表格抽取原理}{102}{subsubsection*.38}%
\contentsline {subsubsection}{pdfplumber常见的表格抽取模式}{102}{subsubsection*.39}%
\contentsline {subsection}{\numberline {17.3.3}深度学习方法-语义分割}{103}{subsection.17.3.3}%
\contentsline {subsubsection}{table-ocr/table-detect}{103}{subsubsection*.40}%
\contentsline {subsubsection}{腾讯表格图像识别}{103}{subsubsection*.41}%
\contentsline {subsubsection}{TableNet}{103}{subsubsection*.42}%
\contentsline {subsubsection}{CascadeTabNet}{103}{subsubsection*.43}%
\contentsline {subsubsection}{SPLERGE}{103}{subsubsection*.44}%
\contentsline {subsubsection}{DeepDeSRT}{103}{subsubsection*.45}%
\contentsline {section}{\numberline {17.4}方法比较与应用建议}{104}{section.17.4}%
\contentsline {subsection}{\numberline {17.4.1}各类方法优缺点比较}{104}{subsection.17.4.1}%
\contentsline {subsection}{\numberline {17.4.2}实际应用建议}{104}{subsection.17.4.2}%
\contentsline {section}{\numberline {17.5}技术挑战与发展趋势}{104}{section.17.5}%
\contentsline {subsection}{\numberline {17.5.1}当前主要挑战}{104}{subsection.17.5.1}%
\contentsline {subsection}{\numberline {17.5.2}未来发展趋势}{104}{subsection.17.5.2}%
\contentsline {chapter}{\numberline {第十八章\hspace {.3em}}大模型(LLMs)RAG版面分析-文本分块面}{105}{chapter.18}%
\contentsline {section}{\numberline {18.1}文本分块的必要性}{105}{section.18.1}%
\contentsline {subsection}{\numberline {18.1.1}为什么需要对文本分块？}{105}{subsection.18.1.1}%
\contentsline {section}{\numberline {18.2}常见的文本分块方法}{105}{section.18.2}%
\contentsline {subsection}{\numberline {18.2.1}一般的文本分块方法}{105}{subsection.18.2.1}%
\contentsline {subsection}{\numberline {18.2.2}正则拆分的文本分块方法}{106}{subsection.18.2.2}%
\contentsline {subsection}{\numberline {18.2.3}Spacy Text Splitter方法}{107}{subsection.18.2.3}%
\contentsline {subsection}{\numberline {18.2.4}基于langchain的CharacterTextSplitter方法}{107}{subsection.18.2.4}%
\contentsline {subsection}{\numberline {18.2.5}基于langchain的递归字符切分方法}{108}{subsection.18.2.5}%
\contentsline {subsection}{\numberline {18.2.6}HTML文本拆分方法}{109}{subsection.18.2.6}%
\contentsline {subsection}{\numberline {18.2.7}Markdown文本拆分方法}{110}{subsection.18.2.7}%
\contentsline {subsection}{\numberline {18.2.8}Python代码拆分方法}{111}{subsection.18.2.8}%
\contentsline {subsection}{\numberline {18.2.9}LaTex文本拆分方法}{111}{subsection.18.2.9}%
\contentsline {section}{\numberline {18.3}文本分块实践建议}{113}{section.18.3}%
\contentsline {subsection}{\numberline {18.3.1}分块策略选择}{113}{subsection.18.3.1}%
\contentsline {subsection}{\numberline {18.3.2}分块参数调优建议}{113}{subsection.18.3.2}%
\contentsline {subsection}{\numberline {18.3.3}不同文档类型的推荐分块方法}{113}{subsection.18.3.3}%
\contentsline {chapter}{\numberline {第十九章\hspace {.3em}}大模型外挂知识库优化：利用大模型辅助召回}{114}{chapter.19}%
\contentsline {section}{\numberline {19.1}引言：为什么需要大模型辅助召回？}{114}{section.19.1}%
\contentsline {section}{\numberline {19.2}策略一：HYDE（Hypothetical Document Embeddings）}{114}{section.19.2}%
\contentsline {subsection}{\numberline {19.2.1}HYDE 基本介绍}{114}{subsection.19.2.1}%
\contentsline {subsection}{\numberline {19.2.2}HYDE 思路详解}{114}{subsection.19.2.2}%
\contentsline {subsection}{\numberline {19.2.3}HYDE 存在的问题与局限性}{115}{subsection.19.2.3}%
\contentsline {section}{\numberline {19.3}策略二：FLARE（Forward-Looking Active REtrieval）}{115}{section.19.3}%
\contentsline {subsection}{\numberline {19.3.1}FLARE 基本介绍}{115}{subsection.19.3.1}%
\contentsline {subsection}{\numberline {19.3.2}为什么需要 FLARE？}{116}{subsection.19.3.2}%
\contentsline {subsection}{\numberline {19.3.3}FLARE 召回策略}{116}{subsection.19.3.3}%
\contentsline {subsubsection}{传统多次召回方案}{116}{subsubsection*.47}%
\contentsline {subsection}{\numberline {19.3.4}FLARE 策略1：主动召回标识}{116}{subsection.19.3.4}%
\contentsline {subsubsection}{策略1思路}{116}{subsubsection*.48}%
\contentsline {subsubsection}{策略1缺陷与解决方案}{116}{subsubsection*.49}%
\contentsline {subsection}{\numberline {19.3.5}FLARE 策略2：基于置信度的召回}{117}{subsection.19.3.5}%
\contentsline {subsubsection}{策略2思路}{117}{subsubsection*.50}%
\contentsline {section}{\numberline {19.4}技术对比与总结}{117}{section.19.4}%
\contentsline {subsection}{\numberline {19.4.1}方法优势比较}{117}{subsection.19.4.1}%
\contentsline {subsection}{\numberline {19.4.2}实践建议}{117}{subsection.19.4.2}%
\contentsline {subsection}{\numberline {19.4.3}未来发展方向}{118}{subsection.19.4.3}%
\contentsline {chapter}{\numberline {第二十章\hspace {.3em}}大模型外挂知识库优化负样本挖掘篇}{119}{chapter.20}%
\contentsline {section}{\numberline {20.1}引言：为什么需要构建负难样本？}{119}{section.20.1}%
\contentsline {section}{\numberline {20.2}负难样本构建方法}{119}{section.20.2}%
\contentsline {subsection}{\numberline {20.2.1}随机采样策略（Random Sampling）方法}{119}{subsection.20.2.1}%
\contentsline {subsubsection}{方法描述}{119}{subsubsection*.52}%
\contentsline {subsubsection}{存在问题}{119}{subsubsection*.53}%
\contentsline {subsubsection}{梯度影响分析}{119}{subsubsection*.54}%
\contentsline {subsection}{\numberline {20.2.2}Top-K负例采样策略（Top-K Hard Negative Sampling）方法}{120}{subsection.20.2.2}%
\contentsline {subsubsection}{方法描述}{120}{subsubsection*.55}%
\contentsline {subsubsection}{优点}{120}{subsubsection*.56}%
\contentsline {subsubsection}{存在问题}{120}{subsubsection*.57}%
\contentsline {subsubsection}{梯度影响分析}{120}{subsubsection*.58}%
\contentsline {subsection}{\numberline {20.2.3}困惑负样本采样方法SimANS方法}{120}{subsection.20.2.3}%
\contentsline {subsubsection}{动机}{120}{subsubsection*.59}%
\contentsline {subsubsection}{方法}{120}{subsubsection*.60}%
\contentsline {subsubsection}{采样方法特点}{120}{subsubsection*.61}%
\contentsline {subsubsection}{困惑样本采样分布}{120}{subsubsection*.62}%
\contentsline {subsubsection}{SimANS算法伪代码}{121}{subsubsection*.63}%
\contentsline {subsection}{\numberline {20.2.4}利用对比学习微调方式构建负例方法}{121}{subsection.20.2.4}%
\contentsline {subsubsection}{对比学习目的}{121}{subsubsection*.64}%
\contentsline {subsubsection}{文档召回场景}{122}{subsubsection*.65}%
\contentsline {subsubsection}{构建方法}{122}{subsubsection*.66}%
\contentsline {subsubsection}{损失函数}{122}{subsubsection*.67}%
\contentsline {subsubsection}{实现方法}{122}{subsubsection*.68}%
\contentsline {subsection}{\numberline {20.2.5}基于批内负采样的对比学习方法}{123}{subsection.20.2.5}%
\contentsline {subsubsection}{本质}{123}{subsubsection*.69}%
\contentsline {subsubsection}{论文方法}{123}{subsubsection*.70}%
\contentsline {subsection}{\numberline {20.2.6}相同文章采样方法}{123}{subsection.20.2.6}%
\contentsline {subsubsection}{思路}{123}{subsubsection*.71}%
\contentsline {subsubsection}{存在问题}{123}{subsubsection*.72}%
\contentsline {subsection}{\numberline {20.2.7}LLM辅助生成软标签及蒸馏}{123}{subsection.20.2.7}%
\contentsline {subsubsection}{方法}{123}{subsubsection*.73}%
\contentsline {subsubsection}{存在问题}{124}{subsubsection*.74}%
\contentsline {subsubsection}{优化策略}{124}{subsubsection*.75}%
\contentsline {section}{\numberline {20.3}辅助知识：梯度计算方法}{124}{section.20.3}%
\contentsline {subsection}{\numberline {20.3.1}梯度计算公式}{124}{subsection.20.3.1}%
\contentsline {section}{\numberline {20.4}方法总结与对比}{124}{section.20.4}%
\contentsline {subsection}{\numberline {20.4.1}各方法优缺点对比}{124}{subsection.20.4.1}%
\contentsline {subsection}{\numberline {20.4.2}实践建议}{124}{subsection.20.4.2}%
\contentsline {subsection}{\numberline {20.4.3}未来发展方向}{125}{subsection.20.4.3}%
\contentsline {chapter}{\numberline {第二十一章\hspace {.3em}}RAG(检索增强生成)评测面}{126}{chapter.21}%
\contentsline {section}{\numberline {21.1}引言：为什么需要对RAG进行评测？}{126}{section.21.1}%
\contentsline {section}{\numberline {21.2}RAG测试集合成方法}{126}{section.21.2}%
\contentsline {subsection}{\numberline {21.2.1}测试集构建需求}{126}{subsection.21.2.1}%
\contentsline {subsection}{\numberline {21.2.2}测试集生成流程}{126}{subsection.21.2.2}%
\contentsline {subsubsection}{生成问题和基准答案}{126}{subsubsection*.77}%
\contentsline {subsubsection}{具体操作步骤}{126}{subsubsection*.78}%
\contentsline {subsection}{\numberline {21.2.3}提示模板设计}{127}{subsection.21.2.3}%
\contentsline {subsection}{\numberline {21.2.4}编码实现示例}{127}{subsection.21.2.4}%
\contentsline {subsection}{\numberline {21.2.5}RAG预测收集}{129}{subsection.21.2.5}%
\contentsline {section}{\numberline {21.3}RAG评估方法分类}{130}{section.21.3}%
\contentsline {subsection}{\numberline {21.3.1}评估方法概述}{130}{subsection.21.3.1}%
\contentsline {subsection}{\numberline {21.3.2}独立评估（Independent Evaluation）}{130}{subsection.21.3.2}%
\contentsline {subsubsection}{独立评估介绍}{130}{subsubsection*.79}%
\contentsline {subsubsection}{独立评估模块}{130}{subsubsection*.80}%
\contentsline {subsubsection}{独立评估指标}{130}{subsubsection*.81}%
\contentsline {paragraph}{1. 答案相关性（Answer Relevancy）}{130}{paragraph*.82}%
\contentsline {paragraph}{2. 忠实度（Faithfulness）}{130}{paragraph*.83}%
\contentsline {paragraph}{3. 上下文精确度（Context Precision）}{131}{paragraph*.84}%
\contentsline {paragraph}{4. 答案正确性（Answer Correctness）}{131}{paragraph*.85}%
\contentsline {subsection}{\numberline {21.3.3}端到端评估（End-to-End Evaluation）}{131}{subsection.21.3.3}%
\contentsline {subsubsection}{端到端评估介绍}{131}{subsubsection*.86}%
\contentsline {subsubsection}{端到端评估模块}{131}{subsubsection*.87}%
\contentsline {section}{\numberline {21.4}RAG关键指标和能力}{132}{section.21.4}%
\contentsline {subsection}{\numberline {21.4.1}关键指标}{132}{subsection.21.4.1}%
\contentsline {subsection}{\numberline {21.4.2}关键能力}{132}{subsection.21.4.2}%
\contentsline {section}{\numberline {21.5}RAG评估框架}{132}{section.21.5}%
\contentsline {subsection}{\numberline {21.5.1}RAGAS框架}{132}{subsection.21.5.1}%
\contentsline {subsubsection}{RAGAS介绍}{132}{subsubsection*.88}%
\contentsline {subsubsection}{RAGAS算法原理}{132}{subsubsection*.89}%
\contentsline {subsection}{\numberline {21.5.2}ARES框架}{133}{subsection.21.5.2}%
\contentsline {subsubsection}{ARES介绍}{133}{subsubsection*.90}%
\contentsline {subsubsection}{ARES算法原理}{133}{subsubsection*.91}%
\contentsline {section}{\numberline {21.6}评估实践建议}{133}{section.21.6}%
\contentsline {subsection}{\numberline {21.6.1}评估流程设计}{133}{subsection.21.6.1}%
\contentsline {subsection}{\numberline {21.6.2}常见挑战与解决方案}{133}{subsection.21.6.2}%
\contentsline {subsection}{\numberline {21.6.3}最佳实践}{133}{subsection.21.6.3}%
\contentsline {chapter}{\numberline {第二十二章\hspace {.3em}}检索增强生成(RAG)优化策略篇}{134}{chapter.22}%
\contentsline {section}{\numberline {22.1}RAG基础功能篇}{134}{section.22.1}%
\contentsline {subsection}{\numberline {22.1.1}RAG工作流程}{134}{subsection.22.1.1}%
\contentsline {section}{\numberline {22.2}RAG各模块优化策略}{134}{section.22.2}%
\contentsline {subsection}{\numberline {22.2.1}文档块切分优化策略}{134}{subsection.22.2.1}%
\contentsline {subsection}{\numberline {22.2.2}文本嵌入模型优化策略}{134}{subsection.22.2.2}%
\contentsline {subsection}{\numberline {22.2.3}提示工程优化策略}{134}{subsection.22.2.3}%
\contentsline {subsection}{\numberline {22.2.4}大模型迭代优化策略}{135}{subsection.22.2.4}%
\contentsline {subsection}{\numberline {22.2.5}查询召回后处理优化}{135}{subsection.22.2.5}%
\contentsline {section}{\numberline {22.3}RAG架构优化策略}{135}{section.22.3}%
\contentsline {subsection}{\numberline {22.3.1}知识图谱(KG)上下文增强}{135}{subsection.22.3.1}%
\contentsline {subsubsection}{向量数据库上下文增强存在的问题}{135}{subsubsection*.92}%
\contentsline {subsubsection}{知识图谱增强策略}{135}{subsubsection*.93}%
\contentsline {subsection}{\numberline {22.3.2}Self-RAG：大模型对召回结果的筛选}{135}{subsection.22.3.2}%
\contentsline {subsubsection}{典型RAG架构中向量数据库的问题}{135}{subsubsection*.94}%
\contentsline {subsubsection}{Self-RAG核心思想}{135}{subsubsection*.95}%
\contentsline {subsubsection}{Self-RAG的创新点：反思字符（Reflection Tokens）}{136}{subsubsection*.96}%
\contentsline {subsubsection}{Self-RAG训练过程}{136}{subsubsection*.98}%
\contentsline {subsubsection}{Self-RAG推理过程}{136}{subsubsection*.99}%
\contentsline {subsubsection}{Self-RAG代码实战}{136}{subsubsection*.100}%
\contentsline {subsection}{\numberline {22.3.3}多向量检索器多模态RAG}{137}{subsection.22.3.3}%
\contentsline {subsubsection}{多向量检索器核心思想}{137}{subsubsection*.101}%
\contentsline {subsubsection}{半结构化RAG支持（文本+表格）}{137}{subsubsection*.102}%
\contentsline {subsubsection}{多模态RAG支持（文本+表格+图片）}{138}{subsubsection*.103}%
\contentsline {subsubsection}{私有化多模态RAG支持}{138}{subsubsection*.104}%
\contentsline {subsection}{\numberline {22.3.4}RAG Fusion优化策略}{138}{subsection.22.3.4}%
\contentsline {subsection}{\numberline {22.3.5}模块化RAG优化策略}{138}{subsection.22.3.5}%
\contentsline {subsection}{\numberline {22.3.6}RAG新模式优化策略}{139}{subsection.22.3.6}%
\contentsline {subsection}{\numberline {22.3.7}RAG结合SFT}{139}{subsection.22.3.7}%
\contentsline {subsection}{\numberline {22.3.8}查询转换（Query Transformations）}{139}{subsection.22.3.8}%
\contentsline {subsection}{\numberline {22.3.9}BERT在RAG中的应用}{139}{subsection.22.3.9}%
\contentsline {section}{\numberline {22.4}RAG索引优化策略}{139}{section.22.4}%
\contentsline {subsection}{\numberline {22.4.1}嵌入优化策略}{139}{subsection.22.4.1}%
\contentsline {subsection}{\numberline {22.4.2}检索召回率低解决方案}{140}{subsection.22.4.2}%
\contentsline {subsection}{\numberline {22.4.3}索引结构优化}{140}{subsection.22.4.3}%
\contentsline {subsection}{\numberline {22.4.4}混合检索提升效果}{140}{subsection.22.4.4}%
\contentsline {subsection}{\numberline {22.4.5}重新排名提升效果}{140}{subsection.22.4.5}%
\contentsline {section}{\numberline {22.5}RAG索引数据优化策略}{140}{section.22.5}%
\contentsline {subsection}{\numberline {22.5.1}提升索引数据质量}{140}{subsection.22.5.1}%
\contentsline {subsection}{\numberline {22.5.2}添加元数据提升效果}{141}{subsection.22.5.2}%
\contentsline {subsection}{\numberline {22.5.3}输入查询与文档对齐}{141}{subsection.22.5.3}%
\contentsline {subsection}{\numberline {22.5.4}提示压缩提升效果}{141}{subsection.22.5.4}%
\contentsline {subsection}{\numberline {22.5.5}查询重写和扩展}{141}{subsection.22.5.5}%
\contentsline {section}{\numberline {22.6}RAG未来发展方向}{141}{section.22.6}%
\contentsline {subsection}{\numberline {22.6.1}垂直优化}{141}{subsection.22.6.1}%
\contentsline {subsection}{\numberline {22.6.2}水平扩展}{142}{subsection.22.6.2}%
\contentsline {subsection}{\numberline {22.6.3}RAG生态系统}{142}{subsection.22.6.3}%
\contentsline {chapter}{\numberline {第二十三章\hspace {.3em}}大模型(LLMs)RAG关键痛点及解决方案}{143}{chapter.23}%
\contentsline {section}{\numberline {23.1}前言}{143}{section.23.1}%
\contentsline {section}{\numberline {23.2}问题一：内容缺失问题}{143}{section.23.2}%
\contentsline {subsection}{\numberline {23.2.1}内容缺失问题介绍}{143}{subsection.23.2.1}%
\contentsline {subsection}{\numberline {23.2.2}内容缺失问题解决方案}{143}{subsection.23.2.2}%
\contentsline {section}{\numberline {23.3}问题二：错过排名靠前的文档}{144}{section.23.3}%
\contentsline {subsection}{\numberline {23.3.1}错过排名靠前的文档问题介绍}{144}{subsection.23.3.1}%
\contentsline {subsection}{\numberline {23.3.2}错过排名靠前的文档问题解决方案}{144}{subsection.23.3.2}%
\contentsline {section}{\numberline {23.4}问题三：脱离上下文—整合策略的限制}{145}{section.23.4}%
\contentsline {subsection}{\numberline {23.4.1}脱离上下文问题介绍}{145}{subsection.23.4.1}%
\contentsline {subsection}{\numberline {23.4.2}脱离上下文问题解决方案}{145}{subsection.23.4.2}%
\contentsline {section}{\numberline {23.5}问题四：未能提取答案}{146}{section.23.5}%
\contentsline {subsection}{\numberline {23.5.1}未能提取答案问题介绍}{146}{subsection.23.5.1}%
\contentsline {subsection}{\numberline {23.5.2}未能提取答案问题解决方案}{146}{subsection.23.5.2}%
\contentsline {section}{\numberline {23.6}问题五：格式错误}{147}{section.23.6}%
\contentsline {subsection}{\numberline {23.6.1}格式错误问题介绍}{147}{subsection.23.6.1}%
\contentsline {subsection}{\numberline {23.6.2}格式错误问题解决方案}{147}{subsection.23.6.2}%
\contentsline {section}{\numberline {23.7}问题六：特异性错误}{148}{section.23.7}%
\contentsline {subsection}{\numberline {23.7.1}特异性错误问题介绍}{148}{subsection.23.7.1}%
\contentsline {subsection}{\numberline {23.7.2}特异性错误问题解决方案}{148}{subsection.23.7.2}%
\contentsline {section}{\numberline {23.8}问题七：回答不全面}{149}{section.23.8}%
\contentsline {subsection}{\numberline {23.8.1}回答不全面问题介绍}{149}{subsection.23.8.1}%
\contentsline {subsection}{\numberline {23.8.2}回答不全面问题解决方案}{149}{subsection.23.8.2}%
\contentsline {section}{\numberline {23.9}问题八：数据处理能力的挑战}{149}{section.23.9}%
\contentsline {subsection}{\numberline {23.9.1}数据处理能力挑战介绍}{149}{subsection.23.9.1}%
\contentsline {subsection}{\numberline {23.9.2}数据处理能力挑战解决方案}{149}{subsection.23.9.2}%
\contentsline {section}{\numberline {23.10}问题九：结构化数据查询的难题}{150}{section.23.10}%
\contentsline {subsection}{\numberline {23.10.1}结构化数据查询难题介绍}{150}{subsection.23.10.1}%
\contentsline {subsection}{\numberline {23.10.2}结构化数据查询难题解决方案}{150}{subsection.23.10.2}%
\contentsline {section}{\numberline {23.11}问题十：从复杂PDF文件中提取数据}{151}{section.23.11}%
\contentsline {subsection}{\numberline {23.11.1}复杂PDF数据提取问题介绍}{151}{subsection.23.11.1}%
\contentsline {subsection}{\numberline {23.11.2}复杂PDF数据提取问题解决方案}{151}{subsection.23.11.2}%
\contentsline {section}{\numberline {23.12}问题十一：备用模型}{152}{section.23.12}%
\contentsline {subsection}{\numberline {23.12.1}备用模型问题介绍}{152}{subsection.23.12.1}%
\contentsline {subsection}{\numberline {23.12.2}备用模型问题解决方案}{152}{subsection.23.12.2}%
\contentsline {section}{\numberline {23.13}问题十二：大语言模型(LLM)的安全挑战}{153}{section.23.13}%
\contentsline {subsection}{\numberline {23.13.1}LLM安全挑战介绍}{153}{subsection.23.13.1}%
\contentsline {subsection}{\numberline {23.13.2}LLM安全挑战解决方案}{153}{subsection.23.13.2}%
\contentsline {section}{\numberline {23.14}总结}{153}{section.23.14}%
\contentsline {chapter}{\numberline {第二十四章\hspace {.3em}}大模型(LLMs) RAG优化策略RAG-Fusion篇}{154}{chapter.24}%
\contentsline {section}{\numberline {24.1}RAG技术概述}{154}{section.24.1}%
\contentsline {subsection}{\numberline {24.1.1}RAG的优点}{154}{subsection.24.1.1}%
\contentsline {subsection}{\numberline {24.1.2}RAG的局限性}{154}{subsection.24.1.2}%
\contentsline {section}{\numberline {24.2}RAG-Fusion技术概述}{154}{section.24.2}%
\contentsline {subsection}{\numberline {24.2.1}为什么需要RAG-Fusion？}{154}{subsection.24.2.1}%
\contentsline {subsection}{\numberline {24.2.2}RAG-Fusion核心技术}{155}{subsection.24.2.2}%
\contentsline {section}{\numberline {24.3}RAG-Fusion工作流程}{155}{section.24.3}%
\contentsline {subsection}{\numberline {24.3.1}多查询生成}{155}{subsection.24.3.1}%
\contentsline {subsubsection}{为什么要生成多个查询？}{155}{subsubsection*.106}%
\contentsline {subsubsection}{多查询生成技术实现（提示工程）}{155}{subsubsection*.107}%
\contentsline {subsubsection}{多查询生成工作原理}{156}{subsubsection*.108}%
\contentsline {subsection}{\numberline {24.3.2}逆向排名融合（RRF）}{156}{subsection.24.3.2}%
\contentsline {subsubsection}{为什么选择RRF？}{156}{subsubsection*.109}%
\contentsline {subsubsection}{RRF技术实现}{157}{subsubsection*.110}%
\contentsline {subsubsection}{生成性输出用户意图保留}{158}{subsubsection*.111}%
\contentsline {subsubsection}{生成性输出用户意图保留技术实现}{158}{subsubsection*.112}%
\contentsline {section}{\numberline {24.4}RAG-Fusion的优势和挑战}{159}{section.24.4}%
\contentsline {subsection}{\numberline {24.4.1}RAG-Fusion优势}{159}{subsection.24.4.1}%
\contentsline {subsection}{\numberline {24.4.2}RAG-Fusion挑战}{159}{subsection.24.4.2}%
\contentsline {subsubsection}{伦理和用户体验具体考虑}{159}{subsubsection*.113}%
\contentsline {section}{\numberline {24.5}完整RAG-Fusion实现示例}{160}{section.24.5}%
\contentsline {section}{\numberline {24.6}总结}{163}{section.24.6}%
\contentsline {chapter}{\numberline {第二十五章\hspace {.3em}}基于知识图谱的大模型检索增强实现策略：Graph RAG}{164}{chapter.25}%
\contentsline {section}{\numberline {25.1}引言：为什么需要Graph RAG？}{164}{section.25.1}%
\contentsline {section}{\numberline {25.2}Graph RAG基本概念}{164}{section.25.2}%
\contentsline {subsection}{\numberline {25.2.1}什么是Graph RAG？}{164}{subsection.25.2.1}%
\contentsline {subsection}{\numberline {25.2.2}Graph RAG的核心思路}{164}{subsection.25.2.2}%
\contentsline {section}{\numberline {25.3}Graph RAG技术架构}{165}{section.25.3}%
\contentsline {subsection}{\numberline {25.3.1}整体工作流程}{165}{subsection.25.3.1}%
\contentsline {subsection}{\numberline {25.3.2}代码实现框架}{165}{subsection.25.3.2}%
\contentsline {section}{\numberline {25.4}Graph RAG具体实现}{166}{section.25.4}%
\contentsline {subsection}{\numberline {25.4.1}实体提取技术}{166}{subsection.25.4.1}%
\contentsline {subsection}{\numberline {25.4.2}子图检索策略}{168}{subsection.25.4.2}%
\contentsline {section}{\numberline {25.5}Graph RAG应用示例}{169}{section.25.5}%
\contentsline {subsection}{\numberline {25.5.1}示例1：人物信息查询}{169}{subsection.25.5.1}%
\contentsline {subsection}{\numberline {25.5.2}示例2：机构事件查询}{169}{subsection.25.5.2}%
\contentsline {subsection}{\numberline {25.5.3}完整示例代码}{170}{subsection.25.5.3}%
\contentsline {section}{\numberline {25.6}Graph RAG排序优化策略}{171}{section.25.6}%
\contentsline {subsection}{\numberline {25.6.1}现有方法的局限性}{171}{subsection.25.6.1}%
\contentsline {subsection}{\numberline {25.6.2}两阶段排序优化}{171}{subsection.25.6.2}%
\contentsline {subsubsection}{粗排阶段（LightGBM模型）}{171}{subsubsection*.114}%
\contentsline {subsubsection}{精排阶段（预训练语言模型）}{172}{subsubsection*.115}%
\contentsline {section}{\numberline {25.7}Graph RAG的优势与挑战}{173}{section.25.7}%
\contentsline {subsection}{\numberline {25.7.1}技术优势}{173}{subsection.25.7.1}%
\contentsline {subsection}{\numberline {25.7.2}面临挑战}{173}{subsection.25.7.2}%
\contentsline {subsection}{\numberline {25.7.3}未来发展方向}{174}{subsection.25.7.3}%
\contentsline {section}{\numberline {25.8}总结}{174}{section.25.8}%
\contentsline {chapter}{\numberline {第二十六章\hspace {.3em}}大模型(LLMs)参数高效微调(PEFT)技术综述}{175}{chapter.26}%
\contentsline {section}{\numberline {26.1}微调方法概述}{175}{section.26.1}%
\contentsline {subsection}{\numberline {26.1.1}微调方法分类}{175}{subsection.26.1.1}%
\contentsline {subsection}{\numberline {26.1.2}技术对比研究}{175}{subsection.26.1.2}%
\contentsline {section}{\numberline {26.2}为什么需要PEFT？}{176}{section.26.2}%
\contentsline {section}{\numberline {26.3}PEFT技术介绍}{176}{section.26.3}%
\contentsline {subsection}{\numberline {26.3.1}PEFT定义}{176}{subsection.26.3.1}%
\contentsline {subsection}{\numberline {26.3.2}PEFT优点}{176}{subsection.26.3.2}%
\contentsline {section}{\numberline {26.4}微调方法性能对比}{177}{section.26.4}%
\contentsline {subsection}{\numberline {26.4.1}资源消耗对比}{177}{subsection.26.4.1}%
\contentsline {subsection}{\numberline {26.4.2}PEFT与全量微调的区别}{177}{subsection.26.4.2}%
\contentsline {section}{\numberline {26.5}多种高效微调方法对比}{177}{section.26.5}%
\contentsline {subsection}{\numberline {26.5.1}方法选择建议}{177}{subsection.26.5.1}%
\contentsline {subsection}{\numberline {26.5.2}综合对比表}{177}{subsection.26.5.2}%
\contentsline {subsection}{\numberline {26.5.3}参数规模评估}{178}{subsection.26.5.3}%
\contentsline {section}{\numberline {26.6}当前高效微调技术存在的问题}{178}{section.26.6}%
\contentsline {subsection}{\numberline {26.6.1}参数计算口径不一致}{178}{subsection.26.6.1}%
\contentsline {subsection}{\numberline {26.6.2}缺乏模型大小的考虑}{178}{subsection.26.6.2}%
\contentsline {subsection}{\numberline {26.6.3}缺乏测量基准和评价标准}{178}{subsection.26.6.3}%
\contentsline {subsection}{\numberline {26.6.4}代码实现可读性差}{178}{subsection.26.6.4}%
\contentsline {section}{\numberline {26.7}高效微调技术最佳实践}{178}{section.26.7}%
\contentsline {section}{\numberline {26.8}PEFT存在的问题}{179}{section.26.8}%
\contentsline {section}{\numberline {26.9}参数高效微调方法总结}{179}{section.26.9}%
\contentsline {subsection}{\numberline {26.9.1}方法分类}{179}{subsection.26.9.1}%
\contentsline {subsection}{\numberline {26.9.2}技术特点比较}{179}{subsection.26.9.2}%
\contentsline {section}{\numberline {26.10}未来发展方向}{179}{section.26.10}%
\contentsline {chapter}{\numberline {第二十七章\hspace {.3em}}适配器微调(Adapter-tuning)技术详解}{182}{chapter.27}%
\contentsline {section}{\numberline {27.1}引言：为什么需要适配器微调？}{182}{section.27.1}%
\contentsline {subsection}{\numberline {27.1.1}全量微调的挑战}{182}{subsection.27.1.1}%
\contentsline {subsection}{\numberline {27.1.2}适配器微调的优势}{182}{subsection.27.1.2}%
\contentsline {section}{\numberline {27.2}适配器微调基本原理}{182}{section.27.2}%
\contentsline {subsection}{\numberline {27.2.1}核心思路}{182}{subsection.27.2.1}%
\contentsline {subsection}{\numberline {27.2.2}适配器结构设计}{182}{subsection.27.2.2}%
\contentsline {subsection}{\numberline {27.2.3}残差连接设计}{183}{subsection.27.2.3}%
\contentsline {section}{\numberline {27.3}适配器微调的技术特点}{183}{section.27.3}%
\contentsline {subsection}{\numberline {27.3.1}参数效率}{183}{subsection.27.3.1}%
\contentsline {subsection}{\numberline {27.3.2}推理开销}{183}{subsection.27.3.2}%
\contentsline {subsection}{\numberline {27.3.3}代码实现示例}{183}{subsection.27.3.3}%
\contentsline {section}{\numberline {27.4}AdapterFusion：多任务知识融合}{184}{section.27.4}%
\contentsline {subsection}{\numberline {27.4.1}设计思路}{184}{subsection.27.4.1}%
\contentsline {subsection}{\numberline {27.4.2}两阶段训练流程}{185}{subsection.27.4.2}%
\contentsline {subsection}{\numberline {27.4.3}融合机制}{185}{subsection.27.4.3}%
\contentsline {subsection}{\numberline {27.4.4}代码实现}{185}{subsection.27.4.4}%
\contentsline {section}{\numberline {27.5}AdapterDrop：动态效率优化}{186}{section.27.5}%
\contentsline {subsection}{\numberline {27.5.1}设计动机}{186}{subsection.27.5.1}%
\contentsline {subsection}{\numberline {27.5.2}核心策略}{186}{subsection.27.5.2}%
\contentsline {subsection}{\numberline {27.5.3}技术特点}{186}{subsection.27.5.3}%
\contentsline {subsection}{\numberline {27.5.4}动态决策算法}{186}{subsection.27.5.4}%
\contentsline {section}{\numberline {27.6}MAM Adapter：统一框架设计}{187}{section.27.6}%
\contentsline {subsection}{\numberline {27.6.1}整合思路}{187}{subsection.27.6.1}%
\contentsline {subsection}{\numberline {27.6.2}架构设计}{187}{subsection.27.6.2}%
\contentsline {subsubsection}{并行适配器（Parallel Adapter）}{187}{subsubsection*.121}%
\contentsline {subsubsection}{软提示（Soft Prompts）}{187}{subsubsection*.122}%
\contentsline {subsection}{\numberline {27.6.3}数学表达}{188}{subsection.27.6.3}%
\contentsline {subsection}{\numberline {27.6.4}优势分析}{188}{subsection.27.6.4}%
\contentsline {subsection}{\numberline {27.6.5}完整实现}{188}{subsection.27.6.5}%
\contentsline {section}{\numberline {27.7}适配器微调的性能评估}{189}{section.27.7}%
\contentsline {subsection}{\numberline {27.7.1}效率对比}{189}{subsection.27.7.1}%
\contentsline {subsection}{\numberline {27.7.2}适用场景分析}{190}{subsection.27.7.2}%
\contentsline {section}{\numberline {27.8}实践建议与最佳实践}{190}{section.27.8}%
\contentsline {subsection}{\numberline {27.8.1}参数配置建议}{190}{subsection.27.8.1}%
\contentsline {subsection}{\numberline {27.8.2}训练技巧}{190}{subsection.27.8.2}%
\contentsline {subsection}{\numberline {27.8.3}多任务适配策略}{191}{subsection.27.8.3}%
\contentsline {section}{\numberline {27.9}总结与展望}{191}{section.27.9}%
\contentsline {subsection}{\numberline {27.9.1}技术优势总结}{191}{subsection.27.9.1}%
\contentsline {subsection}{\numberline {27.9.2}未来发展方向}{191}{subsection.27.9.2}%
\contentsline {subsection}{\numberline {27.9.3}应用前景}{191}{subsection.27.9.3}%
\contentsline {chapter}{\numberline {第二十八章\hspace {.3em}}提示学习(Prompting)技术详解}{192}{chapter.28}%
\contentsline {section}{\numberline {28.1}引言：为什么需要提示学习？}{192}{section.28.1}%
\contentsline {subsection}{\numberline {28.1.1}全量微调的挑战}{192}{subsection.28.1.1}%
\contentsline {subsection}{\numberline {28.1.2}提示学习的优势}{192}{subsection.28.1.2}%
\contentsline {section}{\numberline {28.2}提示学习基本概念}{192}{section.28.2}%
\contentsline {subsection}{\numberline {28.2.1}什么是提示学习？}{192}{subsection.28.2.1}%
\contentsline {subsection}{\numberline {28.2.2}提示学习应用实例}{192}{subsection.28.2.2}%
\contentsline {section}{\numberline {28.3}提示学习的优点}{193}{section.28.3}%
\contentsline {section}{\numberline {28.4}提示学习方法综述}{193}{section.28.4}%
\contentsline {subsection}{\numberline {28.4.1}方法分类}{193}{subsection.28.4.1}%
\contentsline {section}{\numberline {28.5}前缀微调（Prefix-tuning）}{193}{section.28.5}%
\contentsline {subsection}{\numberline {28.5.1}为什么需要前缀微调？}{193}{subsection.28.5.1}%
\contentsline {subsection}{\numberline {28.5.2}前缀微调思路}{193}{subsection.28.5.2}%
\contentsline {subsection}{\numberline {28.5.3}前缀微调优点}{193}{subsection.28.5.3}%
\contentsline {subsection}{\numberline {28.5.4}前缀微调缺点}{194}{subsection.28.5.4}%
\contentsline {section}{\numberline {28.6}指示微调（Prompt-tuning）}{194}{section.28.6}%
\contentsline {subsection}{\numberline {28.6.1}为什么需要指示微调？}{194}{subsection.28.6.1}%
\contentsline {subsection}{\numberline {28.6.2}指示微调思路}{194}{subsection.28.6.2}%
\contentsline {subsection}{\numberline {28.6.3}指示微调优点}{194}{subsection.28.6.3}%
\contentsline {subsection}{\numberline {28.6.4}指示微调缺点}{194}{subsection.28.6.4}%
\contentsline {subsection}{\numberline {28.6.5}指示微调 vs 前缀微调}{195}{subsection.28.6.5}%
\contentsline {subsection}{\numberline {28.6.6}指示微调 vs 全量微调}{195}{subsection.28.6.6}%
\contentsline {section}{\numberline {28.7}P-tuning方法}{195}{section.28.7}%
\contentsline {subsection}{\numberline {28.7.1}为什么需要P-tuning？}{195}{subsection.28.7.1}%
\contentsline {subsection}{\numberline {28.7.2}P-tuning思路}{195}{subsection.28.7.2}%
\contentsline {subsection}{\numberline {28.7.3}P-tuning优点}{196}{subsection.28.7.3}%
\contentsline {subsection}{\numberline {28.7.4}P-tuning缺点}{196}{subsection.28.7.4}%
\contentsline {subsection}{\numberline {28.7.5}P-tuning vs 传统微调}{196}{subsection.28.7.5}%
\contentsline {section}{\numberline {28.8}P-tuning v2方法}{197}{section.28.8}%
\contentsline {subsection}{\numberline {28.8.1}为什么需要P-tuning v2？}{197}{subsection.28.8.1}%
\contentsline {subsection}{\numberline {28.8.2}P-tuning v2思路}{197}{subsection.28.8.2}%
\contentsline {subsection}{\numberline {28.8.3}P-tuning v2优点}{197}{subsection.28.8.3}%
\contentsline {subsection}{\numberline {28.8.4}P-tuning v2缺点}{197}{subsection.28.8.4}%
\contentsline {subsection}{\numberline {28.8.5}P-tuning v2架构实现}{197}{subsection.28.8.5}%
\contentsline {section}{\numberline {28.9}方法对比与分析}{199}{section.28.9}%
\contentsline {subsection}{\numberline {28.9.1}技术演进路径}{199}{subsection.28.9.1}%
\contentsline {subsection}{\numberline {28.9.2}适用场景建议}{199}{subsection.28.9.2}%
\contentsline {section}{\numberline {28.10}实践建议与最佳实践}{199}{section.28.10}%
\contentsline {subsection}{\numberline {28.10.1}参数配置建议}{199}{subsection.28.10.1}%
\contentsline {subsection}{\numberline {28.10.2}训练技巧}{200}{subsection.28.10.2}%
\contentsline {section}{\numberline {28.11}挑战与未来方向}{200}{section.28.11}%
\contentsline {subsection}{\numberline {28.11.1}当前挑战}{200}{subsection.28.11.1}%
\contentsline {subsection}{\numberline {28.11.2}未来研究方向}{200}{subsection.28.11.2}%
\contentsline {section}{\numberline {28.12}总结}{201}{section.28.12}%
\contentsline {chapter}{\numberline {第二十九章\hspace {.3em}}LoRA系列微调技术详解}{202}{chapter.29}%
\contentsline {section}{\numberline {29.1}LoRA基础篇}{202}{section.29.1}%
\contentsline {subsection}{\numberline {29.1.1}什么是LoRA？}{202}{subsection.29.1.1}%
\contentsline {subsection}{\numberline {29.1.2}LoRA核心思路}{202}{subsection.29.1.2}%
\contentsline {subsection}{\numberline {29.1.3}LoRA技术特点}{202}{subsection.29.1.3}%
\contentsline {subsection}{\numberline {29.1.4}LoRA简单描述}{202}{subsection.29.1.4}%
\contentsline {section}{\numberline {29.2}QLoRA技术篇}{203}{section.29.2}%
\contentsline {subsection}{\numberline {29.2.1}QLoRA核心思路}{203}{subsection.29.2.1}%
\contentsline {subsection}{\numberline {29.2.2}QLoRA技术特点}{203}{subsection.29.2.2}%
\contentsline {section}{\numberline {29.3}AdaLoRA技术篇}{203}{section.29.3}%
\contentsline {subsection}{\numberline {29.3.1}AdaLoRA核心思路}{203}{subsection.29.3.1}%
\contentsline {section}{\numberline {29.4}LoRA权重管理}{203}{section.29.4}%
\contentsline {subsection}{\numberline {29.4.1}权重合并可行性}{203}{subsection.29.4.1}%
\contentsline {subsection}{\numberline {29.4.2}实际存储需求}{203}{subsection.29.4.2}%
\contentsline {section}{\numberline {29.5}LoRA微调优势分析}{203}{section.29.5}%
\contentsline {subsection}{\numberline {29.5.1}主要优点}{203}{subsection.29.5.1}%
\contentsline {subsection}{\numberline {29.5.2}训练加速原理}{204}{subsection.29.5.2}%
\contentsline {section}{\numberline {29.6}LoRA持续训练策略}{204}{section.29.6}%
\contentsline {subsection}{\numberline {29.6.1}持续训练方法}{204}{subsection.29.6.1}%
\contentsline {section}{\numberline {29.7}LoRA局限性分析}{204}{section.29.7}%
\contentsline {subsection}{\numberline {29.7.1}技术局限性}{204}{subsection.29.7.1}%
\contentsline {subsection}{\numberline {29.7.2}与全参数微调对比}{205}{subsection.29.7.2}%
\contentsline {section}{\numberline {29.8}实验效果分析}{205}{section.29.8}%
\contentsline {subsection}{\numberline {29.8.1}多任务性能对比}{205}{subsection.29.8.1}%
\contentsline {section}{\numberline {29.9}LoRA参数配置优化}{205}{section.29.9}%
\contentsline {subsection}{\numberline {29.9.1}Transformer参数矩阵选择}{205}{subsection.29.9.1}%
\contentsline {subsection}{\numberline {29.9.2}参数量确定方法}{206}{subsection.29.9.2}%
\contentsline {subsection}{\numberline {29.9.3}Rank选择策略}{206}{subsection.29.9.3}%
\contentsline {subsection}{\numberline {29.9.4}Alpha参数配置}{206}{subsection.29.9.4}%
\contentsline {section}{\numberline {29.10}过拟合防止策略}{206}{section.29.10}%
\contentsline {subsection}{\numberline {29.10.1}过拟合应对措施}{206}{subsection.29.10.1}%
\contentsline {section}{\numberline {29.11}优化器选择}{207}{section.29.11}%
\contentsline {subsection}{\numberline {29.11.1}优化器推荐}{207}{subsection.29.11.1}%
\contentsline {section}{\numberline {29.12}内存使用优化}{207}{section.29.12}%
\contentsline {subsection}{\numberline {29.12.1}内存影响因素}{207}{subsection.29.12.1}%
\contentsline {section}{\numberline {29.13}高级特性}{207}{section.29.13}%
\contentsline {subsection}{\numberline {29.13.1}权重合并能力}{207}{subsection.29.13.1}%
\contentsline {subsection}{\numberline {29.13.2}逐层Rank调整}{207}{subsection.29.13.2}%
\contentsline {section}{\numberline {29.14}初始化策略}{207}{section.29.14}%
\contentsline {subsection}{\numberline {29.14.1}矩阵初始化方法}{207}{subsection.29.14.1}%
\contentsline {subsection}{\numberline {29.14.2}初始化原理分析}{208}{subsection.29.14.2}%
\contentsline {section}{\numberline {29.15}实践指南}{208}{section.29.15}%
\contentsline {subsection}{\numberline {29.15.1}可训练参数比例确定}{208}{subsection.29.15.1}%
\contentsline {subsection}{\numberline {29.15.2}结果保存策略}{208}{subsection.29.15.2}%
\contentsline {section}{\numberline {29.16}总结}{209}{section.29.16}%
\contentsline {chapter}{\numberline {第三十章\hspace {.3em}}PEFT库中LoRA使用详解}{210}{chapter.30}%
\contentsline {section}{\numberline {30.1}前言}{210}{section.30.1}%
\contentsline {subsection}{\numberline {30.1.1}环境依赖配置}{210}{subsection.30.1.1}%
\contentsline {section}{\numberline {30.2}LoraConfig配置详解}{210}{section.30.2}%
\contentsline {subsection}{\numberline {30.2.1}基本配置示例}{210}{subsection.30.2.1}%
\contentsline {subsection}{\numberline {30.2.2}参数说明}{211}{subsection.30.2.2}%
\contentsline {section}{\numberline {30.3}模型加入PEFT策略}{211}{section.30.3}%
\contentsline {subsection}{\numberline {30.3.1}模型加载策略}{211}{subsection.30.3.1}%
\contentsline {subsection}{\numberline {30.3.2}模型显存占用分析}{212}{subsection.30.3.2}%
\contentsline {subsection}{\numberline {30.3.3}显存优化策略}{212}{subsection.30.3.3}%
\contentsline {subsubsection}{8bit量化优化}{212}{subsubsection*.130}%
\contentsline {subsubsection}{梯度检查优化}{212}{subsubsection*.131}%
\contentsline {subsection}{\numberline {30.3.4}PEFT策略集成}{213}{subsection.30.3.4}%
\contentsline {section}{\numberline {30.4}PEFT库中LoRA模块代码实现}{213}{section.30.4}%
\contentsline {subsection}{\numberline {30.4.1}整体架构设计}{213}{subsection.30.4.1}%
\contentsline {subsection}{\numberline {30.4.2}\_find\_and\_replace()实现}{213}{subsection.30.4.2}%
\contentsline {subsection}{\numberline {30.4.3}LoRA层实现细节}{214}{subsection.30.4.3}%
\contentsline {subsubsection}{基类LoraLayer}{214}{subsubsection*.132}%
\contentsline {subsubsection}{Linear层实现}{215}{subsubsection*.133}%
\contentsline {section}{\numberline {30.5}LoRA微调存储策略}{216}{section.30.5}%
\contentsline {subsection}{\numberline {30.5.1}存储实现}{216}{subsection.30.5.1}%
\contentsline {section}{\numberline {30.6}LoRA推理加载策略}{217}{section.30.6}%
\contentsline {subsection}{\numberline {30.6.1}方案一：直接加载LoRA层}{217}{subsection.30.6.1}%
\contentsline {subsection}{\numberline {30.6.2}方案二：权重合并后加载}{218}{subsection.30.6.2}%
\contentsline {section}{\numberline {30.7}多LoRA适配器切换}{219}{section.30.7}%
\contentsline {subsection}{\numberline {30.7.1}环境要求}{219}{subsection.30.7.1}%
\contentsline {subsection}{\numberline {30.7.2}使用方法}{219}{subsection.30.7.2}%
\contentsline {subsection}{\numberline {30.7.3}实战案例}{219}{subsection.30.7.3}%
\contentsline {section}{\numberline {30.8}总结}{220}{section.30.8}%
\contentsline {chapter}{\numberline {第三十一章\hspace {.3em}}大模型(LLMs)推理技术详解}{222}{chapter.31}%
\contentsline {section}{\numberline {31.1}引言：大模型推理的挑战与机遇}{222}{section.31.1}%
\contentsline {section}{\numberline {31.2}推理显存占用分析}{222}{section.31.2}%
\contentsline {subsection}{\numberline {31.2.1}显存暴涨原因}{222}{subsection.31.2.1}%
\contentsline {subsection}{\numberline {31.2.2}显存组成分析}{222}{subsection.31.2.2}%
\contentsline {section}{\numberline {31.3}推理速度性能分析}{222}{section.31.3}%
\contentsline {subsection}{\numberline {31.3.1}GPU vs CPU推理速度对比}{222}{subsection.31.3.1}%
\contentsline {subsection}{\numberline {31.3.2}精度对推理速度的影响}{223}{subsection.31.3.2}%
\contentsline {section}{\numberline {31.4}大模型的推理能力分析}{223}{section.31.4}%
\contentsline {subsection}{\numberline {31.4.1}上下文纠正能力}{223}{subsection.31.4.1}%
\contentsline {subsection}{\numberline {31.4.2}知识推理与创造能力}{223}{subsection.31.4.2}%
\contentsline {section}{\numberline {31.5}生成参数配置优化}{223}{section.31.5}%
\contentsline {subsection}{\numberline {31.5.1}关键参数调优建议}{223}{subsection.31.5.1}%
\contentsline {subsection}{\numberline {31.5.2}参数详细说明}{224}{subsection.31.5.2}%
\contentsline {subsubsection}{top\_p（核采样）}{224}{subsubsection*.136}%
\contentsline {subsubsection}{temperature（温度参数）}{224}{subsubsection*.137}%
\contentsline {subsubsection}{repetition\_penalty（重复惩罚）}{224}{subsubsection*.138}%
\contentsline {subsubsection}{任务特定调优策略}{224}{subsubsection*.139}%
\contentsline {section}{\numberline {31.6}内存高效推理方法}{224}{section.31.6}%
\contentsline {subsection}{\numberline {31.6.1}内存需求估算方法}{224}{subsection.31.6.1}%
\contentsline {subsubsection}{精度对内存的影响}{224}{subsubsection*.141}%
\contentsline {subsubsection}{内存组成分析}{225}{subsubsection*.142}%
\contentsline {subsubsection}{LLaMA-6B内存估算示例}{225}{subsubsection*.143}%
\contentsline {subsubsection}{中间变量内存计算}{225}{subsubsection*.145}%
\contentsline {subsection}{\numberline {31.6.2}FP16混合精度推理}{226}{subsection.31.6.2}%
\contentsline {subsubsection}{技术原理}{226}{subsubsection*.146}%
\contentsline {subsubsection}{PyTorch实现}{226}{subsubsection*.147}%
\contentsline {subsubsection}{HuggingFace Transformers集成}{226}{subsubsection*.148}%
\contentsline {subsection}{\numberline {31.6.3}INT8量化推理}{227}{subsection.31.6.3}%
\contentsline {subsubsection}{技术挑战与解决方案}{227}{subsubsection*.149}%
\contentsline {subsubsection}{量化实现原理}{227}{subsubsection*.150}%
\contentsline {subsubsection}{HuggingFace集成示例}{227}{subsubsection*.151}%
\contentsline {subsection}{\numberline {31.6.4}LoRA低秩适配推理}{227}{subsection.31.6.4}%
\contentsline {subsubsection}{核心思想}{227}{subsubsection*.152}%
\contentsline {subsubsection}{参数效率分析}{228}{subsubsection*.153}%
\contentsline {subsubsection}{实际应用}{228}{subsubsection*.154}%
\contentsline {subsection}{\numberline {31.6.5}梯度检查点技术}{228}{subsection.31.6.5}%
\contentsline {subsubsection}{技术原理}{228}{subsubsection*.155}%
\contentsline {subsubsection}{PyTorch实现}{228}{subsubsection*.156}%
\contentsline {subsubsection}{HuggingFace集成}{229}{subsubsection*.157}%
\contentsline {subsection}{\numberline {31.6.6}Torch FSDP + CPU Offload}{229}{subsection.31.6.6}%
\contentsline {subsubsection}{完全分片数据并行}{229}{subsubsection*.158}%
\contentsline {subsubsection}{CPU Offload技术}{229}{subsubsection*.159}%
\contentsline {subsubsection}{实现示例}{229}{subsubsection*.160}%
\contentsline {section}{\numberline {31.7}推理输出合规化处理}{230}{section.31.7}%
\contentsline {subsection}{\numberline {31.7.1}合规化处理流程}{230}{subsection.31.7.1}%
\contentsline {subsection}{\numberline {31.7.2}多级兜底策略}{230}{subsection.31.7.2}%
\contentsline {section}{\numberline {31.8}应用模式优化策略}{230}{section.31.8}%
\contentsline {subsection}{\numberline {31.8.1}模式演进分析}{230}{subsection.31.8.1}%
\contentsline {subsection}{\numberline {31.8.2}混合模式优化实践}{230}{subsection.31.8.2}%
\contentsline {section}{\numberline {31.9}输出分布稀疏性处理}{231}{section.31.9}%
\contentsline {subsection}{\numberline {31.9.1}问题分析}{231}{subsection.31.9.1}%
\contentsline {subsection}{\numberline {31.9.2}解决方案}{231}{subsection.31.9.2}%
\contentsline {subsubsection}{温度参数调节}{231}{subsubsection*.163}%
\contentsline {subsubsection}{正则化技术}{231}{subsubsection*.164}%
\contentsline {subsubsection}{高级平滑技术}{231}{subsubsection*.165}%
\contentsline {section}{\numberline {31.10}实践建议与最佳实践}{232}{section.31.10}%
\contentsline {subsection}{\numberline {31.10.1}硬件选型建议}{232}{subsection.31.10.1}%
\contentsline {subsection}{\numberline {31.10.2}推理流水线优化}{232}{subsection.31.10.2}%
\contentsline {section}{\numberline {31.11}总结与展望}{233}{section.31.11}%
\contentsline {chapter}{\numberline {第三十二章\hspace {.3em}}大模型(LLMs)增量预训练技术详解}{235}{chapter.32}%
\contentsline {section}{\numberline {32.1}引言：为什么需要增量预训练？}{235}{section.32.1}%
\contentsline {subsection}{\numberline {32.1.1}增量预训练的理论基础}{235}{subsection.32.1.1}%
\contentsline {subsection}{\numberline {32.1.2}增量预训练的核心价值}{235}{subsection.32.1.2}%
\contentsline {section}{\numberline {32.2}增量预训练准备工作}{235}{section.32.2}%
\contentsline {subsection}{\numberline {32.2.1}模型底座选型策略}{235}{subsection.32.2.1}%
\contentsline {subsubsection}{主流模型选择考量}{235}{subsubsection*.167}%
\contentsline {subsubsection}{选型关键因素}{235}{subsubsection*.169}%
\contentsline {subsection}{\numberline {32.2.2}数据收集策略}{236}{subsection.32.2.2}%
\contentsline {subsubsection}{高质量数据源推荐}{236}{subsubsection*.170}%
\contentsline {subsubsection}{数据收集原则}{236}{subsubsection*.171}%
\contentsline {subsection}{\numberline {32.2.3}数据清洗流程}{236}{subsection.32.2.3}%
\contentsline {subsubsection}{清洗关键步骤}{236}{subsubsection*.172}%
\contentsline {subsubsection}{清洗工具推荐}{237}{subsubsection*.173}%
\contentsline {section}{\numberline {32.3}训练框架选择}{238}{section.32.3}%
\contentsline {subsection}{\numberline {32.3.1}超大规模训练框架}{238}{subsection.32.3.1}%
\contentsline {subsubsection}{3D并行训练}{238}{subsubsection*.174}%
\contentsline {subsection}{\numberline {32.3.2}中小规模训练框架}{238}{subsection.32.3.2}%
\contentsline {subsubsection}{单节点/多节点训练}{238}{subsubsection*.175}%
\contentsline {subsubsection}{张量并行注意事项}{238}{subsubsection*.176}%
\contentsline {subsection}{\numberline {32.3.3}资源受限环境训练}{238}{subsection.32.3.3}%
\contentsline {subsubsection}{LoRA微调方案}{238}{subsubsection*.177}%
\contentsline {section}{\numberline {32.4}完整训练流程}{239}{section.32.4}%
\contentsline {subsection}{\numberline {32.4.1}数据预处理}{239}{subsection.32.4.1}%
\contentsline {subsubsection}{文本长度处理}{239}{subsubsection*.178}%
\contentsline {subsubsection}{预处理注意事项}{239}{subsubsection*.179}%
\contentsline {subsection}{\numberline {32.4.2}分词器选择}{240}{subsection.32.4.2}%
\contentsline {subsubsection}{分词器选型建议}{240}{subsubsection*.180}%
\contentsline {subsection}{\numberline {32.4.3}模型加载与转换}{240}{subsection.32.4.3}%
\contentsline {subsubsection}{模型格式处理}{240}{subsubsection*.181}%
\contentsline {subsubsection}{模型转换示例}{240}{subsubsection*.182}%
\contentsline {subsection}{\numberline {32.4.4}训练参数配置}{240}{subsection.32.4.4}%
\contentsline {subsubsection}{基础参数设置}{240}{subsubsection*.183}%
\contentsline {subsubsection}{显存优化配置}{241}{subsubsection*.184}%
\contentsline {subsection}{\numberline {32.4.5}训练监控与分析}{241}{subsection.32.4.5}%
\contentsline {subsubsection}{关键监控指标}{241}{subsubsection*.185}%
\contentsline {subsubsection}{监控工具推荐}{241}{subsubsection*.186}%
\contentsline {subsection}{\numberline {32.4.6}模型转换与测试}{242}{subsection.32.4.6}%
\contentsline {subsubsection}{Checkpoint转换流程}{242}{subsubsection*.187}%
\contentsline {subsubsection}{转换脚本示例}{242}{subsubsection*.188}%
\contentsline {subsubsection}{模型测试验证}{242}{subsubsection*.189}%
\contentsline {section}{\numberline {32.5}数据量要求与规划}{243}{section.32.5}%
\contentsline {subsection}{\numberline {32.5.1}最小数据量要求}{243}{subsection.32.5.1}%
\contentsline {subsection}{\numberline {32.5.2}数据量规划建议}{243}{subsection.32.5.2}%
\contentsline {section}{\numberline {32.6}训练过程关键问题处理}{243}{section.32.6}%
\contentsline {subsection}{\numberline {32.6.1}Loss上升现象分析}{243}{subsection.32.6.1}%
\contentsline {subsubsection}{正常Loss上升场景}{243}{subsubsection*.191}%
\contentsline {subsubsection}{异常Loss上升排查}{243}{subsubsection*.192}%
\contentsline {subsection}{\numberline {32.6.2}学习率调优策略}{243}{subsection.32.6.2}%
\contentsline {subsubsection}{学习率设置原则}{243}{subsubsection*.193}%
\contentsline {subsubsection}{具体设置建议}{244}{subsubsection*.194}%
\contentsline {subsubsection}{Batch Size缩放规则}{244}{subsubsection*.195}%
\contentsline {subsection}{\numberline {32.6.3}Warmup比例设置}{244}{subsection.32.6.3}%
\contentsline {subsubsection}{一般设置规则}{244}{subsubsection*.196}%
\contentsline {subsubsection}{增量预训练特殊考量}{244}{subsubsection*.197}%
\contentsline {section}{\numberline {32.7}关键参数实验分析}{244}{section.32.7}%
\contentsline {subsection}{\numberline {32.7.1}Warmup步数影响分析}{244}{subsection.32.7.1}%
\contentsline {subsubsection}{实验设计}{244}{subsubsection*.198}%
\contentsline {subsubsection}{实验结果}{245}{subsubsection*.199}%
\contentsline {subsubsection}{实践建议}{245}{subsubsection*.200}%
\contentsline {subsection}{\numberline {32.7.2}学习率大小影响分析}{245}{subsection.32.7.2}%
\contentsline {subsubsection}{实验设计}{245}{subsubsection*.201}%
\contentsline {subsubsection}{实验结果}{245}{subsubsection*.202}%
\contentsline {subsubsection}{重要发现}{245}{subsubsection*.203}%
\contentsline {subsection}{\numberline {32.7.3}Rewarmup策略影响分析}{245}{subsection.32.7.3}%
\contentsline {subsubsection}{实验设计}{245}{subsubsection*.204}%
\contentsline {subsubsection}{重要发现}{245}{subsubsection*.205}%
\contentsline {subsubsection}{实践指导}{246}{subsubsection*.206}%
\contentsline {section}{\numberline {32.8}增量预训练最佳实践}{246}{section.32.8}%
\contentsline {subsection}{\numberline {32.8.1}完整工作流总结}{246}{subsection.32.8.1}%
\contentsline {subsection}{\numberline {32.8.2}故障排查指南}{246}{subsection.32.8.2}%
\contentsline {subsection}{\numberline {32.8.3}持续优化建议}{247}{subsection.32.8.3}%
\contentsline {section}{\numberline {32.9}总结与展望}{247}{section.32.9}%
\contentsline {chapter}{\numberline {第三十三章\hspace {.3em}}大模型增量预训练样本拼接技术详解}{248}{chapter.33}%
\contentsline {section}{\numberline {33.1}引言：为什么需要样本拼接？}{248}{section.33.1}%
\contentsline {subsection}{\numberline {33.1.1}样本拼接的核心价值}{248}{subsection.33.1.1}%
\contentsline {subsection}{\numberline {33.1.2}技术挑战与机遇}{248}{subsection.33.1.2}%
\contentsline {section}{\numberline {33.2}样本拼接方法综述}{248}{section.33.2}%
\contentsline {subsection}{\numberline {33.2.1}方法一：随机拼接（Random Concatenate）}{248}{subsection.33.2.1}%
\contentsline {subsubsection}{基本实现原理}{248}{subsubsection*.208}%
\contentsline {subsubsection}{优势分析}{249}{subsubsection*.209}%
\contentsline {subsubsection}{局限性分析}{249}{subsubsection*.210}%
\contentsline {subsubsection}{改进尝试：特殊标记隔离}{249}{subsubsection*.211}%
\contentsline {subsection}{\numberline {33.2.2}方法二：随机拼接+噪声掩码（Random Concatenate + NoiseMask）}{250}{subsection.33.2.2}%
\contentsline {subsubsection}{技术动机}{250}{subsubsection*.212}%
\contentsline {subsubsection}{核心实现}{250}{subsubsection*.213}%
\contentsline {subsubsection}{实验效果}{251}{subsubsection*.214}%
\contentsline {subsubsection}{技术局限性}{251}{subsubsection*.215}%
\contentsline {subsubsection}{深层分析}{252}{subsubsection*.216}%
\contentsline {subsection}{\numberline {33.2.3}方法三：随机拼接+聚类（Random Concatenate + Cluster）}{252}{subsection.33.2.3}%
\contentsline {subsubsection}{创新思路}{252}{subsubsection*.217}%
\contentsline {subsubsection}{聚类策略}{252}{subsubsection*.218}%
\contentsline {subsubsection}{技术挑战}{253}{subsubsection*.219}%
\contentsline {subsubsection}{实体聚类实践}{253}{subsubsection*.220}%
\contentsline {subsection}{\numberline {33.2.4}方法四：上下文预训练（IN-CONTEXT PRETRAINING）}{253}{subsection.33.2.4}%
\contentsline {subsubsection}{核心思想}{253}{subsubsection*.221}%
\contentsline {subsubsection}{算法流程}{253}{subsubsection*.222}%
\contentsline {subsubsection}{技术实现细节}{254}{subsubsection*.223}%
\contentsline {subsubsection}{关键技术创新}{256}{subsubsection*.224}%
\contentsline {subsubsection}{实验验证}{257}{subsubsection*.225}%
\contentsline {section}{\numberline {33.3}方法对比与分析}{257}{section.33.3}%
\contentsline {subsection}{\numberline {33.3.1}各方法特性对比}{257}{subsection.33.3.1}%
\contentsline {subsection}{\numberline {33.3.2}适用场景建议}{257}{subsection.33.3.2}%
\contentsline {subsubsection}{随机拼接适用场景}{257}{subsubsection*.227}%
\contentsline {subsubsection}{噪声掩码适用场景}{257}{subsubsection*.228}%
\contentsline {subsubsection}{聚类拼接适用场景}{257}{subsubsection*.229}%
\contentsline {subsubsection}{上下文预训练适用场景}{258}{subsubsection*.230}%
\contentsline {section}{\numberline {33.4}实施建议与最佳实践}{258}{section.33.4}%
\contentsline {subsection}{\numberline {33.4.1}数据预处理策略}{258}{subsection.33.4.1}%
\contentsline {subsubsection}{数据质量保障}{258}{subsubsection*.231}%
\contentsline {subsubsection}{规模控制策略}{258}{subsubsection*.232}%
\contentsline {subsection}{\numberline {33.4.2}超参数调优指南}{259}{subsection.33.4.2}%
\contentsline {subsubsection}{序列长度选择}{259}{subsubsection*.233}%
\contentsline {subsubsection}{相似度阈值调优}{259}{subsubsection*.234}%
\contentsline {section}{\numberline {33.5}总结与展望}{259}{section.33.5}%
\contentsline {subsection}{\numberline {33.5.1}技术总结}{259}{subsection.33.5.1}%
\contentsline {subsection}{\numberline {33.5.2}未来发展方向}{260}{subsection.33.5.2}%
\contentsline {subsubsection}{技术融合创新}{260}{subsubsection*.235}%
\contentsline {subsubsection}{算法优化方向}{260}{subsubsection*.236}%
\contentsline {subsubsection}{评估体系完善}{260}{subsubsection*.237}%
\contentsline {chapter}{\numberline {第三十四章\hspace {.3em}}基于LoRA的LLaMA2二次预训练技术详解}{261}{chapter.34}%
\contentsline {section}{\numberline {34.1}引言：为什么需要基于LoRA的LLaMA2二次预训练？}{261}{section.34.1}%
\contentsline {subsection}{\numberline {34.1.1}技术背景与动机}{261}{subsection.34.1.1}%
\contentsline {subsection}{\numberline {34.1.2}核心优势分析}{261}{subsection.34.1.2}%
\contentsline {section}{\numberline {34.2}LoRA技术理论基础}{262}{section.34.2}%
\contentsline {subsection}{\numberline {34.2.1}本征维度理论}{262}{subsection.34.2.1}%
\contentsline {subsection}{\numberline {34.2.2}低秩假设}{262}{subsection.34.2.2}%
\contentsline {subsection}{\numberline {34.2.3}参数更新策略}{262}{subsection.34.2.3}%
\contentsline {section}{\numberline {34.3}语料构建与数据处理}{262}{section.34.3}%
\contentsline {subsection}{\numberline {34.3.1}数据来源与获取}{262}{subsection.34.3.1}%
\contentsline {subsection}{\numberline {34.3.2}语料组成分析}{263}{subsection.34.3.2}%
\contentsline {subsection}{\numberline {34.3.3}数据格式规范}{263}{subsection.34.3.3}%
\contentsline {subsection}{\numberline {34.3.4}语料预处理流程}{263}{subsection.34.3.4}%
\contentsline {section}{\numberline {34.4}二次预训练实现细节}{264}{section.34.4}%
\contentsline {subsection}{\numberline {34.4.1}模型参数配置}{264}{subsection.34.4.1}%
\contentsline {subsubsection}{基础模型参数}{264}{subsubsection*.240}%
\contentsline {subsubsection}{数据参数配置}{265}{subsubsection*.241}%
\contentsline {subsubsection}{LoRA特定参数}{266}{subsubsection*.242}%
\contentsline {subsection}{\numberline {34.4.2}模型配置策略}{267}{subsection.34.4.2}%
\contentsline {subsubsection}{不同场景下的模型配置}{267}{subsubsection*.243}%
\contentsline {subsection}{\numberline {34.4.3}训练参数优化}{268}{subsection.34.4.3}%
\contentsline {subsubsection}{关键超参数设置}{268}{subsubsection*.245}%
\contentsline {subsubsection}{注意力层作用分析}{268}{subsubsection*.246}%
\contentsline {subsection}{\numberline {34.4.4}训练启动命令}{268}{subsection.34.4.4}%
\contentsline {section}{\numberline {34.5}指令微调实现}{269}{section.34.5}%
\contentsline {subsection}{\numberline {34.5.1}微调数据准备}{269}{subsection.34.5.1}%
\contentsline {subsubsection}{数据来源}{269}{subsubsection*.247}%
\contentsline {subsubsection}{提示模板设计}{270}{subsubsection*.248}%
\contentsline {subsection}{\numberline {34.5.2}微调参数配置}{270}{subsection.34.5.2}%
\contentsline {subsubsection}{关键参数设置}{270}{subsubsection*.249}%
\contentsline {subsubsection}{微调启动命令}{270}{subsubsection*.250}%
\contentsline {section}{\numberline {34.6}资源监控与优化}{271}{section.34.6}%
\contentsline {subsection}{\numberline {34.6.1}GPU资源使用情况}{271}{subsection.34.6.1}%
\contentsline {subsubsection}{训练过程监控}{271}{subsubsection*.251}%
\contentsline {subsection}{\numberline {34.6.2}存储空间分析}{272}{subsection.34.6.2}%
\contentsline {subsubsection}{模型文件大小}{272}{subsubsection*.253}%
\contentsline {section}{\numberline {34.7}推理部署与应用}{272}{section.34.7}%
\contentsline {subsection}{\numberline {34.7.1}推理脚本使用}{272}{subsection.34.7.1}%
\contentsline {subsubsection}{基础推理命令}{272}{subsubsection*.255}%
\contentsline {subsubsection}{推理示例}{273}{subsubsection*.256}%
\contentsline {subsection}{\numberline {34.7.2}部署优化策略}{273}{subsection.34.7.2}%
\contentsline {subsubsection}{内存优化}{273}{subsubsection*.257}%
\contentsline {subsubsection}{性能优化}{273}{subsubsection*.258}%
\contentsline {section}{\numberline {34.8}技术总结与展望}{273}{section.34.8}%
\contentsline {subsection}{\numberline {34.8.1}关键技术要点}{273}{subsection.34.8.1}%
\contentsline {subsubsection}{LoRA优势总结}{273}{subsubsection*.259}%
\contentsline {subsubsection}{实践建议}{273}{subsubsection*.260}%
\contentsline {subsection}{\numberline {34.8.2}未来发展方向}{274}{subsection.34.8.2}%
\contentsline {subsubsection}{技术优化方向}{274}{subsubsection*.261}%
\contentsline {subsubsection}{应用拓展方向}{274}{subsubsection*.262}%
\contentsline {subsection}{\numberline {34.8.3}实践价值}{274}{subsection.34.8.3}%
\contentsline {chapter}{\numberline {第三十五章\hspace {.3em}}大语言模型(LLMs)评测技术详解}{275}{chapter.35}%
\contentsline {section}{\numberline {35.1}引言：为什么需要大模型评测？}{275}{section.35.1}%
\contentsline {subsection}{\numberline {35.1.1}传统评测基准的局限性}{275}{subsection.35.1.1}%
\contentsline {subsection}{\numberline {35.1.2}大模型评测的必要性}{275}{subsection.35.1.2}%
\contentsline {section}{\numberline {35.2}大模型评测的核心维度}{275}{section.35.2}%
\contentsline {subsection}{\numberline {35.2.1}理解能力评估}{275}{subsection.35.2.1}%
\contentsline {subsubsection}{深度文本理解}{275}{subsubsection*.263}%
\contentsline {subsubsection}{评估示例}{276}{subsubsection*.264}%
\contentsline {subsection}{\numberline {35.2.2}语言生成能力评估}{276}{subsection.35.2.2}%
\contentsline {subsubsection}{生成质量指标}{276}{subsubsection*.265}%
\contentsline {subsubsection}{生成任务设计}{276}{subsubsection*.266}%
\contentsline {subsection}{\numberline {35.2.3}知识面广度评估}{276}{subsection.35.2.3}%
\contentsline {subsubsection}{知识领域分类}{276}{subsubsection*.267}%
\contentsline {subsection}{\numberline {35.2.4}适应性能力评估}{276}{subsection.35.2.4}%
\contentsline {subsubsection}{多任务适应性}{277}{subsubsection*.269}%
\contentsline {subsection}{\numberline {35.2.5}长文本处理能力评估}{277}{subsection.35.2.5}%
\contentsline {subsubsection}{长文本理解}{277}{subsubsection*.270}%
\contentsline {subsubsection}{长文本生成}{277}{subsubsection*.271}%
\contentsline {subsection}{\numberline {35.2.6}多样性表达能力评估}{278}{subsection.35.2.6}%
\contentsline {subsubsection}{创造性思维}{278}{subsubsection*.272}%
\contentsline {subsubsection}{评估方法}{278}{subsubsection*.273}%
\contentsline {subsection}{\numberline {35.2.7}情感智能评估}{278}{subsection.35.2.7}%
\contentsline {subsubsection}{情感分析能力}{278}{subsubsection*.274}%
\contentsline {subsubsection}{情感表达能力}{278}{subsubsection*.275}%
\contentsline {subsection}{\numberline {35.2.8}逻辑推理能力评估}{279}{subsection.35.2.8}%
\contentsline {subsubsection}{推理类型测试}{279}{subsubsection*.276}%
\contentsline {subsubsection}{推理复杂度分级}{279}{subsubsection*.278}%
\contentsline {subsection}{\numberline {35.2.9}问题解决能力评估}{279}{subsection.35.2.9}%
\contentsline {subsubsection}{实际问题解决}{279}{subsubsection*.279}%
\contentsline {subsubsection}{问题解决流程评估}{279}{subsubsection*.280}%
\contentsline {subsection}{\numberline {35.2.10}道德伦理判断评估}{280}{subsection.35.2.10}%
\contentsline {subsubsection}{伦理困境分析}{280}{subsubsection*.281}%
\contentsline {subsubsection}{评估案例}{280}{subsubsection*.282}%
\contentsline {subsection}{\numberline {35.2.11}对话交互能力评估}{280}{subsection.35.2.11}%
\contentsline {subsubsection}{多轮对话质量}{280}{subsubsection*.283}%
\contentsline {subsubsection}{对话评估指标}{280}{subsubsection*.284}%
\contentsline {section}{\numberline {35.3}大模型Honest原则的实现机制}{281}{section.35.3}%
\contentsline {subsection}{\numberline {35.3.1}Honest原则的技术内涵}{281}{subsection.35.3.1}%
\contentsline {subsection}{\numberline {35.3.2}训练数据策略}{281}{subsection.35.3.2}%
\contentsline {subsubsection}{知识问答样本构造}{281}{subsubsection*.285}%
\contentsline {subsubsection}{样本构造示例}{281}{subsubsection*.286}%
\contentsline {subsection}{\numberline {35.3.3}阅读理解训练优化}{281}{subsection.35.3.3}%
\contentsline {subsubsection}{真实性约束机制}{281}{subsubsection*.287}%
\contentsline {subsubsection}{训练技术细节}{282}{subsubsection*.288}%
\contentsline {subsection}{\numberline {35.3.4}技术实现策略}{282}{subsection.35.3.4}%
\contentsline {subsubsection}{知识边界识别}{282}{subsubsection*.289}%
\contentsline {subsubsection}{真实性评估框架}{282}{subsubsection*.290}%
\contentsline {section}{\numberline {35.4}大模型评测方法体系}{283}{section.35.4}%
\contentsline {subsection}{\numberline {35.4.1}人工评估方法}{283}{subsection.35.4.1}%
\contentsline {subsubsection}{人工评估的优势}{283}{subsubsection*.291}%
\contentsline {subsubsection}{代表性工作}{283}{subsubsection*.292}%
\contentsline {subsection}{\numberline {35.4.2}自动评估方法}{283}{subsection.35.4.2}%
\contentsline {subsubsection}{GPT-4反馈评估}{283}{subsubsection*.294}%
\contentsline {subsubsection}{评估提示设计}{283}{subsubsection*.295}%
\contentsline {subsection}{\numberline {35.4.3}指标化评估方法}{284}{subsection.35.4.3}%
\contentsline {subsubsection}{传统指标应用}{284}{subsubsection*.296}%
\contentsline {subsubsection}{非自然指令评估}{284}{subsubsection*.297}%
\contentsline {subsection}{\numberline {35.4.4}Chatbot Arena评估平台}{284}{subsection.35.4.4}%
\contentsline {subsubsection}{传统基准的局限性}{284}{subsubsection*.298}%
\contentsline {subsubsection}{两两对比评估机制}{284}{subsubsection*.299}%
\contentsline {subsubsection}{ELO评级系统}{285}{subsubsection*.300}%
\contentsline {section}{\numberline {35.5}大模型评测工具生态}{285}{section.35.5}%
\contentsline {subsection}{\numberline {35.5.1}OpenAI Evals评估框架}{285}{subsection.35.5.1}%
\contentsline {subsubsection}{核心设计理念}{285}{subsubsection*.301}%
\contentsline {subsubsection}{评估模板设计}{285}{subsubsection*.302}%
\contentsline {subsubsection}{模板化评估优势}{286}{subsubsection*.303}%
\contentsline {subsection}{\numberline {35.5.2}PandaLM自动化评估模型}{286}{subsection.35.5.2}%
\contentsline {subsubsection}{模型架构设计}{286}{subsubsection*.304}%
\contentsline {subsubsection}{三分制评分体系}{286}{subsubsection*.305}%
\contentsline {subsubsection}{模型训练策略}{286}{subsubsection*.306}%
\contentsline {subsection}{\numberline {35.5.3}综合评测平台建设}{288}{subsection.35.5.3}%
\contentsline {subsubsection}{评测维度整合}{288}{subsubsection*.307}%
\contentsline {subsubsection}{评测流水线设计}{288}{subsubsection*.309}%
\contentsline {section}{\numberline {35.6}评测实践与挑战}{289}{section.35.6}%
\contentsline {subsection}{\numberline {35.6.1}评测数据构建}{289}{subsection.35.6.1}%
\contentsline {subsubsection}{高质量测试集构建原则}{289}{subsubsection*.310}%
\contentsline {subsubsection}{测试数据来源}{289}{subsubsection*.311}%
\contentsline {subsection}{\numberline {35.6.2}评测中的挑战与应对}{289}{subsection.35.6.2}%
\contentsline {subsubsection}{主要技术挑战}{289}{subsubsection*.312}%
\contentsline {subsubsection}{应对策略}{289}{subsubsection*.313}%
\contentsline {section}{\numberline {35.7}未来发展方向}{289}{section.35.7}%
\contentsline {subsection}{\numberline {35.7.1}评测技术趋势}{289}{subsection.35.7.1}%
\contentsline {subsubsection}{多模态评测扩展}{289}{subsubsection*.315}%
\contentsline {subsubsection}{动态适应性评测}{290}{subsubsection*.316}%
\contentsline {subsection}{\numberline {35.7.2}评测生态建设}{290}{subsection.35.7.2}%
\contentsline {subsubsection}{开放评测生态}{290}{subsubsection*.317}%
\contentsline {subsubsection}{伦理合规评测}{290}{subsubsection*.318}%
\contentsline {section}{\numberline {35.8}总结}{290}{section.35.8}%
\contentsline {chapter}{\numberline {第三十六章\hspace {.3em}}大语言模型强化学习技术详解}{292}{chapter.36}%
\contentsline {section}{\numberline {36.1}引言：大模型与强化学习}{292}{section.36.1}%
\contentsline {subsection}{\numberline {36.1.1}强化学习在大模型中的作用}{292}{subsection.36.1.1}%
\contentsline {subsection}{\numberline {36.1.2}技术演进背景}{292}{subsection.36.1.2}%
\contentsline {section}{\numberline {36.2}强化学习基础}{292}{section.36.2}%
\contentsline {subsection}{\numberline {36.2.1}强化学习基本概念}{292}{subsection.36.2.1}%
\contentsline {subsection}{\numberline {36.2.2}强化学习关键要素}{292}{subsection.36.2.2}%
\contentsline {subsection}{\numberline {36.2.3}强化学习在大模型中的应用特点}{292}{subsection.36.2.3}%
\contentsline {section}{\numberline {36.3}基于人类反馈的强化学习(RLHF)}{293}{section.36.3}%
\contentsline {subsection}{\numberline {36.3.1}RLHF技术框架}{293}{subsection.36.3.1}%
\contentsline {subsubsection}{三阶段流程}{293}{subsubsection*.320}%
\contentsline {subsubsection}{数学形式化}{293}{subsubsection*.321}%
\contentsline {subsection}{\numberline {36.3.2}RLHF的实施细节}{293}{subsection.36.3.2}%
\contentsline {subsubsection}{阶段一：监督微调(SFT)}{293}{subsubsection*.322}%
\contentsline {subsubsection}{阶段二：奖励模型训练(RM)}{294}{subsubsection*.323}%
\contentsline {subsubsection}{阶段三：PPO优化}{295}{subsubsection*.324}%
\contentsline {section}{\numberline {36.4}RLHF实践挑战与解决方案}{296}{section.36.4}%
\contentsline {subsection}{\numberline {36.4.1}奖励模型与基础模型一致性问题}{296}{subsection.36.4.1}%
\contentsline {subsubsection}{一致性要求分析}{296}{subsubsection*.325}%
\contentsline {subsubsection}{技术实现考量}{296}{subsubsection*.327}%
\contentsline {subsection}{\numberline {36.4.2}RLHF三大核心挑战}{297}{subsection.36.4.2}%
\contentsline {subsubsection}{挑战一：人工偏好数据成本高昂}{297}{subsubsection*.328}%
\contentsline {subsubsection}{挑战二：三阶段训练流程复杂}{297}{subsubsection*.329}%
\contentsline {subsubsection}{挑战三：计算资源需求巨大}{297}{subsubsection*.330}%
\contentsline {section}{\numberline {36.5}AI专家替代方案}{297}{section.36.5}%
\contentsline {subsection}{\numberline {36.5.1}RLAIF：AI反馈的强化学习}{297}{subsection.36.5.1}%
\contentsline {subsubsection}{核心思想}{297}{subsubsection*.331}%
\contentsline {subsubsection}{技术流程}{297}{subsubsection*.332}%
\contentsline {subsubsection}{实现细节}{297}{subsubsection*.333}%
\contentsline {subsection}{\numberline {36.5.2}RRHF：基于排名的偏好优化}{298}{subsection.36.5.2}%
\contentsline {subsubsection}{方法创新}{298}{subsubsection*.334}%
\contentsline {subsubsection}{排名损失设计}{298}{subsubsection*.335}%
\contentsline {subsubsection}{实现代码}{299}{subsubsection*.336}%
\contentsline {section}{\numberline {36.6}微调数据优化方案}{300}{section.36.6}%
\contentsline {subsection}{\numberline {36.6.1}LIMA：少即是多的对齐假设}{300}{subsection.36.6.1}%
\contentsline {subsubsection}{核心理论}{300}{subsubsection*.337}%
\contentsline {subsubsection}{理论推论}{300}{subsubsection*.338}%
\contentsline {subsubsection}{实施策略}{300}{subsubsection*.339}%
\contentsline {subsection}{\numberline {36.6.2}0.5\%数据假设：数据效率优化}{301}{subsection.36.6.2}%
\contentsline {subsubsection}{核心思想}{301}{subsubsection*.340}%
\contentsline {subsubsection}{关键技术}{301}{subsubsection*.341}%
\contentsline {subsubsection}{样本选择算法}{301}{subsubsection*.342}%
\contentsline {section}{\numberline {36.7}训练过程改造方案}{302}{section.36.7}%
\contentsline {subsection}{\numberline {36.7.1}RAFT：奖励排序微调}{302}{subsection.36.7.1}%
\contentsline {subsubsection}{方法概述}{302}{subsubsection*.343}%
\contentsline {subsubsection}{核心步骤}{302}{subsubsection*.344}%
\contentsline {subsubsection}{算法优势}{302}{subsubsection*.345}%
\contentsline {subsubsection}{实现框架}{302}{subsubsection*.346}%
\contentsline {subsection}{\numberline {36.7.2}DPO：直接偏好优化}{304}{subsection.36.7.2}%
\contentsline {subsubsection}{理论突破}{304}{subsubsection*.347}%
\contentsline {subsubsection}{关键洞察}{304}{subsubsection*.348}%
\contentsline {subsubsection}{优势分析}{304}{subsubsection*.349}%
\contentsline {subsubsection}{DPO实现}{304}{subsubsection*.350}%
\contentsline {section}{\numberline {36.8}技术对比与实践建议}{305}{section.36.8}%
\contentsline {subsection}{\numberline {36.8.1}方法对比分析}{305}{subsection.36.8.1}%
\contentsline {subsection}{\numberline {36.8.2}实践选择指南}{305}{subsection.36.8.2}%
\contentsline {subsubsection}{根据资源条件选择}{305}{subsubsection*.352}%
\contentsline {subsubsection}{根据应用场景选择}{306}{subsubsection*.353}%
\contentsline {subsubsection}{技术选型决策树}{306}{subsubsection*.354}%
\contentsline {section}{\numberline {36.9}未来发展方向}{307}{section.36.9}%
\contentsline {subsection}{\numberline {36.9.1}技术趋势展望}{307}{subsection.36.9.1}%
\contentsline {subsubsection}{理论创新方向}{307}{subsubsection*.355}%
\contentsline {subsubsection}{工程优化方向}{307}{subsubsection*.356}%
\contentsline {subsubsection}{应用拓展方向}{307}{subsubsection*.357}%
\contentsline {section}{\numberline {36.10}总结}{307}{section.36.10}%
\contentsline {chapter}{\numberline {第三十七章\hspace {.3em}}大语言模型强化学习PPO技术详解}{308}{chapter.37}%
\contentsline {section}{\numberline {37.1}引言：PPO在RLHF中的核心地位}{308}{section.37.1}%
\contentsline {subsection}{\numberline {37.1.1}PPO技术背景}{308}{subsection.37.1.1}%
\contentsline {subsection}{\numberline {37.1.2}PPO在RLHF中的价值}{308}{subsection.37.1.2}%
\contentsline {section}{\numberline {37.2}RLHF中PPO的核心步骤}{308}{section.37.2}%
\contentsline {subsection}{\numberline {37.2.1}三阶段流程架构}{308}{subsection.37.2.1}%
\contentsline {subsubsection}{算法框架}{308}{subsubsection*.358}%
\contentsline {subsection}{\numberline {37.2.2}步骤一：采样阶段}{309}{subsection.37.2.2}%
\contentsline {subsubsection}{采样过程本质}{309}{subsubsection*.359}%
\contentsline {subsubsection}{采样数据示例}{309}{subsubsection*.360}%
\contentsline {subsubsection}{采样技术实现}{310}{subsubsection*.362}%
\contentsline {subsection}{\numberline {37.2.3}步骤二：反馈阶段}{310}{subsection.37.2.3}%
\contentsline {subsubsection}{奖励计算机制}{310}{subsubsection*.363}%
\contentsline {subsubsection}{奖励函数设计}{311}{subsubsection*.364}%
\contentsline {subsection}{\numberline {37.2.4}步骤三：学习阶段}{312}{subsection.37.2.4}%
\contentsline {subsubsection}{PPO优化目标}{312}{subsubsection*.365}%
\contentsline {subsubsection}{多epoch优化}{312}{subsubsection*.366}%
\contentsline {section}{\numberline {37.3}RLHF教学类比理解}{313}{section.37.3}%
\contentsline {subsection}{\numberline {37.3.1}师生互动比喻}{313}{subsection.37.3.1}%
\contentsline {subsubsection}{角色对应关系}{313}{subsubsection*.367}%
\contentsline {subsubsection}{教学过程模拟}{313}{subsubsection*.369}%
\contentsline {subsection}{\numberline {37.3.2}教育心理学启示}{314}{subsection.37.3.2}%
\contentsline {subsubsection}{渐进式学习}{314}{subsubsection*.370}%
\contentsline {subsubsection}{激励设计}{314}{subsubsection*.371}%
\contentsline {section}{\numberline {37.4}PPO采样策略与技术实现}{315}{section.37.4}%
\contentsline {subsection}{\numberline {37.4.1}采样过程详解}{315}{subsection.37.4.1}%
\contentsline {subsubsection}{采样本质}{315}{subsubsection*.372}%
\contentsline {subsubsection}{采样参数配置}{315}{subsubsection*.373}%
\contentsline {subsection}{\numberline {37.4.2}演员-评论家架构}{316}{subsection.37.4.2}%
\contentsline {subsubsection}{双模型策略}{316}{subsubsection*.374}%
\contentsline {subsubsection}{架构实现}{316}{subsubsection*.376}%
\contentsline {subsection}{\numberline {37.4.3}收益评估机制}{317}{subsection.37.4.3}%
\contentsline {subsubsection}{收益定义}{317}{subsubsection*.377}%
\contentsline {subsubsection}{奖励组成}{318}{subsubsection*.378}%
\contentsline {subsubsection}{优势函数估计}{319}{subsubsection*.379}%
\contentsline {section}{\numberline {37.5}PPO在RLHF中的实践考量}{320}{section.37.5}%
\contentsline {subsection}{\numberline {37.5.1}超参数调优}{320}{subsection.37.5.1}%
\contentsline {subsubsection}{关键超参数}{320}{subsubsection*.380}%
\contentsline {subsection}{\numberline {37.5.2}训练稳定性保障}{320}{subsection.37.5.2}%
\contentsline {subsubsection}{梯度裁剪}{320}{subsubsection*.382}%
\contentsline {subsubsection}{早期停止机制}{321}{subsubsection*.383}%
\contentsline {section}{\numberline {37.6}总结与展望}{321}{section.37.6}%
\contentsline {subsection}{\numberline {37.6.1}技术总结}{321}{subsection.37.6.1}%
\contentsline {subsection}{\numberline {37.6.2}未来优化方向}{322}{subsection.37.6.2}%
\contentsline {subsubsection}{算法改进}{322}{subsubsection*.384}%
\contentsline {subsubsection}{工程优化}{322}{subsubsection*.385}%
\contentsline {subsubsection}{应用拓展}{322}{subsubsection*.386}%
\contentsline {chapter}{\numberline {第三十八章\hspace {.3em}}强化学习在自然语言处理中的应用技术详解}{323}{chapter.38}%
\contentsline {section}{\numberline {38.1}引言：强化学习与自然语言处理的融合}{323}{section.38.1}%
\contentsline {subsection}{\numberline {38.1.1}技术融合背景}{323}{subsection.38.1.1}%
\contentsline {subsection}{\numberline {38.1.2}RL在NLP中的独特优势}{323}{subsection.38.1.2}%
\contentsline {section}{\numberline {38.2}强化学习基础理论}{323}{section.38.2}%
\contentsline {subsection}{\numberline {38.2.1}强化学习基本框架}{323}{subsection.38.2.1}%
\contentsline {subsubsection}{核心定义}{323}{subsubsection*.387}%
\contentsline {subsubsection}{交互流程}{324}{subsubsection*.388}%
\contentsline {subsection}{\numberline {38.2.2}状态与观测系统}{324}{subsection.38.2.2}%
\contentsline {subsubsection}{状态（States）定义}{324}{subsubsection*.389}%
\contentsline {subsubsection}{观测（Observations）定义}{324}{subsubsection*.390}%
\contentsline {subsubsection}{在NLP中的具体体现}{324}{subsubsection*.392}%
\contentsline {subsection}{\numberline {38.2.3}动作空间分类与特性}{324}{subsection.38.2.3}%
\contentsline {subsubsection}{离散动作空间}{324}{subsubsection*.393}%
\contentsline {subsubsection}{连续动作空间}{325}{subsubsection*.394}%
\contentsline {subsubsection}{在NLP中的动作空间设计}{325}{subsubsection*.395}%
\contentsline {subsection}{\numberline {38.2.4}策略类型与实现}{325}{subsection.38.2.4}%
\contentsline {subsubsection}{确定性策略}{325}{subsubsection*.397}%
\contentsline {subsubsection}{随机性策略}{326}{subsubsection*.398}%
\contentsline {subsubsection}{策略网络实现}{326}{subsubsection*.399}%
\contentsline {subsection}{\numberline {38.2.5}轨迹与状态转移}{328}{subsection.38.2.5}%
\contentsline {subsubsection}{轨迹定义}{328}{subsubsection*.400}%
\contentsline {subsubsection}{状态转移动力学}{328}{subsubsection*.401}%
\contentsline {subsubsection}{初始状态分布}{328}{subsubsection*.402}%
\contentsline {subsubsection}{轨迹概率计算}{328}{subsubsection*.403}%
\contentsline {subsection}{\numberline {38.2.6}奖励函数设计}{328}{subsection.38.2.6}%
\contentsline {subsubsection}{奖励函数定义}{328}{subsubsection*.404}%
\contentsline {subsubsection}{累积回报}{328}{subsubsection*.405}%
\contentsline {subsubsection}{在NLP中的奖励设计}{329}{subsubsection*.406}%
\contentsline {subsection}{\numberline {38.2.7}强化学习问题形式化}{329}{subsection.38.2.7}%
\contentsline {subsubsection}{核心优化问题}{329}{subsubsection*.408}%
\contentsline {subsubsection}{值函数概念}{329}{subsubsection*.409}%
\contentsline {section}{\numberline {38.3}强化学习发展路径：从Value-based到PPO}{330}{section.38.3}%
\contentsline {subsection}{\numberline {38.3.1}Value-based方法}{330}{subsection.38.3.1}%
\contentsline {subsubsection}{基本思想}{330}{subsubsection*.410}%
\contentsline {subsubsection}{最优值函数定义}{330}{subsubsection*.411}%
\contentsline {subsubsection}{最优策略推导}{330}{subsubsection*.412}%
\contentsline {subsubsection}{值函数关系}{330}{subsubsection*.413}%
\contentsline {subsection}{\numberline {38.3.2}贝尔曼方程}{330}{subsection.38.3.2}%
\contentsline {subsubsection}{基本思想}{330}{subsubsection*.414}%
\contentsline {subsubsection}{贝尔曼期望方程}{330}{subsubsection*.415}%
\contentsline {subsubsection}{贝尔曼最优方程}{331}{subsubsection*.416}%
\contentsline {subsubsection}{在NLP中的意义}{331}{subsubsection*.417}%
\contentsline {subsection}{\numberline {38.3.3}优势函数}{331}{subsection.38.3.3}%
\contentsline {subsubsection}{基本概念}{331}{subsubsection*.418}%
\contentsline {subsubsection}{直观解释}{331}{subsubsection*.419}%
\contentsline {subsubsection}{数学性质}{331}{subsubsection*.420}%
\contentsline {subsubsection}{在策略梯度中的应用}{332}{subsubsection*.421}%
\contentsline {subsection}{\numberline {38.3.4}从传统RL到PPO的发展路径}{332}{subsection.38.3.4}%
\contentsline {subsubsection}{技术演进脉络}{332}{subsubsection*.422}%
\contentsline {subsubsection}{PPO的核心创新}{332}{subsubsection*.424}%
\contentsline {section}{\numberline {38.4}RL在NLP中的具体应用}{332}{section.38.4}%
\contentsline {subsection}{\numberline {38.4.1}文本生成任务}{332}{subsection.38.4.1}%
\contentsline {subsubsection}{序列生成建模}{332}{subsubsection*.425}%
\contentsline {subsubsection}{奖励设计策略}{333}{subsubsection*.426}%
\contentsline {subsection}{\numberline {38.4.2}对话系统优化}{334}{subsection.38.4.2}%
\contentsline {subsubsection}{对话作为马尔可夫决策过程}{334}{subsubsection*.427}%
\contentsline {subsubsection}{深度强化学习对话系统}{334}{subsubsection*.428}%
\contentsline {subsection}{\numberline {38.4.3}文本风格迁移}{335}{subsection.38.4.3}%
\contentsline {subsubsection}{风格迁移的RL建模}{335}{subsubsection*.429}%
\contentsline {subsubsection}{约束优化框架}{336}{subsubsection*.430}%
\contentsline {section}{\numberline {38.5}技术挑战与未来方向}{336}{section.38.5}%
\contentsline {subsection}{\numberline {38.5.1}当前技术挑战}{336}{subsection.38.5.1}%
\contentsline {subsubsection}{奖励设计复杂性}{336}{subsubsection*.431}%
\contentsline {subsubsection}{训练稳定性问题}{336}{subsubsection*.432}%
\contentsline {subsubsection}{计算效率挑战}{336}{subsubsection*.433}%
\contentsline {subsection}{\numberline {38.5.2}未来研究方向}{336}{subsection.38.5.2}%
\contentsline {subsubsection}{算法改进方向}{336}{subsubsection*.434}%
\contentsline {subsubsection}{应用拓展方向}{336}{subsubsection*.435}%
\contentsline {subsubsection}{工程优化方向}{337}{subsubsection*.436}%
\contentsline {section}{\numberline {38.6}总结}{337}{section.38.6}%
\contentsline {chapter}{\numberline {第三十九章\hspace {.3em}}大语言模型训练数据集构建技术}{338}{chapter.39}%
\contentsline {section}{\numberline {39.1}引言：训练数据在大模型中的核心地位}{338}{section.39.1}%
\contentsline {subsection}{\numberline {39.1.1}数据驱动的大模型发展}{338}{subsection.39.1.1}%
\contentsline {subsection}{\numberline {39.1.2}数据层级体系}{338}{subsection.39.1.2}%
\contentsline {section}{\numberline {39.2}各阶段训练数据格式规范}{338}{section.39.2}%
\contentsline {subsection}{\numberline {39.2.1}有监督微调（SFT）数据格式}{338}{subsection.39.2.1}%
\contentsline {subsubsection}{基本数据格式}{338}{subsubsection*.437}%
\contentsline {subsubsection}{具体数据示例}{338}{subsubsection*.438}%
\contentsline {subsubsection}{数据质量要求}{339}{subsubsection*.439}%
\contentsline {subsection}{\numberline {39.2.2}奖励模型（RM）数据格式}{339}{subsection.39.2.2}%
\contentsline {subsubsection}{偏好排序格式}{339}{subsubsection*.441}%
\contentsline {subsubsection}{数据示例}{339}{subsubsection*.442}%
\contentsline {subsubsection}{排序质量评估}{340}{subsubsection*.443}%
\contentsline {subsection}{\numberline {39.2.3}强化学习（PPO）数据格式}{340}{subsection.39.2.3}%
\contentsline {subsubsection}{数据需求特点}{340}{subsubsection*.444}%
\contentsline {subsubsection}{数据使用策略}{340}{subsubsection*.445}%
\contentsline {subsubsection}{防偏离机制}{340}{subsubsection*.447}%
\contentsline {section}{\numberline {39.3}训练数据集资源指南}{341}{section.39.3}%
\contentsline {subsection}{\numberline {39.3.1}公开数据集推荐}{341}{subsection.39.3.1}%
\contentsline {subsubsection}{Alpaca-COT数据集}{341}{subsubsection*.448}%
\contentsline {subsubsection}{RedPajama-Data-1T开源计划}{342}{subsubsection*.449}%
\contentsline {subsubsection}{数据集子集详情}{342}{subsubsection*.451}%
\contentsline {subsection}{\numberline {39.3.2}领域预训练数据选择}{342}{subsection.39.3.2}%
\contentsline {subsubsection}{领域适应性考量}{342}{subsubsection*.452}%
\contentsline {subsubsection}{数据选择矩阵}{342}{subsubsection*.453}%
\contentsline {section}{\numberline {39.4}微调数据量需求分析}{342}{section.39.4}%
\contentsline {subsection}{\numberline {39.4.1}数据量影响因素}{342}{subsection.39.4.1}%
\contentsline {subsubsection}{分布一致性关键作用}{342}{subsubsection*.455}%
\contentsline {subsubsection}{任务复杂度影响}{343}{subsubsection*.456}%
\contentsline {subsection}{\numberline {39.4.2}冷门领域数据策略}{343}{subsection.39.4.2}%
\contentsline {subsubsection}{药品识别案例}{343}{subsubsection*.458}%
\contentsline {subsubsection}{多轮训练必要性}{344}{subsubsection*.459}%
\contentsline {section}{\numberline {39.5}微调数据构建方法论}{344}{section.39.5}%
\contentsline {subsection}{\numberline {39.5.1}最优微调数据特征}{344}{subsection.39.5.1}%
\contentsline {subsubsection}{数据多样性要求}{344}{subsubsection*.460}%
\contentsline {subsubsection}{长尾分布挑战}{344}{subsubsection*.461}%
\contentsline {subsubsection}{小红书案例}{344}{subsubsection*.462}%
\contentsline {subsection}{\numberline {39.5.2}数据构建先进方法}{344}{subsection.39.5.2}%
\contentsline {subsection}{\numberline {39.5.3}Self-Instruct框架}{344}{subsection.39.5.3}%
\contentsline {subsubsection}{核心思想}{344}{subsubsection*.464}%
\contentsline {subsubsection}{实现流程}{345}{subsubsection*.465}%
\contentsline {subsection}{\numberline {39.5.4}主动学习策略}{346}{subsection.39.5.4}%
\contentsline {subsubsection}{两大基本原则}{346}{subsubsection*.466}%
\contentsline {subsubsection}{多样性保障：数据去重}{346}{subsubsection*.467}%
\contentsline {subsubsection}{差异性数据发现}{347}{subsubsection*.468}%
\contentsline {subsubsection}{不确定性采样}{348}{subsubsection*.469}%
\contentsline {section}{\numberline {39.6}数据质量评估体系}{349}{section.39.6}%
\contentsline {subsection}{\numberline {39.6.1}多维度质量指标}{349}{subsection.39.6.1}%
\contentsline {subsubsection}{标注质量评估}{349}{subsubsection*.470}%
\contentsline {subsubsection}{数据质量量化}{350}{subsubsection*.471}%
\contentsline {section}{\numberline {39.7}实践建议与最佳实践}{350}{section.39.7}%
\contentsline {subsection}{\numberline {39.7.1}数据构建流程优化}{350}{subsection.39.7.1}%
\contentsline {subsubsection}{迭代式数据构建}{350}{subsubsection*.473}%
\contentsline {subsubsection}{质量控制闭环}{350}{subsubsection*.474}%
\contentsline {subsection}{\numberline {39.7.2}数据管理最佳实践}{351}{subsection.39.7.2}%
\contentsline {subsubsection}{版本控制}{351}{subsubsection*.475}%
\contentsline {subsubsection}{元数据管理}{352}{subsubsection*.476}%
\contentsline {section}{\numberline {39.8}总结与展望}{352}{section.39.8}%
\contentsline {subsection}{\numberline {39.8.1}技术总结}{352}{subsection.39.8.1}%
\contentsline {subsection}{\numberline {39.8.2}未来发展方向}{352}{subsection.39.8.2}%
\contentsline {chapter}{\numberline {第四十章\hspace {.3em}}大语言模型SFT数据生成技术}{353}{chapter.40}%
\contentsline {section}{\numberline {40.1}引言：SFT数据生成的重要性与挑战}{353}{section.40.1}%
\contentsline {subsection}{\numberline {40.1.1}SFT在大模型训练中的关键作用}{353}{subsection.40.1.1}%
\contentsline {subsection}{\numberline {40.1.2}数据生成方法对比}{353}{subsection.40.1.2}%
\contentsline {subsection}{\numberline {40.1.3}方法选择考量因素}{353}{subsection.40.1.3}%
\contentsline {section}{\numberline {40.2}Self-Instruct数据生成方法}{354}{section.40.2}%
\contentsline {subsection}{\numberline {40.2.1}Self-Instruct技术概述}{354}{subsection.40.2.1}%
\contentsline {subsubsection}{基本概念}{354}{subsubsection*.478}%
\contentsline {subsubsection}{技术原理}{354}{subsubsection*.479}%
\contentsline {subsection}{\numberline {40.2.2}Self-Instruct实现流程}{354}{subsection.40.2.2}%
\contentsline {subsubsection}{四阶段流程}{354}{subsubsection*.480}%
\contentsline {subsubsection}{阶段一：指令生成}{354}{subsubsection*.481}%
\contentsline {subsubsection}{阶段二：任务类型识别与处理}{355}{subsubsection*.482}%
\contentsline {subsubsection}{阶段三：输入输出生成}{356}{subsubsection*.483}%
\contentsline {paragraph}{输入优先策略（非分类任务）}{356}{paragraph*.484}%
\contentsline {paragraph}{输出优先策略（分类任务）}{356}{paragraph*.485}%
\contentsline {subsubsection}{阶段四：后处理与质量控制}{358}{subsubsection*.486}%
\contentsline {subsection}{\numberline {40.2.3}Self-Instruct技术优势}{359}{subsection.40.2.3}%
\contentsline {subsubsection}{效率提升}{359}{subsubsection*.487}%
\contentsline {subsubsection}{质量保障}{359}{subsubsection*.488}%
\contentsline {section}{\numberline {40.3}回译数据生成方法}{359}{section.40.3}%
\contentsline {subsection}{\numberline {40.3.1}回译技术概述}{359}{subsection.40.3.1}%
\contentsline {subsubsection}{传统回译方法}{359}{subsubsection*.490}%
\contentsline {subsubsection}{SFT数据生成中的回译创新}{360}{subsubsection*.491}%
\contentsline {subsection}{\numberline {40.3.2}回译方法实现流程}{360}{subsection.40.3.2}%
\contentsline {subsubsection}{基本流程}{360}{subsubsection*.492}%
\contentsline {paragraph}{步骤一：输出生成}{360}{paragraph*.493}%
\contentsline {paragraph}{步骤二：指令生成}{360}{paragraph*.494}%
\contentsline {paragraph}{步骤三：质量验证}{360}{paragraph*.495}%
\contentsline {subsubsection}{质量增强策略}{361}{subsubsection*.496}%
\contentsline {subsection}{\numberline {40.3.3}回译方法技术优势}{362}{subsection.40.3.3}%
\contentsline {subsubsection}{内容质量保证}{362}{subsubsection*.497}%
\contentsline {subsubsection}{多样性生成}{363}{subsubsection*.498}%
\contentsline {section}{\numberline {40.4}混合数据生成策略}{363}{section.40.4}%
\contentsline {subsection}{\numberline {40.4.1}人工与自动生成的结合}{363}{subsection.40.4.1}%
\contentsline {subsubsection}{混合流程设计}{363}{subsubsection*.500}%
\contentsline {subsubsection}{质量控制机制}{363}{subsubsection*.501}%
\contentsline {section}{\numberline {40.5}数据质量评估体系}{365}{section.40.5}%
\contentsline {subsection}{\numberline {40.5.1}多维度评估指标}{365}{subsection.40.5.1}%
\contentsline {subsubsection}{自动化评估指标}{365}{subsubsection*.502}%
\contentsline {subsubsection}{人工评估标准}{365}{subsubsection*.503}%
\contentsline {subsection}{\numberline {40.5.2}评估实施流程}{365}{subsection.40.5.2}%
\contentsline {section}{\numberline {40.6}实践建议与最佳实践}{367}{section.40.6}%
\contentsline {subsection}{\numberline {40.6.1}方法选择指南}{367}{subsection.40.6.1}%
\contentsline {subsubsection}{根据场景选择方法}{367}{subsubsection*.505}%
\contentsline {subsection}{\numberline {40.6.2}质量控制最佳实践}{367}{subsection.40.6.2}%
\contentsline {subsubsection}{多层次质量控制}{367}{subsubsection*.507}%
\contentsline {subsubsection}{迭代优化流程}{367}{subsubsection*.508}%
\contentsline {section}{\numberline {40.7}总结与展望}{368}{section.40.7}%
\contentsline {subsection}{\numberline {40.7.1}技术总结}{368}{subsection.40.7.1}%
\contentsline {subsection}{\numberline {40.7.2}未来发展方向}{369}{subsection.40.7.2}%
\contentsline {subsubsection}{技术改进方向}{369}{subsubsection*.509}%
\contentsline {subsubsection}{应用拓展方向}{369}{subsubsection*.510}%
\contentsline {chapter}{\numberline {第四十一章\hspace {.3em}}大语言模型显存优化与性能评估技术详解}{370}{chapter.41}%
\contentsline {section}{\numberline {41.1}引言：大模型显存挑战概述}{370}{section.41.1}%
\contentsline {subsection}{\numberline {41.1.1}大模型规模与显存需求}{370}{subsection.41.1.1}%
\contentsline {subsection}{\numberline {41.1.2}显存需求的核心影响因素}{370}{subsection.41.1.2}%
\contentsline {section}{\numberline {41.2}模型规模与文件大小}{370}{section.41.2}%
\contentsline {subsection}{\numberline {41.2.1}参数规模表示法}{370}{subsection.41.2.1}%
\contentsline {subsection}{\numberline {41.2.2}精度与存储关系}{371}{subsection.41.2.2}%
\contentsline {subsection}{\numberline {41.2.3}实际文件大小计算}{371}{subsection.41.2.3}%
\contentsline {section}{\numberline {41.3}硬件配置可行性分析}{371}{section.41.3}%
\contentsline {subsection}{\numberline {41.3.1} Vicuna-65B训练硬件需求}{371}{subsection.41.3.1}%
\contentsline {subsubsection}{基础显存需求分析}{371}{subsubsection*.512}%
\contentsline {subsubsection}{4×V100-32G配置分析}{371}{subsubsection*.513}%
\contentsline {subsection}{\numberline {41.3.2}技术限制分析}{371}{subsection.41.3.2}%
\contentsline {subsection}{\numberline {41.3.3}替代解决方案}{372}{subsection.41.3.3}%
\contentsline {section}{\numberline {41.4}低显存环境下的解决方案}{373}{section.41.4}%
\contentsline {subsection}{\numberline {41.4.1}量化技术应用}{373}{subsection.41.4.1}%
\contentsline {subsubsection}{GPTQ量化原理}{373}{subsubsection*.514}%
\contentsline {subsubsection}{LLaMA-65B-INT4可行性}{373}{subsubsection*.515}%
\contentsline {subsection}{\numberline {41.4.2}LoRA微调技术}{373}{subsection.41.4.2}%
\contentsline {subsubsection}{参数高效微调}{373}{subsubsection*.516}%
\contentsline {section}{\numberline {41.5}显存需求详细估算}{374}{section.41.5}%
\contentsline {subsection}{\numberline {41.5.1}推理显存需求}{374}{subsection.41.5.1}%
\contentsline {subsubsection}{基础计算公式}{374}{subsubsection*.517}%
\contentsline {subsubsection}{不同精度下的推理需求}{375}{subsubsection*.518}%
\contentsline {subsection}{\numberline {41.5.2}训练显存需求}{375}{subsection.41.5.2}%
\contentsline {subsubsection}{训练组件分析}{375}{subsubsection*.520}%
\contentsline {subsubsection}{优化器状态分析}{375}{subsubsection*.521}%
\contentsline {subsubsection}{总显存需求公式}{375}{subsubsection*.522}%
\contentsline {subsubsection}{实例验证：Vicuna-7B}{375}{subsubsection*.523}%
\contentsline {section}{\numberline {41.6}内存需求估算方法论}{376}{section.41.6}%
\contentsline {subsection}{\numberline {41.6.1}系统化估算框架}{376}{subsection.41.6.1}%
\contentsline {subsubsection}{估算步骤}{376}{subsubsection*.524}%
\contentsline {subsection}{\numberline {41.6.2}LLaMA-6B案例研究}{376}{subsection.41.6.2}%
\contentsline {subsubsection}{精度影响分析}{376}{subsubsection*.525}%
\contentsline {subsubsection}{系统开销计算}{376}{subsubsection*.527}%
\contentsline {subsubsection}{激活内存计算}{377}{subsubsection*.528}%
\contentsline {subsubsection}{总内存需求汇总}{377}{subsubsection*.529}%
\contentsline {section}{\numberline {41.7}GPU利用率评估方法}{378}{section.41.7}%
\contentsline {subsection}{\numberline {41.7.1}评估方法概述}{378}{subsection.41.7.1}%
\contentsline {subsubsection}{三种评估方法对比}{378}{subsubsection*.531}%
\contentsline {subsection}{\numberline {41.7.2}FLOPS比值法}{378}{subsection.41.7.2}%
\contentsline {subsubsection}{理论基础}{378}{subsubsection*.533}%
\contentsline {subsubsection}{具体实施}{378}{subsubsection*.534}%
\contentsline {subsubsection}{DeepSpeed配置示例}{379}{subsubsection*.535}%
\contentsline {subsection}{\numberline {41.7.3}吞吐量估计法}{379}{subsection.41.7.3}%
\contentsline {subsubsection}{计算方法}{379}{subsubsection*.536}%
\contentsline {subsubsection}{实际案例}{379}{subsubsection*.537}%
\contentsline {subsection}{\numberline {41.7.4}PyTorch Profiler分析法}{380}{subsection.41.7.4}%
\contentsline {subsubsection}{完整分析流程}{380}{subsubsection*.538}%
\contentsline {section}{\numberline {41.8}系统诊断与性能优化}{381}{section.41.8}%
\contentsline {subsection}{\numberline {41.8.1}硬件诊断工具}{381}{subsection.41.8.1}%
\contentsline {subsubsection}{网络性能诊断}{381}{subsubsection*.539}%
\contentsline {subsubsection}{GPU拓扑分析}{382}{subsubsection*.540}%
\contentsline {subsubsection}{详细硬件信息}{382}{subsubsection*.541}%
\contentsline {subsection}{\numberline {41.8.2}性能瓶颈识别}{382}{subsection.41.8.2}%
\contentsline {subsubsection}{通信瓶颈分析}{382}{subsubsection*.542}%
\contentsline {subsubsection}{Tensor Core利用率优化}{382}{subsubsection*.544}%
\contentsline {section}{\numberline {41.9}实践建议与总结}{383}{section.41.9}%
\contentsline {subsection}{\numberline {41.9.1}显存优化最佳实践}{383}{subsection.41.9.1}%
\contentsline {subsubsection}{多层次优化策略}{383}{subsubsection*.545}%
\contentsline {subsubsection}{配置建议}{383}{subsubsection*.546}%
\contentsline {subsection}{\numberline {41.9.2}性能监控体系}{383}{subsection.41.9.2}%
\contentsline {subsubsection}{持续监控指标}{383}{subsubsection*.548}%
\contentsline {subsubsection}{自动化优化框架}{384}{subsubsection*.549}%
\contentsline {section}{\numberline {41.10}总结}{385}{section.41.10}%
\contentsline {chapter}{\numberline {第四十二章\hspace {.3em}}大语言模型显存优化策略技术详解}{386}{chapter.42}%
\contentsline {section}{\numberline {42.1}引言：显存优化的重要性与挑战}{386}{section.42.1}%
\contentsline {subsection}{\numberline {42.1.1}显存瓶颈的根源}{386}{subsection.42.1.1}%
\contentsline {subsection}{\numberline {42.1.2}显存优化的核心目标}{386}{subsection.42.1.2}%
\contentsline {section}{\numberline {42.2}梯度累积（Gradient Accumulation）优化策略}{386}{section.42.2}%
\contentsline {subsection}{\numberline {42.2.1}技术原理与背景}{386}{subsection.42.2.1}%
\contentsline {subsubsection}{传统梯度更新的问题}{386}{subsubsection*.550}%
\contentsline {subsubsection}{梯度累积的核心思想}{387}{subsubsection*.551}%
\contentsline {subsection}{\numberline {42.2.2}实现机制与流程}{387}{subsection.42.2.2}%
\contentsline {subsubsection}{优化后的梯度更新流程}{387}{subsubsection*.552}%
\contentsline {subsubsection}{关键技术要点}{388}{subsubsection*.553}%
\contentsline {subsection}{\numberline {42.2.3}优势分析与实践考量}{388}{subsection.42.2.3}%
\contentsline {subsubsection}{主要优势}{388}{subsubsection*.554}%
\contentsline {subsubsection}{实践考量因素}{388}{subsubsection*.556}%
\contentsline {subsubsection}{潜在问题与解决方案}{388}{subsubsection*.557}%
\contentsline {section}{\numberline {42.3}梯度检查点（Gradient Checkpointing）优化策略}{390}{section.42.3}%
\contentsline {subsection}{\numberline {42.3.1}技术原理与背景}{390}{subsection.42.3.1}%
\contentsline {subsubsection}{反向传播的内存挑战}{390}{subsubsection*.558}%
\contentsline {subsubsection}{梯度检查点的核心思想}{390}{subsubsection*.559}%
\contentsline {subsection}{\numberline {42.3.2}实现机制与流程}{390}{subsection.42.3.2}%
\contentsline {subsubsection}{技术实现原理}{390}{subsubsection*.560}%
\contentsline {subsubsection}{PyTorch实现示例}{390}{subsubsection*.561}%
\contentsline {subsection}{\numberline {42.3.3}优势分析与实践考量}{391}{subsection.42.3.3}%
\contentsline {subsubsection}{主要优势}{391}{subsubsection*.562}%
\contentsline {subsubsection}{实践考量因素}{391}{subsubsection*.564}%
\contentsline {subsubsection}{性能权衡分析}{391}{subsubsection*.565}%
\contentsline {section}{\numberline {42.4}综合优化策略与实践指南}{392}{section.42.4}%
\contentsline {subsection}{\numberline {42.4.1}优化策略组合应用}{392}{subsection.42.4.1}%
\contentsline {subsubsection}{多层次优化框架}{392}{subsubsection*.566}%
\contentsline {subsubsection}{配置建议矩阵}{392}{subsubsection*.567}%
\contentsline {subsection}{\numberline {42.4.2}实践实施指南}{392}{subsection.42.4.2}%
\contentsline {subsubsection}{实施步骤与流程}{392}{subsubsection*.569}%
\contentsline {section}{\numberline {42.5}总结与展望}{394}{section.42.5}%
\contentsline {subsection}{\numberline {42.5.1}技术总结}{394}{subsection.42.5.1}%
\contentsline {subsection}{\numberline {42.5.2}未来发展方向}{395}{subsection.42.5.2}%
\contentsline {chapter}{\numberline {第四十三章\hspace {.3em}}大语言模型分布式训练技术全景解析}{396}{chapter.43}%
\contentsline {section}{\numberline {43.1}引言：大模型训练的挑战与需求}{396}{section.43.1}%
\contentsline {subsection}{\numberline {43.1.1}大模型训练的核心挑战}{396}{subsection.43.1.1}%
\contentsline {subsubsection}{显存效率问题}{396}{subsubsection*.570}%
\contentsline {subsubsection}{计算效率问题}{396}{subsubsection*.571}%
\contentsline {subsection}{\numberline {43.1.2}分布式训练的必要性}{396}{subsection.43.1.2}%
\contentsline {section}{\numberline {43.2}分布式通信基础}{396}{section.43.2}%
\contentsline {subsection}{\numberline {43.2.1}点对点通信（Point-to-Point Communication）}{396}{subsection.43.2.1}%
\contentsline {subsubsection}{基本概念}{396}{subsubsection*.572}%
\contentsline {subsubsection}{技术特点}{397}{subsubsection*.573}%
\contentsline {subsection}{\numberline {43.2.2}集体通信（Collective Communication）}{397}{subsection.43.2.2}%
\contentsline {subsubsection}{基本概念}{397}{subsubsection*.575}%
\contentsline {subsubsection}{常见操作类型}{397}{subsubsection*.576}%
\contentsline {subsubsection}{性能分析}{397}{subsubsection*.577}%
\contentsline {section}{\numberline {43.3}数据并行（Data Parallelism）}{398}{section.43.3}%
\contentsline {subsection}{\numberline {43.3.1}技术原理}{398}{subsection.43.3.1}%
\contentsline {subsubsection}{基本思想}{398}{subsubsection*.579}%
\contentsline {subsubsection}{数学表达}{398}{subsubsection*.580}%
\contentsline {subsection}{\numberline {43.3.2}实现机制}{398}{subsection.43.3.2}%
\contentsline {subsubsection}{一致性保证}{398}{subsubsection*.581}%
\contentsline {subsubsection}{关键技术}{398}{subsubsection*.582}%
\contentsline {subsection}{\numberline {43.3.3}性能优化技术}{399}{subsection.43.3.3}%
\contentsline {subsubsection}{梯度分桶（Gradient Bucketing）}{399}{subsubsection*.583}%
\contentsline {subsubsection}{计算通信重叠}{400}{subsubsection*.584}%
\contentsline {subsubsection}{梯度累积}{400}{subsubsection*.585}%
\contentsline {section}{\numberline {43.4}流水线并行（Pipeline Parallelism）}{400}{section.43.4}%
\contentsline {subsection}{\numberline {43.4.1}技术原理}{400}{subsection.43.4.1}%
\contentsline {subsubsection}{层间划分策略}{400}{subsubsection*.586}%
\contentsline {subsubsection}{计算流程}{400}{subsubsection*.587}%
\contentsline {subsection}{\numberline {43.4.2}技术变体与优化}{400}{subsection.43.4.2}%
\contentsline {subsubsection}{GPipe方案}{400}{subsubsection*.588}%
\contentsline {subsubsection}{PipeDream方案}{400}{subsubsection*.589}%
\contentsline {subsection}{\numberline {43.4.3}显存效率对比}{401}{subsection.43.4.3}%
\contentsline {section}{\numberline {43.5}张量并行（Tensor Parallelism）}{401}{section.43.5}%
\contentsline {subsection}{\numberline {43.5.1}技术原理}{401}{subsection.43.5.1}%
\contentsline {subsubsection}{层内划分策略}{401}{subsubsection*.591}%
\contentsline {subsubsection}{矩阵乘法的并行化}{401}{subsubsection*.592}%
\contentsline {subsection}{\numberline {43.5.2}行并行（Row Parallelism）}{401}{subsection.43.5.2}%
\contentsline {subsubsection}{划分策略}{401}{subsubsection*.593}%
\contentsline {subsubsection}{计算流程}{401}{subsubsection*.594}%
\contentsline {subsection}{\numberline {43.5.3}列并行（Column Parallelism）}{402}{subsection.43.5.3}%
\contentsline {subsubsection}{划分策略}{402}{subsubsection*.595}%
\contentsline {subsubsection}{计算流程}{402}{subsubsection*.596}%
\contentsline {section}{\numberline {43.6}并行策略对比与3D并行}{402}{section.43.6}%
\contentsline {subsection}{\numberline {43.6.1}三种并行策略对比分析}{402}{subsection.43.6.1}%
\contentsline {subsubsection}{显存效率对比}{402}{subsubsection*.597}%
\contentsline {subsubsection}{通信效率对比}{402}{subsubsection*.599}%
\contentsline {subsection}{\numberline {43.6.2}3D并行架构}{403}{subsection.43.6.2}%
\contentsline {subsubsection}{组合策略}{403}{subsubsection*.601}%
\contentsline {subsubsection}{典型配置示例}{403}{subsubsection*.602}%
\contentsline {subsubsection}{通信层次优化}{403}{subsubsection*.603}%
\contentsline {section}{\numberline {43.7}实践指南：并行策略选择}{404}{section.43.7}%
\contentsline {subsection}{\numberline {43.7.1}硬件配置考量}{404}{subsection.43.7.1}%
\contentsline {subsubsection}{单GPU场景}{404}{subsubsection*.604}%
\contentsline {subsubsection}{单节点多卡场景}{404}{subsubsection*.605}%
\contentsline {subsubsection}{多节点多卡场景}{404}{subsubsection*.607}%
\contentsline {subsection}{\numberline {43.7.2}框架选择指南}{404}{subsection.43.7.2}%
\contentsline {subsubsection}{主流技术栈对比}{404}{subsubsection*.608}%
\contentsline {subsubsection}{实际项目选择}{404}{subsubsection*.610}%
\contentsline {section}{\numberline {43.8}性能优化与问题解决}{406}{section.43.8}%
\contentsline {subsection}{\numberline {43.8.1}推理性能分析}{406}{subsection.43.8.1}%
\contentsline {subsubsection}{硬件性能对比}{406}{subsubsection*.611}%
\contentsline {subsubsection}{性能优化建议}{406}{subsubsection*.613}%
\contentsline {subsection}{\numberline {43.8.2}常见问题与解决方案}{406}{subsection.43.8.2}%
\contentsline {subsubsection}{多机训练通信问题}{406}{subsubsection*.614}%
\contentsline {subsubsection}{训练效率优化}{406}{subsubsection*.615}%
\contentsline {subsubsection}{DeepSpeed配置优化}{407}{subsubsection*.616}%
\contentsline {section}{\numberline {43.9}总结与展望}{407}{section.43.9}%
\contentsline {subsection}{\numberline {43.9.1}技术总结}{407}{subsection.43.9.1}%
\contentsline {subsection}{\numberline {43.9.2}未来发展趋势}{407}{subsection.43.9.2}%
\contentsline {subsubsection}{自动化并行}{407}{subsubsection*.617}%
\contentsline {subsubsection}{软硬件协同优化}{408}{subsubsection*.618}%
\contentsline {subsubsection}{算法创新}{408}{subsubsection*.619}%
\contentsline {chapter}{\numberline {第四十四章\hspace {.3em}}分布式训练技术完整解析}{409}{chapter.44}%
\contentsline {section}{\numberline {44.1}引言：大模型训练的分布式挑战}{409}{section.44.1}%
\contentsline {section}{\numberline {44.2}流水线并行(Pipeline Parallelism)完整解析}{409}{section.44.2}%
\contentsline {subsection}{\numberline {44.2.1}基本概念与优化目标}{409}{subsection.44.2.1}%
\contentsline {subsection}{\numberline {44.2.2}朴素模型并行的问题分析}{409}{subsection.44.2.2}%
\contentsline {subsubsection}{GPU利用度不够}{409}{subsubsection*.620}%
\contentsline {subsubsection}{中间结果占据大量内存}{410}{subsubsection*.621}%
\contentsline {subsection}{\numberline {44.2.3}Gpipe解决方案}{410}{subsection.44.2.3}%
\contentsline {subsubsection}{Micro-batch切分}{410}{subsubsection*.622}%
\contentsline {subsubsection}{重计算技术(Re-materialization)}{410}{subsubsection*.623}%
\contentsline {subsubsection}{Batch Normalization处理}{410}{subsubsection*.624}%
\contentsline {subsection}{\numberline {44.2.4}实验效果验证}{410}{subsection.44.2.4}%
\contentsline {subsubsection}{模型规模扩展能力}{410}{subsubsection*.625}%
\contentsline {subsubsection}{训练速度优化}{410}{subsubsection*.626}%
\contentsline {subsubsection}{时间消耗分布}{410}{subsubsection*.627}%
\contentsline {section}{\numberline {44.3}数据并行技术完整解析}{411}{section.44.3}%
\contentsline {subsection}{\numberline {44.3.1}nn.DataParallel原理}{411}{subsection.44.3.1}%
\contentsline {subsubsection}{基本架构}{411}{subsubsection*.628}%
\contentsline {subsubsection}{参数服务器框架}{411}{subsubsection*.629}%
\contentsline {subsection}{\numberline {44.3.2}常见问题与解决方案}{411}{subsection.44.3.2}%
\contentsline {subsubsection}{多GPU计算时间问题}{411}{subsubsection*.630}%
\contentsline {subsubsection}{模型保存与加载}{411}{subsubsection*.631}%
\contentsline {subsubsection}{第一块卡显存占用更多}{411}{subsubsection*.632}%
\contentsline {subsubsection}{loss警告问题}{411}{subsubsection*.633}%
\contentsline {subsubsection}{device\_ids 0被占用问题}{411}{subsubsection*.634}%
\contentsline {subsection}{\numberline {44.3.3}参数更新流程}{412}{subsection.44.3.3}%
\contentsline {section}{\numberline {44.4}DistributedDataParallel深度解析}{412}{section.44.4}%
\contentsline {subsection}{\numberline {44.4.1}Ring-AllReduce算法原理}{412}{subsection.44.4.1}%
\contentsline {subsubsection}{基本概念}{412}{subsubsection*.635}%
\contentsline {subsubsection}{Reduce-Scatter阶段}{412}{subsubsection*.636}%
\contentsline {subsubsection}{All-Gather阶段}{412}{subsubsection*.637}%
\contentsline {subsection}{\numberline {44.4.2}DDP实现流程}{412}{subsection.44.4.2}%
\contentsline {subsubsection}{初始化配置}{412}{subsubsection*.638}%
\contentsline {subsubsection}{启动命令}{413}{subsubsection*.639}%
\contentsline {subsection}{\numberline {44.4.3}参数更新机制}{413}{subsection.44.4.3}%
\contentsline {subsubsection}{初始化同步}{413}{subsubsection*.640}%
\contentsline {subsubsection}{训练过程}{413}{subsubsection*.641}%
\contentsline {subsection}{\numberline {44.4.4}与DataParallel对比}{413}{subsection.44.4.4}%
\contentsline {section}{\numberline {44.5}混合精度训练(AMP)完整解析}{413}{section.44.5}%
\contentsline {subsection}{\numberline {44.5.1}基本概念与原理}{413}{subsection.44.5.1}%
\contentsline {subsubsection}{自动混合精度定义}{413}{subsubsection*.643}%
\contentsline {subsubsection}{混合精度优势}{414}{subsubsection*.644}%
\contentsline {subsubsection}{混合精度劣势}{414}{subsubsection*.645}%
\contentsline {subsection}{\numberline {44.5.2}解决方案}{414}{subsection.44.5.2}%
\contentsline {subsubsection}{梯度scale}{414}{subsubsection*.646}%
\contentsline {subsubsection}{精度回退}{414}{subsubsection*.647}%
\contentsline {subsection}{\numberline {44.5.3}自动转换操作}{414}{subsection.44.5.3}%
\contentsline {subsection}{\numberline {44.5.4}动态损失缩放机制}{414}{subsection.44.5.4}%
\contentsline {subsubsection}{基本原理}{414}{subsubsection*.648}%
\contentsline {subsection}{\numberline {44.5.5}PyTorch AMP使用}{415}{subsection.44.5.5}%
\contentsline {subsubsection}{基础用法}{415}{subsubsection*.649}%
\contentsline {subsubsection}{错误处理}{415}{subsubsection*.650}%
\contentsline {section}{\numberline {44.6}DeepSpeed框架完整解析}{415}{section.44.6}%
\contentsline {subsection}{\numberline {44.6.1}基本概念}{415}{subsection.44.6.1}%
\contentsline {subsubsection}{分布式基础概念}{415}{subsubsection*.651}%
\contentsline {subsubsection}{通信策略支持}{415}{subsubsection*.652}%
\contentsline {subsection}{\numberline {44.6.2}ZeRO优化技术}{415}{subsection.44.6.2}%
\contentsline {subsubsection}{显存内容分类}{415}{subsubsection*.653}%
\contentsline {subsubsection}{ZeRO阶段划分}{416}{subsubsection*.654}%
\contentsline {subsubsection}{内存减少效果}{416}{subsubsection*.655}%
\contentsline {subsection}{\numberline {44.6.3}DeepSpeed使用实践}{416}{subsection.44.6.3}%
\contentsline {subsubsection}{安装配置}{416}{subsubsection*.656}%
\contentsline {subsubsection}{模型初始化}{416}{subsubsection*.657}%
\contentsline {subsubsection}{训练执行}{416}{subsubsection*.658}%
\contentsline {subsection}{\numberline {44.6.4}优化器与调度器}{416}{subsection.44.6.4}%
\contentsline {subsubsection}{优化器选择}{416}{subsubsection*.659}%
\contentsline {subsubsection}{调度器配置}{417}{subsubsection*.660}%
\contentsline {section}{\numberline {44.7}Accelerate库完整解析}{417}{section.44.7}%
\contentsline {subsection}{\numberline {44.7.1}设计理念与优势}{417}{subsection.44.7.1}%
\contentsline {subsubsection}{主要优势}{417}{subsubsection*.662}%
\contentsline {subsubsection}{加速策略}{417}{subsubsection*.663}%
\contentsline {subsection}{\numberline {44.7.2}使用实践}{417}{subsection.44.7.2}%
\contentsline {subsubsection}{基础配置}{417}{subsubsection*.664}%
\contentsline {subsubsection}{训练流程}{417}{subsubsection*.665}%
\contentsline {subsubsection}{启动方式}{418}{subsubsection*.666}%
\contentsline {section}{\numberline {44.8}实践指南与故障排查}{418}{section.44.8}%
\contentsline {subsection}{\numberline {44.8.1}分布式训练代码规范}{418}{subsection.44.8.1}%
\contentsline {subsubsection}{模型加载时机}{418}{subsubsection*.667}%
\contentsline {subsubsection}{数据加载时机}{418}{subsubsection*.668}%
\contentsline {subsubsection}{batch\_size与GPU数量对应}{418}{subsubsection*.669}%
\contentsline {subsection}{\numberline {44.8.2}常见问题解决方案}{418}{subsection.44.8.2}%
\contentsline {subsubsection}{ModuleNotFoundError}{418}{subsubsection*.670}%
\contentsline {subsubsection}{单卡使用DeepSpeed}{419}{subsubsection*.671}%
\contentsline {subsubsection}{ZeRO配置选择}{419}{subsubsection*.672}%
\contentsline {subsection}{\numberline {44.8.3}性能调优策略}{419}{subsection.44.8.3}%
\contentsline {subsubsection}{显存优化}{419}{subsubsection*.673}%
\contentsline {subsubsection}{通信优化}{419}{subsubsection*.674}%
\contentsline {section}{\numberline {44.9}技术选型与发展趋势}{419}{section.44.9}%
\contentsline {subsection}{\numberline {44.9.1}技术对比分析}{419}{subsection.44.9.1}%
\contentsline {subsection}{\numberline {44.9.2}选型决策流程}{420}{subsection.44.9.2}%
\contentsline {subsection}{\numberline {44.9.3}未来发展趋势}{420}{subsection.44.9.3}%
\contentsline {subsubsection}{技术融合}{420}{subsubsection*.675}%
\contentsline {subsubsection}{易用性提升}{420}{subsubsection*.676}%
\contentsline {section}{\numberline {44.10}总结}{421}{section.44.10}%
