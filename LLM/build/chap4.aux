\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {第四章\hspace  {.3em}}Attention 升级面}{23}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10.0pt}}
\@writefile{lot}{\addvspace {10.0pt}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}传统 Attention 的问题}{23}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Attention 优化方向}{23}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Attention 变体概述}{23}{section.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Multi-Query Attention}{23}{section.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Multi-head Attention 存在的问题}{23}{subsection.4.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Multi-Query Attention 介绍}{23}{subsection.4.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}Multi-head Attention 与 Multi-Query Attention 对比}{24}{subsection.4.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.4}各模型参数配置对比}{24}{subsection.4.4.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces 各模型注意力机制参数配置对比}}{24}{table.caption.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.5}Multi-Query Attention 的模型实现差异}{24}{subsection.4.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.6}Multi-Query Attention 的优势}{24}{subsection.4.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.7}使用 Multi-Query Attention 的模型}{24}{subsection.4.4.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Grouped-query Attention}{24}{section.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}Grouped-query Attention 定义}{24}{subsection.4.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.2}使用 Grouped-query Attention 的模型}{25}{subsection.4.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.6}FlashAttention}{25}{section.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.1}FlashAttention 核心技术}{25}{subsection.4.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.2}FlashAttention 优点}{25}{subsection.4.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.3}使用 FlashAttention 的模型}{25}{subsection.4.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.7}并行 Transformer Block}{25}{section.4.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7.1}并行 Transformer Block 原理}{25}{subsection.4.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7.2}并行 Transformer Block 效果}{25}{subsection.4.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7.3}使用并行 Transformer Block 的模型}{25}{subsection.4.7.3}\protected@file@percent }
\@setckpt{chap4}{
\setcounter{page}{26}
\setcounter{equation}{0}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{4}
\setcounter{section}{7}
\setcounter{subsection}{3}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{0}
\setcounter{table}{1}
\setcounter{parentequation}{0}
\setcounter{section@level}{0}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{Hy@AnnotLevel}{0}
\setcounter{bookmark@seq@number}{75}
\setcounter{lstnumber}{1}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{float@type}{16}
\setcounter{nlinenum}{0}
\setcounter{algorithm}{0}
\setcounter{ALC@unique}{0}
\setcounter{ALC@line}{0}
\setcounter{ALC@rem}{0}
\setcounter{ALC@depth}{0}
\setcounter{definition}{0}
\setcounter{theorem}{0}
\setcounter{remark}{0}
\setcounter{example}{0}
\setcounter{lemma}{0}
\setcounter{lstlisting}{0}
}
