\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {第一章\hspace  {.3em}}LLM知识}{10}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10.0pt}}
\@writefile{lot}{\addvspace {10.0pt}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}基础知识}{10}{section.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}什么是大语言模型？}{10}{subsection.1.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}注意力机制：双向与单向}{10}{subsection.1.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.3}主流解码器架构类型}{10}{subsection.1.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.4}架构比较：注意力掩码设计}{11}{subsection.1.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.5}训练目标函数}{11}{subsection.1.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.6}涌现能力：非线性跃迁现象}{11}{subsection.1.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.7}为什么Decoder-Only架构成为主流？}{12}{subsection.1.1.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.8}大模型的优势与挑战}{12}{subsection.1.1.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Layer Normalization 技术解析}{12}{section.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Layer Normalization 基础原理}{13}{subsection.1.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}RMS Norm：简化而高效的替代方案}{13}{subsection.1.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}Deep Norm：稳定深层训练的归一化技术}{14}{subsection.1.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.4}Layer Normalization 在模型中的位置设计}{14}{subsection.1.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.5}总结与建议}{15}{subsection.1.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}激活函数：从基础到现代大模型的应用}{15}{section.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}前馈神经网络基础结构}{15}{subsection.1.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}常见的激活函数}{15}{subsection.1.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.3}门控线性单元及其工作原理}{16}{subsection.1.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.4}GLU的主要变体及其特性}{16}{subsection.1.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.5}GLU的参数规模调整策略}{17}{subsection.1.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.6}GLU有效性的理论与实证基础}{17}{subsection.1.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.7}主流大模型的激活函数选择}{17}{subsection.1.3.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.8}实践建议与总结}{18}{subsection.1.3.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.4}注意力机制优化：从基础到现代改进方案}{18}{section.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}传统注意力机制的局限性}{18}{subsection.1.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.2}注意力优化方法概览}{18}{subsection.1.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.3}Multi-Query Attention：高效推理的关键技术}{19}{subsection.1.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.4}Grouped-Query Attention：平衡性能与效率}{19}{subsection.1.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.5}FlashAttention：硬件感知的优化算法}{20}{subsection.1.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.6}并行Transformer块：加速训练的结构优化}{20}{subsection.1.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.7}主流模型的注意力配置对比}{20}{subsection.1.4.7}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces 主流大语言模型的注意力配置对比}}{21}{table.caption.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.8}总结与实践建议}{21}{subsection.1.4.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Transformers 库基础操作详解}{21}{section.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.1}加载预训练 BERT 模型}{22}{subsection.1.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.2}获取指定隐藏层的输出}{23}{subsection.1.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.3}BERT 模型的输出结构}{23}{subsection.1.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.4}提取不同层的向量表示}{24}{subsection.1.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.5}总结与建议}{24}{subsection.1.5.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.6}损失函数：从信息论到模型优化}{25}{section.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6.1}信息论基础：熵、交叉熵与KL散度}{25}{subsection.1.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6.2}分类任务中的交叉熵损失函数}{26}{subsection.1.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6.3}为什么分类问题使用交叉熵而非均方误差？}{26}{subsection.1.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6.4}信息增益：决策树中的特征选择准则}{27}{subsection.1.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6.5}Softmax函数与数值稳定性处理}{27}{subsection.1.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6.6}多任务学习中的损失平衡}{28}{subsection.1.6.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6.7}总结}{28}{subsection.1.6.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.7}相似度计算与对比学习}{28}{section.1.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7.1}相似度与距离：如何衡量“接近”？}{28}{subsection.1.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7.2}对比学习：学会“对比”以学习表示}{29}{subsection.1.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7.3}对比损失函数：驱动学习的引擎}{29}{subsection.1.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7.4}负样本的挑战与解决方案}{30}{subsection.1.7.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{负样本的重要性}{30}{subsubsection*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{降低负样本成本的策略}{30}{subsubsection*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7.5}总结与应用}{31}{subsection.1.7.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.8}大模型进阶：从生成到部署的全面解析}{31}{section.1.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8.1}生成式大模型：不仅仅是预测下一个词}{31}{subsection.1.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8.2}如何让生成内容丰富多彩？}{31}{subsection.1.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{训练阶段的多样性保障}{31}{subsubsection*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{推理阶段的多样性调控}{32}{subsubsection*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8.3}应对“复读机”问题：为何产生及如何解决}{32}{subsection.1.8.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{问题的表现形式}{32}{subsubsection*.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{问题产生的根源}{32}{subsubsection*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{系统性的解决方案}{33}{subsubsection*.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8.4}模型选择实践指南}{33}{subsection.1.8.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1.2}{\ignorespaces 模型选择简明指南}}{33}{table.caption.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8.5}专业领域大模型的必要性}{34}{subsection.1.8.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8.6}突破限制：长文本处理技术}{34}{subsection.1.8.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{位置编码扩展}{34}{subsubsection*.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{计算效率优化}{34}{subsubsection*.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{模型架构创新}{34}{subsubsection*.13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8.7}总结}{34}{subsection.1.8.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.9}大模型微调：从理论到实践的全方位指南}{35}{section.1.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9.1}微调基础：资源与目标}{35}{subsection.1.9.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{显存需求估算}{35}{subsubsection*.14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{指令微调的本质：激发而非灌输}{35}{subsubsection*.15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9.2}数据构建的艺术}{36}{subsection.1.9.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{SFT指令微调数据构建原则}{36}{subsubsection*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{领域继续预训练（Continue PreTrain）数据选取}{36}{subsubsection*.17}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{缓解灾难性遗忘：通用与领域数据的混合}{36}{subsubsection*.18}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{多任务指令预训练（MIP）}{36}{subsubsection*.19}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9.3}模型选择与配置策略}{36}{subsection.1.9.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{基座模型的选择：Base模型 vs. Chat模型}{36}{subsubsection*.20}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{评测体系的构建}{37}{subsubsection*.21}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{关于领域词表扩增}{37}{subsubsection*.22}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9.4}训练实践：从步骤到技巧}{37}{subsection.1.9.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{典型的两阶段训练流程}{37}{subsubsection*.23}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{低成本微调方案：LoRA}{37}{subsubsection*.24}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{多轮对话微调}{38}{subsubsection*.25}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9.5}关键技术问题剖析}{38}{subsection.1.9.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{灾难性遗忘}{38}{subsubsection*.26}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{大模型学习的三个阶段}{38}{subsubsection*.27}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{量化显存需求}{38}{subsubsection*.28}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9.6}训练优化技术精要}{39}{subsection.1.9.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Batch Size的权衡}{39}{subsubsection*.29}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{优化器的选择}{39}{subsubsection*.30}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9.7}数据构建的深层建议}{39}{subsection.1.9.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{预训练数据的选择}{39}{subsubsection*.31}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{微调数据的构建原则}{39}{subsubsection*.32}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9.8}应对Loss突刺（Loss Spike）}{40}{subsection.1.9.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{原因分析}{40}{subsubsection*.33}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{常见解决方案}{40}{subsubsection*.34}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9.9}总结}{40}{subsection.1.9.9}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.10}大模型训练实战经验}{40}{section.1.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.10.1}分布式训练框架的选择}{41}{subsection.1.10.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{为什么选择DeepSpeed？}{41}{subsubsection*.35}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{实用建议}{41}{subsubsection*.36}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.10.2}大模型训练的实用建议}{41}{subsection.1.10.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{容错与恢复机制}{41}{subsubsection*.37}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{检查点策略}{42}{subsubsection*.38}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{训练前的规划与记录}{42}{subsubsection*.39}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{监控GPU使用效率}{42}{subsubsection*.40}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{环境配置与依赖管理}{43}{subsubsection*.41}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.10.3}模型规模选择策略：从小处着手}{43}{subsection.1.10.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{渐进式开发流程}{43}{subsubsection*.42}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{当前业界的参考点}{43}{subsubsection*.43}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.10.4}加速卡选择建议}{43}{subsection.1.10.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.10.5}总结}{44}{subsection.1.10.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.11}LangChain：构建大语言模型应用的开源框架}{44}{section.1.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.11.1}LangChain是什么？}{44}{subsection.1.11.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.11.2}核心概念：理解LangChain的架构}{45}{subsection.1.11.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{组件与链}{45}{subsubsection*.44}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{提示模板与提示值}{45}{subsubsection*.45}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{示例选择器}{45}{subsubsection*.46}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{输出解析器}{45}{subsubsection*.47}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{索引与检索器}{46}{subsubsection*.48}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{聊天消息历史}{46}{subsubsection*.49}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{代理与工具集}{46}{subsubsection*.50}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.11.3}LangChain的主要功能}{47}{subsection.1.11.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.11.4}LangChain的模型抽象}{47}{subsection.1.11.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.11.5}实战示例：快速上手LangChain}{47}{subsection.1.11.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{示例1：调用语言模型生成回复}{47}{subsubsection*.51}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{示例2：使用提示模板和链}{48}{subsubsection*.52}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{示例3：构建简单的检索问答系统}{48}{subsubsection*.53}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.11.6}LangChain的挑战与局限}{49}{subsection.1.11.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{令牌计数效率问题}{49}{subsubsection*.54}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{文档与API稳定性}{49}{subsubsection*.55}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{概念复杂性}{49}{subsubsection*.56}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{行为不一致性}{50}{subsubsection*.57}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{缺乏标准数据类型}{50}{subsubsection*.58}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.11.7}替代框架简介}{50}{subsection.1.11.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{LlamaIndex}{50}{subsubsection*.59}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Haystack}{50}{subsubsection*.60}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.11.8}总结与建议}{50}{subsection.1.11.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.12}多轮对话记忆优化：为Agent赋予长期记忆}{51}{section.1.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.12.1}引言：为什么需要长期记忆？}{51}{subsection.1.12.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.12.2}全量历史对话：记住每一句话}{51}{subsection.1.12.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.12.3}滑动窗口：专注于最近的对话}{51}{subsection.1.12.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.12.4}实体记忆：记住关键信息}{52}{subsection.1.12.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.12.5}知识图谱记忆：构建实体关系网络}{52}{subsection.1.12.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.12.6}摘要记忆：压缩历史对话}{52}{subsection.1.12.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.12.7}摘要缓冲区记忆：兼顾细节与概要}{52}{subsection.1.12.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.12.8}令牌缓冲区记忆：平衡长度与信息量}{52}{subsection.1.12.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.12.9}向量检索记忆：从海量历史中检索相关信息}{53}{subsection.1.12.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.12.10}总结与选择指南}{53}{subsection.1.12.10}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1.3}{\ignorespaces 多轮对话记忆策略对比}}{53}{table.caption.61}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.13}基于LangChain构建RAG问答应用实战}{54}{section.1.13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.13.1}项目概述：什么是RAG？}{54}{subsection.1.13.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.13.2}环境搭建}{54}{subsection.1.13.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{创建并激活虚拟环境}{54}{subsubsection*.62}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{安装依赖库}{54}{subsubsection*.63}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.13.3}构建RAG应用：分步实现}{55}{subsection.1.13.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{步骤1：数据准备}{55}{subsubsection*.64}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{步骤2：文档加载与分割}{55}{subsubsection*.65}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{步骤3：向量化与存储}{55}{subsubsection*.66}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{步骤4：设计Prompt模板}{56}{subsubsection*.67}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{步骤5：构建检索问答链}{57}{subsubsection*.68}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{步骤6：运行问答}{57}{subsubsection*.69}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.13.4}技术要点总结与优化建议}{58}{subsection.1.13.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{核心组件回顾}{58}{subsubsection*.70}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{关键参数调优建议}{58}{subsubsection*.71}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{高级优化方向}{58}{subsubsection*.72}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.13.5}扩展应用}{59}{subsection.1.13.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.13.6}结语}{59}{subsection.1.13.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.14}基于LLM与向量库的文档对话：架构、挑战与实践}{59}{section.1.14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.14.1}为何需要外挂知识库？}{59}{subsection.1.14.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.14.2}RAG核心架构：七步流程}{60}{subsection.1.14.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{离线阶段：构建向量知识库}{60}{subsubsection*.73}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{在线阶段：执行用户问答}{60}{subsubsection*.74}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.14.3}核心挑战与优化方案}{60}{subsection.1.14.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{痛点一：文档切分粒度难以把握}{60}{subsubsection*.75}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{痛点二：在垂直领域效果不佳}{61}{subsubsection*.76}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{痛点三：检索召回质量低}{61}{subsubsection*.77}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{痛点四：LLM生成的答案质量不稳定}{61}{subsubsection*.78}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{痛点五：多语言或跨语言检索问题}{62}{subsubsection*.79}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.14.4}工程实践与避坑指南}{62}{subsection.1.14.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{环境配置与依赖管理}{62}{subsubsection*.80}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{性能优化建议}{62}{subsubsection*.81}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.14.5}总结}{63}{subsection.1.14.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.15}RAG技术详解：检索增强生成的原理、实践与挑战}{63}{section.1.15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.15.1}引言：为何需要RAG？LLM的固有局限}{63}{subsection.1.15.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{1. 幻觉问题}{63}{subsubsection*.82}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{2. 时效性问题}{63}{subsubsection*.83}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{3. 数据安全与隐私问题}{64}{subsubsection*.84}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.15.2}RAG核心思想：为LLM配备“外部知识库”}{64}{subsection.1.15.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.15.3}RAG核心组件剖析}{64}{subsection.1.15.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{1. 检索器：如何找到相关信息？}{64}{subsubsection*.85}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{2. 生成器：如何利用信息生成答案？}{64}{subsubsection*.86}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.15.4}RAG的显著优势}{65}{subsection.1.15.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.15.5}RAG vs. 监督微调：两种知识注入路径对比}{65}{subsection.1.15.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1.4}{\ignorespaces RAG与监督微调对比}}{65}{table.caption.87}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.15.6}RAG实现三部曲}{66}{subsection.1.15.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{第一步：数据索引（离线）}{66}{subsubsection*.88}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{第二步：在线检索}{66}{subsubsection*.89}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{第三步：增强生成}{67}{subsubsection*.90}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.15.7}典型案例}{67}{subsection.1.15.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{ChatPDF}{67}{subsubsection*.91}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{百川搜索增强}{67}{subsubsection*.92}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{多模态RAG：RA-CM3}{67}{subsubsection*.93}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.15.8}现存挑战与未来方向}{67}{subsection.1.15.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.15.9}总结}{68}{subsection.1.15.9}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.16}LLM文档对话中的PDF解析：挑战与实践}{68}{section.1.16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.16.1}为何PDF解析是文档对话的基石？}{68}{subsection.1.16.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.16.2}两条核心技术路线}{68}{subsection.1.16.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.16.3}PDF解析的典型问题与挑战}{69}{subsection.1.16.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.16.4}长文档处理：从“块”到“结构”}{69}{subsection.1.16.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.16.5}核心技术：多级标题的提取}{70}{subsection.1.16.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.16.6}复杂版式处理：单栏与双栏}{71}{subsection.1.16.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.16.7}表格与图片数据的提取}{71}{subsection.1.16.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.16.8}总结与建议}{71}{subsection.1.16.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.17}表格识别与文本分块：文档智能处理的双引擎}{72}{section.1.17}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.17.1}表格识别：从复杂布局到结构化数据}{72}{subsection.1.17.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.17.2}文本分块：为模型“喂食”的艺术}{73}{subsection.1.17.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.17.3}总结：构建稳健的文档处理流水线}{75}{subsection.1.17.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.18}外挂知识库优化：HYDE与FLARE策略详解}{75}{section.1.18}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.18.1}问题背景：为什么需要大模型辅助召回？}{76}{subsection.1.18.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.18.2}HYDE：假设文档嵌入策略}{76}{subsection.1.18.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.18.3}FLARE：前瞻性主动检索策略}{77}{subsection.1.18.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.18.4}技术对比与实践建议}{78}{subsection.1.18.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.18.5}未来发展方向}{78}{subsection.1.18.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.18.6}结语}{79}{subsection.1.18.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.19}负样本挖掘：提升检索模型性能的关键技术}{79}{section.1.19}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.19.1}引言：为何需要高质量的负样本？}{79}{subsection.1.19.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.19.2}基础方法：随机采样及其局限}{79}{subsection.1.19.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.19.3}进阶策略：Top-K 难负例采样}{80}{subsection.1.19.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.19.4}SimANS：基于相似度的自适应困惑负例采样}{80}{subsection.1.19.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.19.5}对比学习框架下的负例构建}{80}{subsection.1.19.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.19.6}其他实用策略}{81}{subsection.1.19.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.19.7}方法比较与实践建议}{82}{subsection.1.19.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.19.8}未来展望}{82}{subsection.1.19.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.20}检索增强生成（RAG）的优化策略与前沿进展}{82}{section.1.20}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.20.1}RAG基础流程与模块概览}{82}{subsection.1.20.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.20.2}核心模块的精细化优化}{83}{subsection.1.20.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.20.3}知识图谱增强：引入结构化知识}{84}{subsection.1.20.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.20.4}Self-RAG：让模型学会自主检索与批判}{84}{subsection.1.20.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.20.5}多向量检索器与多模态RAG}{84}{subsection.1.20.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.20.6}RAG Fusion：多查询增强检索}{85}{subsection.1.20.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.20.7}模块化RAG：灵活可扩展的架构}{85}{subsection.1.20.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.20.8}RAG与监督微调的结合：RADIT方法}{86}{subsection.1.20.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.20.9}查询转换与BERT的应用}{86}{subsection.1.20.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.20.10}总结与实践建议}{86}{subsection.1.20.10}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.21}RAG系统关键痛点与系统化解决方案}{87}{section.1.21}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.21.1}痛点一：知识库缺失时的“幻觉”与误导}{87}{subsection.1.21.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.21.2}痛点二：关键文档未被优先召回}{87}{subsection.1.21.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.21.3}痛点三：检索与生成环节脱节}{88}{subsection.1.21.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.21.4}痛点四：上下文信息过载与关键信息提取失败}{88}{subsection.1.21.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.21.5}痛点五：输出格式不符合要求}{89}{subsection.1.21.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.21.6}痛点六：检索结果相关性差}{90}{subsection.1.21.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.21.7}痛点七：数据质量低下导致连锁问题}{90}{subsection.1.21.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.21.8}总结与系统化优化路线图}{90}{subsection.1.21.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.22}RAG-Fusion：多查询融合检索增强策略}{91}{section.1.22}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.22.1}RAG的局限性：单一查询的瓶颈}{91}{subsection.1.22.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.22.2}RAG-Fusion 核心工作流程}{91}{subsection.1.22.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.22.3}RAG-Fusion 的显著优势}{92}{subsection.1.22.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.22.4}技术实现要点与建议}{93}{subsection.1.22.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.22.5}总结}{94}{subsection.1.22.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.23}知识图谱RAG：结构化知识的检索增强策略}{94}{section.1.23}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.23.1}为什么需要Graph RAG？}{94}{subsection.1.23.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.23.2}Graph RAG核心概念}{94}{subsection.1.23.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.23.3}Graph RAG技术架构}{95}{subsection.1.23.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Graph RAG系统架构示意图}}{95}{figure.caption.95}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.23.4}核心组件详解}{95}{subsection.1.23.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.23.5}Graph RAG与传统RAG的融合策略}{97}{subsection.1.23.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.23.6}实践建议与技术选型}{97}{subsection.1.23.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.23.7}挑战与未来方向}{98}{subsection.1.23.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.23.8}总结}{98}{subsection.1.23.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.24}参数高效微调技术综述：原理、方法与选择}{98}{section.1.24}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.24.1}为何需要参数高效微调？}{99}{subsection.1.24.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.24.2}PEFT 技术概览与核心思想}{99}{subsection.1.24.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.24.3}主流PEFT方法详解}{99}{subsection.1.24.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.24.4}技术对比与选择指南}{100}{subsection.1.24.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.24.5}当前PEFT技术存在的问题与挑战}{101}{subsection.1.24.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.24.6}未来展望与总结}{101}{subsection.1.24.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.25}提示学习：引导大模型的参数高效微调技术}{102}{section.1.25}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.25.1}引言：为什么需要提示学习？}{102}{subsection.1.25.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.25.2}提示学习的基本概念}{102}{subsection.1.25.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.25.3}提示学习的显著优势}{102}{subsection.1.25.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.25.4}主流提示学习方法详解}{103}{subsection.1.25.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.25.5}方法对比与选择指南}{104}{subsection.1.25.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.25.6}未来展望与总结}{104}{subsection.1.25.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.26}LoRA系列微调技术：高效适配大语言模型的利器}{105}{section.1.26}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.26.1}LoRA核心思想：用低秩分解“撬动”大模型}{105}{subsection.1.26.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.26.2}LoRA的演进：QLoRA与AdaLoRA}{106}{subsection.1.26.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.26.3}LoRA权重管理与持续训练}{106}{subsection.1.26.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.26.4}LoRA的优势与局限}{107}{subsection.1.26.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.26.5}LoRA实践：参数配置与优化指南}{107}{subsection.1.26.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.26.6}未来展望与总结}{108}{subsection.1.26.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.27}PEFT库中LoRA实战指南：配置、优化与实现原理}{109}{section.1.27}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.27.1}环境准备与依赖安装}{109}{subsection.1.27.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.27.2}LoraConfig：配置你的LoRA微调}{109}{subsection.1.27.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.27.3}模型加载与显存优化技巧}{110}{subsection.1.27.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.27.4}PEFT库中LoRA的实现机制（简要分析）}{112}{subsection.1.27.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.27.5}训练、推理与模型保存}{113}{subsection.1.27.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.27.6}最佳实践与总结}{113}{subsection.1.27.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.28}大模型推理技术详解：从原理到实践优化}{114}{section.1.28}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.28.1}推理过程的显存与速度瓶颈}{114}{subsection.1.28.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.28.2}大模型的推理能力剖析}{115}{subsection.1.28.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.28.3}生成参数配置优化指南}{116}{subsection.1.28.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.28.4}内存高效推理方法}{116}{subsection.1.28.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.28.5}总结与最佳实践}{117}{subsection.1.28.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.29}大模型增量预训练：高效注入领域知识的关键技术}{118}{section.1.29}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.29.1}为什么需要增量预训练？}{118}{subsection.1.29.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.29.2}增量预训练的核心价值}{118}{subsection.1.29.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.29.3}核心准备工作：模型与数据}{118}{subsection.1.29.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.29.4}训练框架与资源配置}{119}{subsection.1.29.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.29.5}完整训练流程与关键技术点}{120}{subsection.1.29.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.29.6}总结与实践建议}{121}{subsection.1.29.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.30}增量预训练中的样本拼接技术：效率、噪声与解决方案}{122}{section.1.30}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.30.1}样本拼接的核心价值与技术挑战}{122}{subsection.1.30.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.30.2}样本拼接方法综述}{122}{subsection.1.30.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.30.3}方法一：朴素随机拼接}{123}{subsection.1.30.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.30.4}方法二：随机拼接 + 噪声掩码}{124}{subsection.1.30.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.30.5}方法三：随机拼接 + 语义聚类}{126}{subsection.1.30.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.30.6}总结、实践建议与未来方向}{127}{subsection.1.30.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.31}基于LoRA的LLaMA2二次预训练实践}{128}{section.1.31}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.31.1}技术背景：为什么选择LoRA进行二次预训练？}{128}{subsection.1.31.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.31.2}LoRA理论基础：本征维度与低秩假设}{129}{subsection.1.31.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.31.3}语料构建与数据处理}{129}{subsection.1.31.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.31.4}二次预训练实现细节}{130}{subsection.1.31.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.31.5}模型评估与应用}{133}{subsection.1.31.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.31.6}实践建议与优化技巧}{133}{subsection.1.31.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.31.7}未来展望}{134}{subsection.1.31.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.31.8}总结}{134}{subsection.1.31.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.32}大语言模型评测技术：构建全面的能力评估体系}{134}{section.1.32}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.32.1}引言：为什么需要新的评测体系？}{134}{subsection.1.32.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.32.2}核心评测维度详解}{135}{subsection.1.32.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.32.3}实践建议：如何构建有效的评测体系}{137}{subsection.1.32.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.32.4}未来展望}{138}{subsection.1.32.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.32.5}总结}{138}{subsection.1.32.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.33}大语言模型强化学习}{138}{section.1.33}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.33.1}强化学习在大模型对齐中的核心作用}{139}{subsection.1.33.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.33.2}强化学习基础：核心概念与适配挑战}{139}{subsection.1.33.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.33.3}基于人类反馈的强化学习技术框架}{140}{subsection.1.33.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.33.4}实践挑战、替代方案与未来方向}{141}{subsection.1.33.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.33.5}总结}{142}{subsection.1.33.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.34}大语言模型强化学习中的PPO技术}{142}{section.1.34}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.34.1}PPO在RLHF中的核心地位}{142}{subsection.1.34.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.34.2}RLHF中PPO的核心步骤}{142}{subsection.1.34.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.34.3}PPO的数学原理：裁剪目标与KL惩罚}{143}{subsection.1.34.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.34.4}教学类比：理解PPO在RLHF中的角色}{144}{subsection.1.34.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.34.5}实践建议、常见挑战与未来方向}{144}{subsection.1.34.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.34.6}总结}{145}{subsection.1.34.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.35}强化学习在自然语言处理中的应用技术详解}{145}{section.1.35}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.35.1}引言：为什么NLP需要强化学习？}{145}{subsection.1.35.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.35.2}强化学习基础回顾}{146}{subsection.1.35.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.35.3}RL在NLP中的核心应用场景}{146}{subsection.1.35.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.35.4}技术挑战与应对策略}{147}{subsection.1.35.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.35.5}未来发展方向}{148}{subsection.1.35.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.35.6}总结与建议}{149}{subsection.1.35.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.36}大语言模型训练数据集构建技术详解}{149}{section.1.36}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.36.1}训练数据：模型能力的基石与天花板}{149}{subsection.1.36.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.36.2}数据层级体系：分阶段的能力塑造}{149}{subsection.1.36.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.36.3}数据处理与质量评估的关键技术}{151}{subsection.1.36.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.36.4}实践建议与未来方向}{152}{subsection.1.36.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.36.5}总结}{153}{subsection.1.36.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.37}大语言模型SFT数据生成技术详解}{153}{section.1.37}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.37.1}SFT数据生成：重要性、挑战与方法概览}{153}{subsection.1.37.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.37.2}Self-Instruct：引导模型自我生成指令数据}{154}{subsection.1.37.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.37.3}SFT数据生成的实践指南与评估}{155}{subsection.1.37.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.37.4}未来展望与总结}{155}{subsection.1.37.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.38}大语言模型显存优化与性能评估技术详解}{156}{section.1.38}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.38.1}大模型显存挑战：从何而来？}{156}{subsection.1.38.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.38.2}模型规模、精度与存储大小的定量关系}{157}{subsection.1.38.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.38.3}核心显存优化技术}{157}{subsection.1.38.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.38.4}性能评估：不仅仅是速度}{158}{subsection.1.38.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.38.5}实践建议与总结}{159}{subsection.1.38.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.39}大语言模型显存优化策略技术详解}{160}{section.1.39}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.39.1}显存挑战：为什么优化至关重要？}{160}{subsection.1.39.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.39.2}梯度累积：以小搏大的虚拟大批量训练}{160}{subsection.1.39.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.39.3}组合拳：梯度累积与其他优化技术联用}{162}{subsection.1.39.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.39.4}其他关键显存优化策略简介}{163}{subsection.1.39.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.39.5}实践建议：构建你的显存优化方案}{163}{subsection.1.39.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.39.6}未来展望与总结}{164}{subsection.1.39.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.40}大语言模型分布式训练技术全景解析}{164}{section.1.40}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.40.1}引言：为什么必须分布式训练？}{165}{subsection.1.40.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.40.2}分布式并行范式：三大主流策略}{165}{subsection.1.40.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.40.3}分布式通信：效率的生命线}{166}{subsection.1.40.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.40.4}主流分布式训练框架}{167}{subsection.1.40.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.40.5}实践指南：从理论到部署}{168}{subsection.1.40.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.40.6}未来展望与挑战}{168}{subsection.1.40.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.40.7}总结}{169}{subsection.1.40.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.41}分布式训练技术完整解析：聚焦流水线并行}{169}{section.1.41}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.41.1}引言：大模型训练的分布式挑战与目标}{169}{subsection.1.41.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.41.2}流水线并行：动机与朴素实现}{170}{subsection.1.41.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.41.3}GPipe：基于微批次的优化方案}{170}{subsection.1.41.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.41.4}实践建议与高级优化}{171}{subsection.1.41.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.41.5}未来展望与总结}{172}{subsection.1.41.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1.5}{\ignorespaces 负样本挖掘方法对比}}{173}{table.caption.94}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1.6}{\ignorespaces 主流PEFT方法对比}}{174}{table.caption.96}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1.7}{\ignorespaces 主流提示学习方法对比}}{174}{table.caption.97}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1.8}{\ignorespaces 针对不同任务的生成参数调优建议}}{174}{table.caption.98}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1.9}{\ignorespaces 主流开源大模型基座选型指南}}{175}{table.caption.99}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1.10}{\ignorespaces 模型精度与存储大小关系（$N$为参数量）}}{175}{table.caption.100}\protected@file@percent }
\@setckpt{chap}{
\setcounter{page}{176}
\setcounter{equation}{0}
\setcounter{enumi}{3}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{1}
\setcounter{section}{41}
\setcounter{subsection}{5}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{1}
\setcounter{table}{10}
\setcounter{parentequation}{0}
\setcounter{section@level}{0}
\setcounter{Item}{211}
\setcounter{Hfootnote}{0}
\setcounter{Hy@AnnotLevel}{0}
\setcounter{bookmark@seq@number}{306}
\setcounter{lstnumber}{23}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{float@type}{16}
\setcounter{nlinenum}{0}
\setcounter{algorithm}{0}
\setcounter{ALC@unique}{0}
\setcounter{ALC@line}{0}
\setcounter{ALC@rem}{0}
\setcounter{ALC@depth}{0}
\setcounter{definition}{0}
\setcounter{theorem}{0}
\setcounter{remark}{0}
\setcounter{example}{0}
\setcounter{lemma}{0}
\setcounter{lstlisting}{0}
}
